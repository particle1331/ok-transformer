{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Integration and Deployment Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/ok-transformer/blob/master/docs/nb/deployment/cicd-pipelines.ipynb)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/ok-transformer?style=social)](https://github.com/particle1331/ok-transformer)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will develop a CI/CD pipeline for our model package and prediction serving API. CI/CD stands for **continuous integration** and **continuous deployment**. This involves automatic testing for changes that are being merged to the main or master branch of the code repository, as well as automatically building and deploying the model package and the associated API. \n",
    "\n",
    "Automation means that no person needs to run a script or SSH into a machine every time a change is made to the code base, which can be time consuming and error prone. Moreover, having a CI/CD pipeline means that the system is always in a releasable state so that development teams can quickly react to issues in production. \n",
    "Hence, a project that has a CI/CD pipeline can have faster release cycles with changes to the code deployed on a regular basis, e.g. days instead of months. This reduces the chance of breaking things and makes it easier to integrate our piece of software to the system as changes around the model are also small.\n",
    "\n",
    "Finally, CI/CD platforms can add visibility to the release cycles which can be important when performing audits. For our project, we will be using the [CircleCI](https://circleci.com/) platform which has a free tier. And we will upload our model package to [Gemfury](https://gemfury.com/) which is a private package index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CircleCI config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CircleCI is a third party platform for managing CI/CD pipelines. This is a good all around tool with a free tier. We log in using our GitHub account. To setup CircleCI workflows, we only need to create a `.circleci` directory in the root of our repository which should contain a `config.yml` file. This allows us to setup the project in CircleCI after logging in with our GitHub account.\n",
    "\n",
    "Recall that previously, we used `tox` as our main tool to train and test our model. Then, we built the model package and uploaded it to PyPI. A similar process was done for our API which was deployed to Heroku. We will continue to use `tox` for setting up the test environments in our CI workflows, e.g. for passing environmental variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`.circleci/config.yml`](https://github.com/particle1331/model-deployment/blob/cicd/.circleci/config.yml#L1-L14)\n",
    "```\n",
    "```YAML\n",
    "version: 2\n",
    "\n",
    "\n",
    "defaults: &defaults\n",
    "  docker:\n",
    "    - image: circleci/python:3.9.5\n",
    "  working_directory: ~/project\n",
    "\n",
    "prepare_tox: &prepare_tox\n",
    "  run:\n",
    "    name: Install tox\n",
    "    command: |\n",
    "      sudo pip install --upgrade pip\n",
    "      pip install --user tox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `&` notation is YAML specific which just means we can use these variables later using `*`, and `version` specifies the version of CircleCI used. First, we define `defaults` which specifies the default environment settings. The other one is `prepare_tox` which installs and upgrades `pip` and installs `tox`. These two will be used by jobs which we define below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`.circleci/config.yml`](https://github.com/particle1331/model-deployment/blob/cicd/.circleci/config.yml#L17-L62)\n",
    "```\n",
    "```YAML\n",
    "jobs:\n",
    "  test_app:\n",
    "    <<: *defaults\n",
    "    working_directory: ~/project/api\n",
    "    steps:\n",
    "      - checkout:\n",
    "          path: ~/project\n",
    "      - *prepare_tox\n",
    "      - run:\n",
    "          name: Runnning app tests\n",
    "          command: |\n",
    "            tox\n",
    "  \n",
    "  deploy_app_to_heroku:\n",
    "    <<: *defaults\n",
    "    steps:\n",
    "      - checkout:\n",
    "          path: ~/project\n",
    "      - run:\n",
    "          name: Deploy to Heroku\n",
    "          command: |\n",
    "            git subtree push --prefix api https://heroku:$HEROKU_API_KEY@git.heroku.com/$HEROKU_APP_NAME.git main\n",
    "  \n",
    "  train_and_upload_regression_model:\n",
    "    <<: *defaults\n",
    "    working_directory: ~/project/packages/regression_model\n",
    "    steps:\n",
    "      - checkout:\n",
    "          path: ~/project\n",
    "      - *prepare_tox\n",
    "      - run:\n",
    "          name: Fetch the data\n",
    "          command: |\n",
    "            tox -e fetch_data\n",
    "      - run:\n",
    "          name: Train the model\n",
    "          command: |\n",
    "            tox -e train\n",
    "      - run:\n",
    "          name: Test the model\n",
    "          command: |\n",
    "            tox\n",
    "      - run:\n",
    "          name: Publish model to Gemfury\n",
    "          command: |\n",
    "            tox -e publish_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `<<` notation just inherits all contents of the variables on the same level. The `checkout` will checkout the source code into the jobâ€™s `working_directory`. First, we have `test_app` which runs the tests on the `api` directory, i.e. for the model serving API. Next, we have `deploy_app_to_heroku` which does not run any test, it just pushes the code to Heroku. Let us look at the `tox` files for the first step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`api/tox.ini`](https://github.com/particle1331/model-deployment/blob/cicd/api/tox.ini#L18-L23)\n",
    "```\n",
    "```ini\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "passenv =\n",
    "\tPIP_EXTRA_INDEX_URL\n",
    "\n",
    "...\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only modification to the `tox` file above is `passenv` where we specify the extra index where `pip` will look for packages if not found in PyPI. This uses the environmental variable `PIP_EXTRA_INDEX_URL`. This is used in Heroku when building the prediction service with the model package as a dependency:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`api/requirements.txt`](https://github.com/particle1331/model-deployment/blob/cicd/api/requirements.txt)\n",
    "```\n",
    "```text\n",
    "--extra-index-url=${PIP_EXTRA_INDEX_URL} \n",
    "\n",
    "uvicorn[standard]\n",
    "fastapi>=0.75.1,<1.0.0\n",
    "python-multipart>=0.0.5,<0.1.0\n",
    "pydantic>=1.8.1,<1.9.0\n",
    "typing_extensions>=4.1.1<4.2\n",
    "loguru>=0.5.3,<0.6.0\n",
    "\n",
    "# Our custom package published on a private index server\n",
    "regression-model==0.2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [private index URL](https://gemfury.com/help/pypi-server/#repo-url) follows the format `https://TOKEN:@pypi.fury.io/USERNAME/` where `TOKEN` is an access token in Gemfury. In our case, we generate a full access token. This also serves as our push URL saved as the environmental variable `GEMFURY_PUSH_URL` for uploading packages to the index. Finally, `HEROKU_API_KEY` and `HEROKU_APP_NAME` are also environmental variables that we set in the project settings of CircleCI so we can deploy changes to the prediction service code to Heroku.  \n",
    "\n",
    "**Remark.** The extra index in the requirements file means that a package is installed from this extra index server if it cannot find it from PyPI. This is pretty bad, though it is unlikely that the tests will pass if the wrong package has been downloaded (i.e. a package with the same name and version from PyPI). To solve this, advanced package managers such as [Pipenv](https://pipenv-fork.readthedocs.io/en/latest/index.html) allows [specifying package indices](https://pipenv.pypa.io/en/latest/advanced/#specifying-package-indexes).\n",
    "\n",
    "<br>\n",
    "\n",
    "```{figure} ../../img/heroku-config.png\n",
    "---\n",
    "width: 42em\n",
    "---\n",
    "Setting `PIP_EXTRA_INDEX` as config variable in Heroku.\n",
    "```\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/secrets.png\n",
    "---\n",
    "---\n",
    "Environment variables in CircleCI project settings.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and upload package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the automatic build and upload step which fetches the data from Kaggle, trains the model, and uploads the model package to Gemfury. For other projects, the fetch part can be replaced by AWS CLI from S3 bucket or making a database call. These steps depend on the `tox` file in the model package:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`packages/regression_model/tox.ini`](https://github.com/particle1331/model-deployment/blob/cicd/packages/regression_model/tox.ini#L15-L61)\n",
    "```\n",
    "```ini\n",
    "...\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "passenv =\n",
    "\tKAGGLE_USERNAME\n",
    "\tKAGGLE_KEY\n",
    "\tGEMFURY_PUSH_URL\n",
    "...\n",
    "\n",
    "[testenv:fetch_data]\n",
    "envdir \t = {toxworkdir}/test_package\n",
    "deps \t = {[testenv:test_package]deps}\n",
    "setenv   = {[testenv:test_package]setenv}\n",
    "commands =\n",
    "\tkaggle competitions download -c house-prices-advanced-regression-techniques -p ./regression_model/datasets\n",
    "\tunzip ./regression_model/datasets/house-prices-advanced-regression-techniques.zip -d ./regression_model/datasets\n",
    "\n",
    "\n",
    "[testenv:publish_model]\n",
    "envdir \t = {toxworkdir}/test_package\n",
    "deps \t = {[testenv:test_package]deps}\n",
    "setenv \t = {[testenv:test_package]setenv}\n",
    "commands =\n",
    "\tpip install --upgrade build\n",
    "\tpython -m build\n",
    "\tpython publish_model.py\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we focus on two environments. First, the  the `fetch_data` uses the Kaggle CLI to download the data, hence the `KAGGLE_USERNAME` and `KAGGLE_KEY` secrets are required. This can be obtained from the `~/kaggle.json` file from your Kaggle account. \n",
    "\n",
    "Next, we have `publish_model` which first builds the regression model package using the Python `build` module. This results in a `dist` directory containing build artifacts which are then pushed to Gemfury using `publish_model.py` script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`packages/regression_model/publish_model.py`](https://github.com/particle1331/model-deployment/blob/cicd/packages/regression_model/publish_model.py)\n",
    "```\n",
    "```py\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "for p in glob.glob('dist/*.whl'):\n",
    "    try:\n",
    "        os.system(f'curl -F package=@{p} {os.environ['GEMFURY_PUSH_URL']}')\n",
    "    except:\n",
    "        raise Exception(\"Uploading package failed on file {p}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `config.yml` defines workflows. A workflow determines a sequence of jobs to run given their triggers for each push to the repository. Below we define a single workflow called `regression-model`.\n",
    "\n",
    "```{margin}\n",
    "[`.circleci/config.yml`](https://github.com/particle1331/model-deployment/blob/cicd/.circleci/config.yml#L65-L84)\n",
    "```\n",
    "```YAML\n",
    "...\n",
    "\n",
    "workflows:\n",
    "  version: 2\n",
    "  regression-model:\n",
    "    jobs:\n",
    "      - test_app\n",
    "      \n",
    "      - train_and_upload_regression_model:\n",
    "          filters:\n",
    "            # Ignore any commit on any branch by default\n",
    "            branches:\n",
    "              ignore: /.*/\n",
    "            # Only act on version tags\n",
    "            tags:\n",
    "              only: /^.*/\n",
    "\n",
    "      - deploy_app_to_heroku:\n",
    "          requires:\n",
    "            - test_app\n",
    "          filters:\n",
    "            branches:\n",
    "              only:\n",
    "                - main\n",
    "```\n",
    "\n",
    "First, we have `test_app` running the tests for the API for each commit on each branch. Next, the model package build and upload job `train_and_upload_regression_model` is triggered only when new version tags are created in the git repository. Lastly, `deploy_app_to_heroku` is triggered for each push to main. Note that the app is deployed to Heroku only if the `test_app` job passes. This makes sense since we do not want to deploy an API build that fails its tests. Also note that a push to development branches does not trigger a deploy of the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggering the workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that workflows are triggered by commits. To trigger all workflows, we will update the model package. \n",
    "Recall model package version in API has to be specified in its requirements file. This makes it transparent. So we need to do the following in sequence:\n",
    "\n",
    "1. Bump model package version.\n",
    "2. Release tag in the repo.\n",
    "3. Update API requirements file.\n",
    "\n",
    "The second step triggers automatically triggers a push to our private index of an updated model package containing a newly trained model. The last step triggers a build of the API with a new regression model version deployed to Heroku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating model version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to updating the model. Suppose we bump the model version, e.g. if the data has updated. Then, we have to make the new model available in the private index. Once this is available, we can update the model used by the prediction server and deploy it. Here we will bump the model version from `0.1.0` to `0.1.1` by changing the `VERSION` file. We create a new release targeted on the `main` branch that adheres to the model version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-model.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating release tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the workflow for uploading the updated package to our private index, we have to create a release tag. Releases is located in the right sidebar of the repository home page in GitHub. Note that a tag release can be applied on a specific branch (not necessarily the `main` branch) at the latest commit:\n",
    "\n",
    "```{figure} ../../img/release-tag.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "```\n",
    "\n",
    "\n",
    "This triggers the train and upload job on the `main` branch at ` ebd941e`:\n",
    "\n",
    "```{figure} ../../img/release-tag-workflow.png\n",
    "---\n",
    "width: 45em\n",
    "---\n",
    "```\n",
    "\n",
    "Finally, a new package model uploaded to Gemfury once the workflow completes its run:\n",
    "\n",
    "\n",
    "```{figure} ../../img/gemfury-recent.png\n",
    "---\n",
    "width: 45em\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating API requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the package finishes uploading, we update the model package of the API in the `main` branch. This triggers a test, build, and deploy job. After the deployment is done, we can look in at the `/api/v1/health` endpoint to see that model version has updated. Note that we had to manually wait for the upload job to complete, otherwise we the package will not be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-api.png\n",
    "---\n",
    "width: 45em\n",
    "---\n",
    "Bump model version required by our prediction service.\n",
    "```\n",
    "\n",
    "\n",
    "```{figure} ../../img/api-old.png\n",
    "---\n",
    "width: 45em\n",
    "---\n",
    "```\n",
    "```{figure} ../../img/api-new.png\n",
    "---\n",
    "width: 47em\n",
    "---\n",
    "Model version has updated from `0.1.0` to `0.1.1`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-model-workflows.png\n",
    "---\n",
    "width: 50em\n",
    "---\n",
    "The completed jobs for retraining the regression model. Having a CI pipeline adds visibility to the deployment history of the service. Note that tests are redundant.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic workflows\n",
    "\n",
    "In this section, we improve upon our CI/CD pipelines by solving some issues. For example, it would be nice if for each model version bump, a build of the prediction service that uses the latest model version is automatically triggered. In the current implementation, we had to wait for the model to finish training and pushing the new package to Gemfury before we can update the prediction service. Otherwise, the update fails since it cannot find the appropriate package. \n",
    "\n",
    "Also, there are multiple redundant tests and redundant builds which waste compute resources. We will attempt to fix this using more advanced functionalities offered by CircleCI. Note that the solutions here takes advantage of the monorepo structure of our services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple optimization to the CI pipeline to trigger workflows only for commits on development branches that has a pull request (PR). This can be set in the project settings in CircleCI. This minimizes the number of CI tests but still makes sure that development tests are executed before the changes are merged to the `main` branch. \n",
    "\n",
    "```{figure} ../../img/settings-ci.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "```\n",
    "\n",
    "Note that the same tests will run after merging, but now on the `main` branch. This is necessary since there may be changes on `main` that are not in the respective development branch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-model-version-pr.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "Workflows being run only for commits in a pull request. Best practice is to wait for these tests to pass before approving the merge.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path specific triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that workflows are triggered by commits. In a monorepo, we have multiple services under the same version control system, but have code that are independent of each other. Hence, change in one service will trigger the test, build, and deployment jobs of all services. This was observed in our above setup. For example, updating the regression model code in the `main` branch triggers a test and deploy of the API. We want workflows that trigger only with commits made on specific folders. To do this we use path filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin} \n",
    "[`.circleci/config.yml`](https://github.com/particle1331/model-deployment/blob/cicd-2/.circleci/config.yml)\n",
    "```\n",
    "```yaml\n",
    "version: 2.1\n",
    "\n",
    "setup: true\n",
    "\n",
    "orbs:\n",
    "  # https://circleci.com/developer/orbs/orb/circleci/path-filtering\n",
    "  path-filtering: circleci/path-filtering@0.1.1\n",
    "\n",
    "workflows:\n",
    "  always-run:\n",
    "    jobs:\n",
    "      - path-filtering/filter:\n",
    "          name: check-updated-files\n",
    "          mapping: |\n",
    "            api/.* api-updated true\n",
    "            packages/regression_model/.* regression-model-updated true\n",
    "            packages/regression_model/regression_model/VERSION regression-model-version-bump true\n",
    "          base-revision: main\n",
    "          config-path: .circleci/continue_config.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basically sets parameters to `true` depending on the paths which differs from the same path in `main`. Note that comparison is made with files from the `main` branch not with changes on the same branch. (This integrates well with the setting of only triggering workflows for commits in a PR request.) The conditional workflows are defined in `continue_config.yml`. \n",
    "The first part of this config defines the trigger parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin} \n",
    "[`.circleci/continue_config.yml`](https://github.com/particle1331/model-deployment/blob/cicd-2/.circleci/continue_config.yml#L4-L15)\n",
    "```\n",
    "```yaml\n",
    "parameters:\n",
    "  api-updated:\n",
    "    type: boolean\n",
    "    default: false\n",
    "\n",
    "  regression-model-updated:\n",
    "    type: boolean\n",
    "    default: false\n",
    "\n",
    "  regression-model-version-bump:\n",
    "    type: boolean\n",
    "    default: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force Heroku rebuild\n",
    "\n",
    "Another automation we want to implement is for the prediction service to install the model package with the latest version without having to manually edit the API requirements file like before. So we [update the requirements file](https://github.com/particle1331/model-deployment/blob/cicd-2/api/requirements.txt#L11) to not specify a version of the model package. The problem with this fix is that with no change on the API code, the application will not be rebuilt in Heroku, and hence will not update the model used in production. Resetting the application's code repository in Heroku fixes this:\n",
    "\n",
    "```{margin} \n",
    "[`.circleci/continue_config.yml`](https://github.com/particle1331/model-deployment/blob/cicd-2/.circleci/continue_config.yml#L88-L103)\n",
    "```\n",
    "```yaml\n",
    "  deploy_app_to_heroku:\n",
    "    <<: *defaults\n",
    "    steps:\n",
    "      - checkout:\n",
    "          path: ~/project\n",
    "      - run:\n",
    "          name: Setup Heroku CLI\n",
    "          command: |\n",
    "            curl https://cli-assets.heroku.com/install-ubuntu.sh | sh\n",
    "      - run:\n",
    "          name: Deploy to Heroku\n",
    "          command: |\n",
    "            heroku plugins:install https://github.com/heroku/heroku-repo.git\n",
    "            heroku repo:purge_cache -a $HEROKU_APP_NAME\n",
    "            heroku repo:reset -a $HEROKU_APP_NAME\n",
    "            git subtree push --prefix api https://heroku:$HEROKU_API_KEY@git.heroku.com/$HEROKU_APP_NAME.git main\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define conditional workflows. Each of these will trigger depending on which path differs with the corresponding path in the `main` branch. This makes sure that tests are not redundant. For the API, a test is triggered for commits in a development branch that are part of a pull request, and the same tests are triggered in `main` once the changes are merged. The deploy step is \"main only\", meaning it is carried out only after the changes are merged into `main` (e.g. not on development branches while the commits are sitting on the PR). \n",
    "\n",
    "Similarly, modifications on the model package directory relative to `main` will trigger tests. This includes a train and a test step. Finally, an update of the `VERSION` file for the model package will trigger jobs for uploading a new package to the private package index based on code in the `main` branch. This is followed by a deploy of the API which is ensured to use the latest model. \n",
    "\n",
    "\n",
    "```{margin} \n",
    "[`.circleci/continue_config.yml`](https://github.com/particle1331/model-deployment/blob/cicd-2/.circleci/continue_config.yml#L113-L140)\n",
    "```\n",
    "\n",
    "```yaml\n",
    "workflows:\n",
    "  api-update:\n",
    "    when: << pipeline.parameters.api-updated >>\n",
    "    jobs:\n",
    "      - test_app\n",
    "      - deploy_app_to_heroku:\n",
    "          <<: *main_only\n",
    "          requires:\n",
    "            - test_app\n",
    "\n",
    "  regression-model-update:\n",
    "    when: << pipeline.parameters.regression-model-updated >>\n",
    "    jobs:\n",
    "      - test_regression_model\n",
    "\n",
    "  regression-model-upload:\n",
    "    when: << pipeline.parameters.regression-model-version-bump >>\n",
    "    jobs:\n",
    "      - train_and_upload_regression_model:\n",
    "          <<: *main_only\n",
    "      - test_app:\n",
    "          <<: *main_only\n",
    "          requires:\n",
    "            - train_and_upload_regression_model\n",
    "      - deploy_app_to_heroku:\n",
    "          <<: *main_only\n",
    "          requires:\n",
    "            - test_app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark.** Note that non-conditional workflows can also be defined here, completing all possible workflows, and keeps the primary config file clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```{figure} ../../img/bump-api-workflows-2.png\n",
    "---\n",
    "width: 50em\n",
    "---\n",
    "API update triggered by a change in the `api` folder. The prediction service is deployed with the latest model package once the tests are passed. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Releasing a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that instead of three steps, we have now reduced bumping the model version into a **single step** (updating the `VERSION` file). Note that the jobs are triggered sequentially to ensure that the test and deploy steps use the latest model version, so no more manual waiting. Note that we do away with tags to trigger model package upload as this is redundant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-model-workflows-2.png\n",
    "---\n",
    "width: 50em\n",
    "---\n",
    "Workflows triggered with a model version update. First, a test in the `cicd-2` development branch is triggered. Only the model package is tested. This is followed by a test in the `main` branch after the merge (`566`). There is still some redundancy with the tests, i.e. retesting the `main` branch (`567`) before uploading and deploying the API. But here we can, for example, inject further tests for the model that will be deployed to production.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/bump-model-version-3.png\n",
    "---\n",
    "width: 50em\n",
    "---\n",
    "Workflow triggered by an update of the `VERSION` file. Note the serial dependency that ensures the API uses the latest model package. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this article, we designed a CI pipeline for our regression model package and prediction service monorepo. We were able to optimize the pipeline so that it minimizes the number of tests. Moreover, the pipeline allows us to build new models and deploy a prediction service that uses the updated model by pushing only a **single commit**. At each step, and for PRs to the main branch, tests are run by the pipeline to ensure code correctness. All of these can all be done without any manual waiting (though, it is best practice to wait for the PRs to complete before merging) and remembering of the specific sequence and checklist of steps to follow. \n",
    "\n",
    "Next steps would be to include tests in the CI pipeline that monitor changes in model prediction, i.e. comparing new model predictions to old ones when performing model updates. Another improvement would be to build and deploy Docker images instead of packages, and upload these images to some container registry which is then accessed by a consuming application. Note that this is a fairly general procedure that can be adapted to other cloud platforms or service providers such as AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
