{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb90edeb",
   "metadata": {
    "papermill": {
     "duration": 0.006077,
     "end_time": "2024-09-23T08:58:05.232398",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.226321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bias-variance decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a549733",
   "metadata": {
    "papermill": {
     "duration": 0.002357,
     "end_time": "2024-09-23T08:58:05.238544",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.236187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Recall that the training set $\\mathcal{D}$ is sampled from an underlying distribution $P$ (i.e. the data generating process). Thus, we want to know how model performance of the trained model $f_{\\mathcal{D}}$ varies with respect to training sample ${\\mathcal{D}}.$ Here, we will analyze the squared error of regression models. For simplicity, we assume the existence of a a ground truth function $f$ that assigns the label of an input $\\boldsymbol{\\mathsf{x}}$ (see remark below). \n",
    "\n",
    "Let $f_{\\mathcal{D}}$ be the function obtained by the training process over the sample $\\mathcal{D}.$ Let $\\bar{f}$ be the expected function when drawing fixed sized samples $\\mathcal{D} \\stackrel{\\text{iid}}{\\sim} P^N$ where $N = |\\mathcal{D}|$ and $P$ is the underlying data distribution. In other words, $\\bar{f}$ is an ensemble of trained models weighted by the probability of its training dataset. Then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f8f0a",
   "metadata": {
    "papermill": {
     "duration": 0.002491,
     "end_time": "2024-09-23T08:58:05.243614",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.241123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ \\left(f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}) \\right)^2 \\right]\n",
    "&= \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ \\left((f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}})) + (\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}})) \\right)^2 \\right] \\\\\n",
    "&= \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ (f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}}))^2 \\right] \n",
    "+ \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[(\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}))^2 \\right] \\\\\n",
    "&\\quad+\\; 2\\cdot \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[(f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}}))(\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}})) \\right] \\\\ \\\\\n",
    "&= \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ (f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}}))^2 \\right] \n",
    "+ \\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[(\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}))^2 \\right] + 0 \\\\\n",
    "&= \\underbrace{\\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ (f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}}))^2 \\right]}_{\\text{Variance}} \n",
    " + \\underbrace{\\mathbb{E}_{\\boldsymbol{\\mathsf{x}}}\\left[(\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}))^2 \\right]}_{\\text{Bias}^2}. \\\\\n",
    "\\end{aligned} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a650c",
   "metadata": {
    "papermill": {
     "duration": 0.001789,
     "end_time": "2024-09-23T08:58:05.247622",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.245833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The middle term vanishes by writing it as: \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\boldsymbol{\\mathsf{x}}} \\left[\\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[(f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - \\bar{f}(\\boldsymbol{\\mathsf{x}}))\\right]}_{0} \\; (\\bar{f}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}))  \\right] = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c9e8a",
   "metadata": {},
   "source": [
    "Observe that the **variance** term describes variability of models as we re-run the training process without actually looking into the true function. The **bias** term, on the other hand, looks at the error of the ensemble $\\bar{f}$ from the true function $f.$ These can be visualized as manifesting in the left and right plots respectively of {numref}`01-overfitting-underfitting`.\n",
    "\n",
    "**Remark.** This derivation ignores target noise which is relevant in real-world datasets. Here we have a distribution $p(y \\mid \\boldsymbol{\\mathsf{x}})$ around the target on which we integrate over to get the expected target. See [these notes](https://www.cs.cornell.edu/courses/cs4780/2018sp/lectures/lecturenote12.html) for a more careful treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b099e",
   "metadata": {
    "papermill": {
     "duration": 0.001837,
     "end_time": "2024-09-23T08:58:05.251243",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.249406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "## Classical tradeoff\n",
    "\n",
    "The classical tradeoff is that, as model complexity increases, models fit each sample so closely that they capture even sampling noise. However, these errors tend to cancel out over many samples, resulting in low bias. Overfitting occurs when the model performs well on the training data but may not generalize to a test sample due to high variance. Conversely, simpler models tend to have high bias and underfit any sample from the dataset.\n",
    "\n",
    "For a fixed model class, assuming the data is well-structured, increasing the sample size generally decreases variance, as more data smooths out noise. Interestingly, bias stems from the choice of model class (e.g., architecture, choice of hyperparameters) and persists regardless of the amount of data available. Indeed, {cite}`barron` provides an explicit tradeoff between data and network size (i.e. its width) for sigmoidal FCNNs with two layers:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\boldsymbol{\\mathsf{x}}, \\mathcal{D}}\\left[ \\left(f_{\\mathcal{D}}(\\boldsymbol{\\mathsf{x}}) - f(\\boldsymbol{\\mathsf{x}}) \\right)^2 \\right] \\leq O\\left(\\frac{1}{M}\\right) + O\\left(\\frac{Md}{N}\\right)\\log N\n",
    "$$\n",
    "\n",
    "where $M$ is the number of nodes, $N = |\\mathcal{D}|$ is the number of training observations, and $d$ is the input dimension. Here the first term corresponds to the bias which is data independent, while the second term corresponds to the variance which increases with network size and decreases with data. The above bound also highlights the [curse of dimensionality](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html). The input dimension contributes linearly to the error, while data only decreases error at the rate $O(\\log N / N)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Double descent\n",
    "\n",
    "For large models there is the phenomenon of **double descent** {cite}`double-descent` observed in most networks used in practice where both bias and variance go down with excess complexity. One intuition is that near the *interpolation threshold*, where there is roughly a 1-1 correspondence between the sample datasets and the models, small changes in the dataset lead to large changes in the model. The strip around this is the *critical regime* in the classical case where overfitting occurs. Having more data destroys this 1-1 correspondence, which is covered by the classical tradeoff discussed above.\n",
    "\n",
    "Double descent occurs in the opposite case where we have much more parameters than data ({numref}`01-double-descent`). SGD gets to focus more on what it wants to do, i.e. search for flat minima {cite}`flat-minima`, since it is not constrained to use the full model capacity. Interestingly, the double descent curve is more prominent when there is label noise. In this case, there is less redundancy in the model parameters when the dataset is harder to learn, so that the complexity tradeoff is sharper in the critical strip.\n",
    "\n",
    "**Remark.** Models around with weights flat minimas have validation errors that are much more stable to perturbation in the weights and, as such, tend to be smooth between data points {cite}`hochreiter1997flat`. SGD is discussed in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29708c",
   "metadata": {
    "papermill": {
     "duration": 0.001716,
     "end_time": "2024-09-23T08:58:05.254697",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.252981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../../img/nn/01-double-descent.png\n",
    "---\n",
    "name: 01-double-descent\n",
    "width: 80%\n",
    "align: center\n",
    "---\n",
    "Double descent for ResNet18. The width parameter controls model complexity. Source: {cite}`double-descent`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd67b3",
   "metadata": {
    "papermill": {
     "duration": 0.001568,
     "end_time": "2024-09-23T08:58:05.258030",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.256462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../../img/nn/01-double-descent-data.png\n",
    "---\n",
    "name: 01-double-descent-data\n",
    "width: 90%\n",
    "align: center\n",
    "---\n",
    "Additional data increases model variance within the critical regime.\n",
    "More data shifts the interpolation threshold to the right, resulting in\n",
    "worse test performance compared to the same model trained on a smaller sample. \n",
    "Increasing model complexity improves test performance.\n",
    "Source: {cite}`double-descent`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185644e2",
   "metadata": {
    "papermill": {
     "duration": 0.001477,
     "end_time": "2024-09-23T08:58:05.261004",
     "exception": false,
     "start_time": "2024-09-23T08:58:05.259527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "```{figure} ../../../img/nn/01-double-descent-epochs.png\n",
    "---\n",
    "name: 01-double-descent-epochs\n",
    "width: 100%\n",
    "align: center\n",
    "---\n",
    "Epoch dimension to double descent. Models are ResNet18s on CIFAR10\n",
    "with 20% label noise, trained using Adam with learning rate 0.0001, and data augmentation. \n",
    "**Left:** Training dynamics for models in three regimes. **Right:** Test error vs. Model size Ã— Epochs. \n",
    "Three slices of this plot are shown on the left. Source: {cite}`double-descent`\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.955602,
   "end_time": "2024-09-23T08:58:05.379735",
   "environment_variables": {},
   "exception": null,
   "input_path": "01ca-bias-variance.ipynb",
   "output_path": "01ca-bias-variance.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T08:58:04.424133",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
