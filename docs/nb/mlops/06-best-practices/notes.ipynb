{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Engineering Practices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Updating&color=blue)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/ok-transformer/blob/master/docs/nb/mlops/04-deployment)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/ok-transformer?style=social)](https://github.com/particle1331/ok-transformer)\n",
    "\n",
    "```text\n",
    "ð—”ð˜ð˜ð—¿ð—¶ð—¯ð˜‚ð˜ð—¶ð—¼ð—»: Notes for Module 6 of the MLOps Zoomcamp (2022) by DataTalks.Club.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will cover best practices for developing and deploying our code. We will take our example [streaming code](https://particle1331.github.io/ok-transformer/nb/mlops/04-deployment/notes.html#streaming-deploying-models-with-kinesis-and-lambda) from a previous module, break it down into testable units, and generally just improve it with software engineering best practices. \n",
    "\n",
    "More precisely, we create and automate unit and integration testing, code quality checks, and add pre-commit hooks for all of these. We will also look at how to use `make` which is a nice tools for abstracting and automating repetitive but involved tasks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Python code with pytest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the [streaming module](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/streaming/lambda_function.py) that we will work on:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Load environmental variables\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "# Load model from S3\n",
    "logged_model = f's3://mlflow-models-ron/1/{RUN_ID}/artifacts/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(features):\n",
    "    pred = model.predict(features)\n",
    "    return float(pred[0])\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    predictions_events = []\n",
    "    \n",
    "    for record in event['Records']:\n",
    "        encoded_data = record['kinesis']['data']\n",
    "        decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "        ride_event = json.loads(decoded_data)\n",
    "\n",
    "        ride = ride_event['ride']\n",
    "        ride_id = ride_event['ride_id']\n",
    "    \n",
    "        features = prepare_features(ride)\n",
    "        prediction = predict(features)\n",
    "    \n",
    "        prediction_event = {\n",
    "            'model': 'ride_duration_prediction_model',\n",
    "            'version': '123',\n",
    "            'prediction': {\n",
    "                'ride_duration': prediction,\n",
    "                'ride_id': ride_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if not TEST_RUN:\n",
    "            kinesis_client = boto3.client('kinesis')\n",
    "            kinesis_client.put_record(\n",
    "                StreamName=PREDICTIONS_STREAM_NAME,\n",
    "                Data=json.dumps(prediction_event),\n",
    "                PartitionKey=str(ride_id)\n",
    "            )\n",
    "        \n",
    "        predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions_events\n",
    "    }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, first this script loads the environmental variables and the model from S3. Then, it defines two helper functions for preprocessing and making prediction with the model. The most important function in this script is `lambda_handler` which takes in an `event` which contains a batch of events from the input stream. This explains the outer loop over `event['Records']`. \n",
    "\n",
    "Inside this block, the data is decoded and a prediction is made which is packaged as an event for the output stream. If this function is in production, i.e. outside of a test run, then the prediction event is written on the output stream. In this case, a Kinesis client is instantiated, and an output event is written to the specific predictions stream."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding unit tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a `tests/` folder where we will put all our tests. We will be using `pipenv` to manage our environment. See the [previous module](https://particle1331.github.io/ok-transformer/nb/mlops/04-deployment/notes.html#setting-up-the-environment-with-pipenv) for details. We will start with the following Pipfile:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ini\n",
    "[[source]]\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "name = \"pypi\"\n",
    "\n",
    "[packages]\n",
    "boto3 = \"*\"\n",
    "mlflow = \"*\"\n",
    "scikit-learn = \"==1.0.2\"\n",
    "\n",
    "[dev-packages]\n",
    "pytest = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.9\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this installs [pytest](https://docs.pytest.org/en/7.1.x/) as a dev dependency. Let us create one test:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "import lambda_function\n",
    "\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 130,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 3.66\n",
    "    }\n",
    "\n",
    "    actual_features = lambda_function.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this, since this test is not related to the model, we can comment out the block that loads the model from S3 to make this test run faster. Tests can be run either by doing `$ pytest` on the terminal:\n",
    "\n",
    "```bash\n",
    "$ pytest\n",
    "======================== test session starts ========================\n",
    "platform darwin -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: /Users/particle1331/code/ok-transformer/docs/nb/mlops/06-best-practices\n",
    "plugins: anyio-3.6.1\n",
    "collected 1 item\n",
    "\n",
    "tests/model_test.py .                                         [100%]\n",
    "\n",
    "========================= 1 passed in 1.03s =========================\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using the UI in VS Code after selecting pytest in the configuration:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/vs-code-testing.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "Testing user interface in VS Code.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we should always try is to deliberately **break** the tests. This makes sure that tests cover the changes being made. For example, we may forget adding `assert` statements which means the test are passed trivially.\n",
    "\n",
    "Notice that unit tests act as invariants that must remain true even if particular implementation details around them changes. This is nice since the tests make sure that the important parts of the code are functioning even if we change or refactor things around it. And also allows fast iteration, we know that we are not making breaking changes to the code. In its extreme form, this practice is called [test-driven development](https://en.wikipedia.org/wiki/Test-driven_development) (TDD)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring the lambda function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to manually comment out things in our tests. This is not really great. Also, it would fail if our dev environment cannot connect to S3. A way to fix this is to create a special class which we can call `Model` containing all the logic of the original function, but with parts that are easier to test.\n",
    "\n",
    "\n",
    "For this we modify `lambda_function.py` as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# lambda_function.py\n",
    "import model\n",
    "import os\n",
    "\n",
    "# Load environmental variables\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "\n",
    "model_service = model.init(\n",
    "    predictions_stream_name=PREDICTIONS_STREAM_NAME,\n",
    "    run_id=RUN_ID,\n",
    "    test_run=TEST_RUN\n",
    ")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    return model_service.lambda_handler(event)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `predictions_stream_name` is specified as the stream where the function writes to. The stream where the function reads from need not be specified since this is configured in AWS Lambda. Then, we need to specify `run_id` to determine the model in S3 to use. Finally, `test_run` is simply a flag to indicate that we are in development mode (i.e. so we don't write on the output stream which may be already deployed during the development of this code). These are variables that are configured when the Docker container is run.\n",
    "\n",
    "All of these variables determine a prediction service called `model_service` which abstracts away the process of predicting on an event. In particular, this means that we don't test directly on the actual `lambda_function` that is exposed by the container. (Although, we will see later that this is still covered with integration tests, since these make sure that everything is working together.) This is implemented in the following class:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def load_model(run_id: str):\n",
    "    logged_model = f's3://mlflow-models-ron/1/{run_id}/artifacts/model'\n",
    "    model =  mlflow.pyfunc.load_model(logged_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def base64_decode(encoded_data):\n",
    "    decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "    ride_event = json.loads(decoded_data)\n",
    "    return ride_event\n",
    "\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "\n",
    "    def prepare_features(self, ride):\n",
    "        features = {}\n",
    "        features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "        features['trip_distance'] = ride['trip_distance']\n",
    "        return features\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred = self.model.predict(features)\n",
    "        return float(pred[0])\n",
    "\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "    \n",
    "        predictions_events = []\n",
    "        \n",
    "        for record in event['Records']:\n",
    "            encoded_data = record['kinesis']['data']\n",
    "            ride_event = base64_decode(encoded_data)\n",
    "\n",
    "            ride = ride_event['ride']\n",
    "            ride_id = ride_event['ride_id']\n",
    "        \n",
    "            features = self.prepare_features(ride)\n",
    "            prediction = self.predict(features)\n",
    "        \n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {\n",
    "                    'ride_duration': prediction,\n",
    "                    'ride_id': ride_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # if not TEST_RUN:\n",
    "            #     kinesis_client = boto3.client('kinesis')\n",
    "            #     kinesis_client.put_record(\n",
    "            #         StreamName=PREDICTIONS_STREAM_NAME,\n",
    "            #         Data=json.dumps(prediction_event),\n",
    "            #         PartitionKey=str(ride_id)\n",
    "            #     )\n",
    "            \n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'predictions': predictions_events\n",
    "        }\n",
    "\n",
    "\n",
    "def init(predictions_stream_name: str, run_id: str, test_run: bool):\n",
    "    model = load_model(run_id)\n",
    "    model_service = ModelService(model=model, model_version=run_id)\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attributes of the class are informed by the methods that we collect inside of it. For example, we also version the models with `run_id`, hence the `model_version` attribute. This information is packaged along with the prediction. Also notice that the functionality for writing outputs is commented out. For now, we focus on getting correct predictions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further unit tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the unit tests should fail now after refactoring. Modifying the code so that it uses the `ModelService` class:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 130,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 3.66\n",
    "    }\n",
    "\n",
    "    model_service = model.ModelService(model=None, model_version=None)\n",
    "    \n",
    "    actual_features = model_service.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more tests on units of functionalities. For example, we can test the decoding base 64 inputs.\n",
    "\n",
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_base64_decode():\n",
    "\n",
    "    base64_input = \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\"\n",
    "    \n",
    "    actual_result = model.base64_decode(base64_input)\n",
    "    \n",
    "    expected_result = {\n",
    "        \"ride\": {\n",
    "            \"PULocationID\": 130,\n",
    "            \"DOLocationID\": 205,\n",
    "            \"trip_distance\": 3.66\n",
    "        }, \n",
    "        \"ride_id\": 123\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we are setting `model=None` since this functionality does not use any model. Now, we want to test predict so we want to have a model to test with. We want to avoid connecting to S3 in our dev environment as it adds additional overhead to our tests. Also, there is no reason yet to spend time on things like access credentials when we are only testing bits of functionality. So we will create a **mock model** which mimics all relevant attributes and methods of real models for prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "class ModelMock:\n",
    "    def __init__(self, value):\n",
    "        self.value = value \n",
    "\n",
    "    def predict(self, X):\n",
    "        n = len(X)\n",
    "        return [self.value] * n\n",
    "\n",
    "\n",
    "def test_predict():\n",
    "    \n",
    "    features = {\n",
    "        'PU_DO': '130_205',\n",
    "        'trip_distance': 3.66,\n",
    "    }\n",
    "\n",
    "    model_mock = ModelMock(value=10.0)\n",
    "    model_service = model.ModelService(model=model_mock, model_version=None)\n",
    "\n",
    "    actual_result = model_service.predict(features)\n",
    "    expected_result = 10.0\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to test the `ModelService.lambda_handler` function:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "...\n",
    "\n",
    "def test_lambda_handler():\n",
    "    \n",
    "    event = {\n",
    "        \"Records\": [\n",
    "            {\n",
    "                \"kinesis\": {\n",
    "                    \"data\": \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    model_mock = ModelMock(value=10.0)\n",
    "    model_service = model.ModelService(model=model_mock, model_version=\"model-mock\")\n",
    "\n",
    "    actual_result = model_service.lambda_handler(event)\n",
    "    expected_result = {\n",
    "        'predictions': [\n",
    "            {\n",
    "                'model': 'ride_duration_prediction_model', \n",
    "                'version': 'model-mock', \n",
    "                'prediction': {\n",
    "                    'ride_duration': 10.0,\n",
    "                    'ride_id': 123\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding callbacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We covered pretty much everything except the writing on the output stream. Note that this part of the `lambda_handler` code seems out of place. All other functionalities are geared towards prediction and now, if we include writing on an output stream, the model service has to know about the Kinesis client, the stream name, etc.\n",
    "\n",
    "Instead, what we can do is define a separate unit that handles what happens **after** the prediction is done, i.e. a **callback** on prediction events. This is called every time the model service completes a prediction. Putting something on the Kinesis stream would be one of the callbacks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version, callbacks=None):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "        self.callbacks = callbacks or []\n",
    "\n",
    "    ...\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "    \n",
    "        predictions_events = []\n",
    "        \n",
    "        for record in event['Records']:\n",
    "            \n",
    "            ...\n",
    "        \n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {\n",
    "                    'ride_duration': prediction,\n",
    "                    'ride_id': ride_id\n",
    "                }\n",
    "            }\n",
    "\n",
    "            for callback in self.callbacks:     # !\n",
    "                callback(prediction_event)\n",
    "            \n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "        return {\n",
    "            'predictions': predictions_events\n",
    "        }\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that callbacks act on prediction events, e.g. writes them to Kinesis streams. Below we modify the `init` function to include the Kinesis callback which we package into a class since we need a callable. Here we simply pass a reference to the `put_record` method which acts on prediction events in the `callbacks` list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "class KinesisCallback:\n",
    "    \n",
    "    def __init__(self, kinesis_client, predictions_stream_name):\n",
    "        self.kinesis_client = kinesis_client\n",
    "        self.predictions_stream_name = predictions_stream_name\n",
    "\n",
    "    def put_record(self, prediction_event):\n",
    "        ride_id = prediction_event['prediction']['ride_id']\n",
    "        self.kinesis_client.put_record(\n",
    "            StreamName=self.predictions_stream_name,\n",
    "            Data=json.dumps(prediction_event),\n",
    "            PartitionKey=str(ride_id)\n",
    "        )\n",
    "\n",
    "\n",
    "def init(predictions_stream_name: str, run_id: str, test_run: bool):\n",
    "    \"\"\"Initialize model_service for lambda_function module.\"\"\"\n",
    "\n",
    "    model = load_model(run_id)\n",
    "    callbacks = []\n",
    "    \n",
    "    if not test_run:\n",
    "        kinesis_client = boto3.client('kinesis')\n",
    "        kinesis_callback = KinesisCallback(kinesis_client, predictions_stream_name)\n",
    "        callbacks.append(kinesis_callback.put_record)\n",
    "\n",
    "    model_service = ModelService(model=model, model_version=run_id, callbacks=callbacks)\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks really really nice. We will test this later with a local cloud setup! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Source code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here for the [finished code](https://github.com/particle1331/ok-transformer/tree/2a5cad64632e098cc305bfe0dfb8bd1242135939/docs/nb/mlops/06-best-practices/code) for this section. Final directory structure at the end should look like:\n",
    "\n",
    "```text\n",
    ".\n",
    "â”œâ”€â”€ Dockerfile\n",
    "â”œâ”€â”€ Pipfile\n",
    "â”œâ”€â”€ Pipfile.lock\n",
    "â”œâ”€â”€ lambda_function.py\n",
    "â”œâ”€â”€ model.py\n",
    "â””â”€â”€ tests\n",
    "    â”œâ”€â”€ __init__.py\n",
    "    â””â”€â”€ model_test.py\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we refactored our original code for our lambda function and created tests. But these tests are quite limited. They only test only functions. They don't test that the entire thing still works. Recall that we have `test_docker.py` which sort of checks that predictions still work for the container as a whole. At this point, we can build and run the container to make sure that this code still works as a whole.\n",
    "\n",
    "**Remarks.** Note that the goal of integration testing is not to test the accuracy of predictions, but only that prediction with the Lambda container works and it has the correct input and output signature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Lambda container"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulding and running the container and running the `test_docker` script can be done along with writing the unit tests, or after refactoring, so that no drastic change is done without making sure everything still are integrated well. But we only get to do this here for the sake of presentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM public.ecr.aws/lambda/python:3.9\n",
    "\n",
    "RUN pip install -U pip\n",
    "RUN pip install pipenv\n",
    "\n",
    "COPY [ \"Pipfile\", \"Pipfile.lock\", \"./\" ]\n",
    "\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "COPY [ \"lambda_function.py\", \"model.py\", \"./\" ]\n",
    "\n",
    "CMD [ \"lambda_function.lambda_handler\" ]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -t stream-model-duration:v2 .\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[+] Building 1.2s (11/11) FINISHED\n",
    " => [internal] load build definition from Dockerfile            0.0s\n",
    " => => transferring dockerfile: 37B                             0.0s\n",
    " => [internal] load .dockerignore                               0.0s\n",
    " => => transferring context: 2B                                 0.0s\n",
    " => [internal] load metadata for public.ecr.aws/lambda/python:  1.0s\n",
    " => [1/6] FROM public.ecr.aws/lambda/python:3.9@sha256:3dda276  0.0s\n",
    " => [internal] load build context                               0.0s\n",
    " => => transferring context: 2.64kB                             0.0s\n",
    " => CACHED [2/6] RUN pip install -U pip                         0.0s\n",
    " => CACHED [3/6] RUN pip install pipenv                         0.0s\n",
    " => CACHED [4/6] COPY [ Pipfile, Pipfile.lock, ./ ]             0.0s\n",
    " => CACHED [5/6] RUN pipenv install --system --deploy           0.0s\n",
    " => [6/6] COPY [ lambda_function.py, model.py, ./ ]             0.0s\n",
    " => exporting to image                                          0.0s\n",
    " => => exporting layers                                         0.0s\n",
    " => => writing image sha256:26e91ec8b6a57ba80437dc8ee278c92dfd  0.0s\n",
    " => => naming to docker.io/library/stream-model-duration:v2     0.0s\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it --rm -p 8080:8080 --env-file .env stream-model-duration:v2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "24 Jul 2022 02:31:10,656 [INFO] (rapid) exec '/var/runtime/bootstrap' (cwd=/var/task, handler=)\n",
    "24 Jul 2022 02:31:14,705 [INFO] (rapid) extensionsDisabledByLayer(/opt/disable-extensions-jwigqn8j) -> stat /opt/disable-extensions-jwigqn8j: no such file or directory\n",
    "24 Jul 2022 02:31:14,707 [WARNING] (rapid) Cannot list external agents error=open /opt/extensions: no such file or directory\n",
    "START RequestId: aa21ad77-9ae1-49bc-a7d2-a7bfa3e42266 Version: $LATEST\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this uses a `.env` file for defining environmental variables:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# .env\n",
    "RUN_ID=f4e2242a53a3410d89c061d1958ae70a\n",
    "TEST_RUN=True\n",
    "PREDICTIONS_STREAM_NAME=ride_predictions\n",
    "AWS_PROFILE=mlops\n",
    "AWS_DEFAULT_REGION=us-east-1\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing prediction using the following script:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_docker.py\n",
    "import requests\n",
    "\n",
    "event = {\n",
    "    \"Records\": [\n",
    "        {\n",
    "            \"kinesis\": {\n",
    "                \"kinesisSchemaVersion\": \"1.0\",\n",
    "                \"partitionKey\": \"1\",\n",
    "                \"sequenceNumber\": \"49630706038424016596026506533782471779140474214180454402\",\n",
    "                \"data\": \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\",\n",
    "                \"approximateArrivalTimestamp\": 1655944485.718\n",
    "            },\n",
    "            \"eventSource\": \"aws:kinesis\",\n",
    "            \"eventVersion\": \"1.0\",\n",
    "            \"eventID\": \"shardId-000000000000:49630706038424016596026506533782471779140474214180454402\",\n",
    "            \"eventName\": \"aws:kinesis:record\",\n",
    "            \"invokeIdentityArn\": \"arn:aws:iam::241297376613:role/lambda-kinesis-role\",\n",
    "            \"awsRegion\": \"us-east-1\",\n",
    "            \"eventSourceARN\": \"arn:aws:kinesis:us-east-1:241297376613:stream/ride_events\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "    response = requests.post(url, json=event)\n",
    "    print(response.json())\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `python test_docker.py` on the terminal. Looks like the lambda function is still working inside the container. That is, it can do download the model from S3, decode the input data, and make a prediction that is exposed in the lambda container. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pipenv run python test_docker.py\n",
    "{\n",
    "    'predictions': [\n",
    "        {\n",
    "            'model': 'ride_duration_prediction_model', \n",
    "            'version': 'f4e2242a53a3410d89c061d1958ae70a', \n",
    "            'prediction': {\n",
    "                'ride_duration': 18.210770674183355, \n",
    "                'ride_id': 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this isn't yet a proper test, i.e. we just printed something and checked the print if it looked correct. In the next section, we change this into something that can be automated with `pytest`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences with DeepDiff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get fine-grained control over the differences between JSON outputs, we install a dev dependency called [DeepDiff](https://zepworks.com/deepdiff/current/index.html). This library works for any two Python objects, so this can be a really useful tool to use with the pytest library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pipenv install --dev deepdiff\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying our `test_docker.py` script to simulate change, also adding an `assert` to trigger an exception:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# test_docker.py\n",
    "...\n",
    "\n",
    "url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "actual_response = requests.post(url, json=event).json()\n",
    "\n",
    "print('actual response:')\n",
    "print(json.dumps(actual_response, indent=4))\n",
    "\n",
    "expected_response = {\n",
    "    'predictions': [\n",
    "        {\n",
    "            'model': 'ride_duration_prediction_model', \n",
    "            'version': 'f4e2242a53a3410d89c061d1958ae70a', \n",
    "            'prediction': {\n",
    "                'ride_duration': 18.0,  # <-\n",
    "                'ride_id': 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "diff = DeepDiff(actual_response, expected_response)\n",
    "print('\\ndiff:')\n",
    "print(json.dumps(diff, indent=4))\n",
    "\n",
    "assert len(diff) == 0\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this we get:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python test_docker.py\n",
    "actual response:\n",
    "{\n",
    "    \"predictions\": [\n",
    "        {\n",
    "            \"model\": \"ride_duration_prediction_model\",\n",
    "            \"version\": \"f4e2242a53a3410d89c061d1958ae70a\",\n",
    "            \"prediction\": {\n",
    "                \"ride_duration\": 18.210770674183355,\n",
    "                \"ride_id\": 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "diff:\n",
    "{\n",
    "    \"values_changed\": {\n",
    "        \"root['predictions'][0]['prediction']['ride_duration']\": {\n",
    "            \"new_value\": 18.210770674183355,\n",
    "            \"old_value\": 18.0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/particle1331/code/ok-transformer/docs/nb/mlops/06-best-practices/code/integration-test/test_docker.py\", line 52, in <module>\n",
    "    assert len(diff) == 1\n",
    "AssertionError\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is indicated precisely where in the passed object did the values change, i.e. from `18.0` to `18.210[...]` in `root['predictions'][0]['prediction']['ride_duration']`. For numeric values, e.g. predictions, we can pass `math_epsilon=0.1` in `DeepDiff` which compares numbers with `lambda x, y: math.isclose(x, y, abs_tol=0.1)`. See [docs](https://zepworks.com/deepdiff/current/index.html) for more options."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a local model for testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to test whether our container is able to make predictions, we want to have the option of using a local model. Note that everything should still work since we write the code in such a way that everything is the same except for the particular model path. Also, the accuracy of the model is not an issue since that is tested elsewhere (e.g. before staging). \n",
    "\n",
    "First, we copy the contents of an MLflow artifacts folder into `integration-test/model/` as shown:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/model-contents.png\n",
    "---\n",
    "width: 20em\n",
    "---\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are artifacts of a different MLflow run than what we have been loading from S3. Refactoring the code a bit to use `model_location` and `model_version` which are now more general. All environmental variables are loaded in the `lambda_function` script which is sort of our main file:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`lambda_function.py`](https://github.com/particle1331/ok-transformer/blob/175e9ce8dd2f8038be36a2f9f1b8e920d7e84c94/docs/nb/mlops/06-best-practices/code/lambda_function.py)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# lambda_function.py\n",
    "\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "MODEL_LOCATION = os.getenv('MODEL_LOCATION')\n",
    "MODEL_BUCKET = os.getenv('MODEL_BUCKET', 'mlflow-models-ron')\n",
    "EXPERIMENT_ID = os.getenv('MLFLOW_EXPERIMENT_ID', '1')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "\n",
    "if MODEL_LOCATION is None:\n",
    "    logged_model = f's3://{MODEL_BUCKET}/{EXPERIMENT_ID}/{RUN_ID}/artifacts/model'\n",
    "    model_version = RUN_ID\n",
    "else:\n",
    "    model_location = MODEL_LOCATION\n",
    "    model_version = 'localtest'\n",
    "\n",
    "\n",
    "model_service = model.init(\n",
    "    predictions_stream_name=PREDICTIONS_STREAM_NAME,\n",
    "    model_location=model_location,\n",
    "    model_version=model_version,\n",
    "    test_run=TEST_RUN,\n",
    ")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    return model_service.lambda_handler(event)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce the `model_location` variable which is either an S3 path or a local path. Model version depends on whether the model comes from local disk or from S3. All functions are modified accordingly, such as `model.init` which we look at below. Note that `load_model` now just abstracts the load script from MLflow, instead of constructing the path. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`model.py`](https://github.com/particle1331/ok-transformer/blob/175e9ce8dd2f8038be36a2f9f1b8e920d7e84c94/docs/nb/mlops/06-best-practices/code/model.py)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "def load_model(model_location):\n",
    "    \"\"\"Load MLflow model from path.\"\"\"\n",
    "    model =  mlflow.pyfunc.load_model(model_location)    \n",
    "    return model\n",
    "\n",
    "...\n",
    "\n",
    "def init(\n",
    "        predictions_stream_name: str, \n",
    "        model_location: str,   # <-\n",
    "        model_version: str,    # <-\n",
    "        test_run: bool\n",
    "    ):\n",
    "    \"\"\"Initialize model_service for lambda_function module.\"\"\"\n",
    "\n",
    "    model = load_model(model_location)   # <-\n",
    "    \n",
    "    ...\n",
    "\n",
    "    model_service = ModelService(\n",
    "        model=model, \n",
    "        model_version=model_version,     # <-\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Dockerfile will not change, but we will mount the local `model` folder to the container while it is running. The following script will be executed inside the `integation-test` folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -t stream-model-duration:v2 .\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it --rm \\\n",
    "    -p 8080:8080 \\\n",
    "    --env-file .env \\\n",
    "    -v $(pwd)/model:/app/model \\\n",
    "    stream-model-duration:v2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that model location is relative to the container, not the dev environment:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# integration-test/.env\n",
    "MODEL_LOCATION=/app/model\n",
    "RUN_ID=f4e2242a53a3410d89c061d1958ae70a\n",
    "EXPERIMENT_ID=1\n",
    "TEST_RUN=True\n",
    "AWS_PROFILE=mlops\n",
    "AWS_DEFAULT_REGION=us-east-1\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a different model so we have to modify the expected response with the new prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2536313889\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = 'code/integration-test/model/model.pkl'\n",
    "model = joblib.load(model_path)\n",
    "expected_features = {\n",
    "    'PU_DO': '130_205',\n",
    "    'trip_distance': 3.66,\n",
    "}\n",
    "\n",
    "print(f'{model.predict(expected_features)[0]:.10f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying accordingly:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`test_docker.py`](https://github.com/particle1331/ok-transformer/blob/175e9ce8dd2f8038be36a2f9f1b8e920d7e84c94/docs/nb/mlops/06-best-practices/code/integration-test/test_docker.py)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# integration_test/test_docker.py\n",
    "...\n",
    "\n",
    "expected_response = {\n",
    "    'predictions': [\n",
    "        {\n",
    "            'model': 'ride_duration_prediction_model', \n",
    "            'version': 'localtest',                 # <-\n",
    "            'prediction': {\n",
    "                'ride_duration': 18.2536313889,     # <-\n",
    "                'ride_id': 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "diff = DeepDiff(expected_response, actual_response, math_epsilon=1e-7)   # <-\n",
    "print('\\ndiff:')\n",
    "print(json.dumps(diff, indent=4))\n",
    "\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the container test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual response:\n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"model\": \"ride_duration_prediction_model\",\n",
      "            \"version\": \"localtest\",\n",
      "            \"prediction\": {\n",
      "                \"ride_duration\": 18.25363138888259,\n",
      "                \"ride_id\": 123\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "diff:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "!python code/integration-test/test_docker.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if unit tests are still working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
      "rootdir: /Users/particle1331/code/ok-transformer/docs/nb/mlops/06-best-practices\n",
      "plugins: anyio-3.5.0\n",
      "collected 4 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "code/tests/model_test.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 1.50s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest code/tests . "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating the test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we have to build the Docker image, run it, and run the test script. In this section, we will automate this process completely with a simple script. But we want to change the run script to `docker-compose` because it would be easier to track all these configuration in a `.yml` file:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# integration-test/docker-compose.yml\n",
    "services:\n",
    "  backend:\n",
    "    image: ${LOCAL_IMAGE_NAME}\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    environment:\n",
    "      - PREDICTIONS_STREAM_NAME=ride_predictions\n",
    "      - TEST_RUN=True\n",
    "      - AWS_DEFAULT_REGION=us-east-1\n",
    "      - MODEL_LOCATION=/app/model\n",
    "    volumes:\n",
    "      - \"./model:/app/model\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing now with our script `integration-test/run.sh`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "cd \"$(dirname \"$0\")\"\n",
    "\n",
    "export LOCAL_TAG=`date +\"%Y-%m-%d-%H-%M\"`\n",
    "export LOCAL_IMAGE_NAME=\"stream-model-duration:${LOCAL_TAG}\"\n",
    "\n",
    "docker build -t ${LOCAL_IMAGE_NAME} ..\n",
    "\n",
    "docker-compose up -d\n",
    "\n",
    "sleep 1\n",
    "\n",
    "pipenv run python test_docker.py\n",
    "\n",
    "docker-compose down\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line ensures that this runs in `bash`. Then, it will change directory to the same directory as `test_docker.py`. It will go one level up to build the Docker image. Next, the script executes `docker-compose up -d`. This runs the Docker image with `${LOCAL_IMAGE_NAME}` in detached mode. Otherwise, it will just keep running in the terminal and the next commands will not push through. It's a good idea to give the terminal some time after starting the Docker container, so we execute `sleep 1`. Then, we run our container test script. Finally, we remove the resources with `docker-compose down`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the script:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ sh run.sh\n",
    "[+] Building 0.4s (11/11) FINISHED\n",
    " => [internal] load build definition from Dockerfile            0.0s\n",
    " => => transferring dockerfile: 37B                             0.0s\n",
    " => [internal] load .dockerignore                               0.0s\n",
    " => => transferring context: 2B                                 0.0s\n",
    " => [internal] load metadata for public.ecr.aws/lambda/python:  0.3s\n",
    " => [internal] load build context                               0.0s\n",
    " => => transferring context: 128B                               0.0s\n",
    " => [1/6] FROM public.ecr.aws/lambda/python:3.9@sha256:3dda276  0.0s\n",
    " => CACHED [2/6] RUN pip install -U pip                         0.0s\n",
    " => CACHED [3/6] RUN pip install pipenv                         0.0s\n",
    " => CACHED [4/6] COPY [ Pipfile, Pipfile.lock, ./ ]             0.0s\n",
    " => CACHED [5/6] RUN pipenv install --system --deploy           0.0s\n",
    " => CACHED [6/6] COPY [ lambda_function.py, model.py, ./ ]      0.0s\n",
    " => exporting to image                                          0.0s\n",
    " => => exporting layers                                         0.0s\n",
    " => => writing image sha256:ce4bdf23e33a8cd20e3d0906ac71f92470  0.0s\n",
    " => => naming to docker.io/library/stream-model-duration:2022-  0.0s\n",
    "[+] Running 2/2\n",
    " â ¿ Network integration-test_default      Created                0.0s\n",
    " â ¿ Container integration-test-backend-1  Started                0.4s\n",
    "Loading .env environment variables...\n",
    "actual response:\n",
    "{\n",
    "    \"predictions\": [\n",
    "        {\n",
    "            \"model\": \"ride_duration_prediction_model\",\n",
    "            \"version\": \"localtest\",\n",
    "            \"prediction\": {\n",
    "                \"ride_duration\": 18.253631388882592,\n",
    "                \"ride_id\": 123\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "diff:\n",
    "{}\n",
    "[+] Running 2/1\n",
    " â ¿ Container integration-test-backend-1  Removed                0.4s\n",
    " â ¿ Network integration-test_default      Removed                0.0s\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we also change the container tag to the current date and time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY              TAG                IMAGE ID       CREATED       SIZE\n",
      "stream-model-duration   2022-07-25-20-03   ce4bdf23e33a   3 hours ago   1.34GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning error codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error codes of previous executed commands can obtained in bash using `$?`. This can be used in CI/CD pipelines. But here we will use it to indicate that our integration test failed. The error code of the integration test can be stored as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`run.sh`](https://github.com/particle1331/ok-transformer/blob/e6acea4021340efeef3704f3ce4a8ad90a66a7f8/docs/nb/mlops/06-best-practices/code/integration-test/run.sh#L14-L24)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "...\n",
    "\n",
    "pipenv run python test_docker.py\n",
    "\n",
    "ERROR_CODE=$?\n",
    "\n",
    "if [ ${ERROR_CODE} != 0 ]; then\n",
    "    docker-compose logs\n",
    "fi\n",
    "\n",
    "docker-compose down\n",
    "\n",
    "exit ${ERROR_CODE}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line returns the error code to the terminal. Testing this with the current tests will return error code `0`. Failing the test will result in an error code of `1`. This can be used in a CI/CD job resulting in a failed job and we can return the logs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Testing cloud services with LocalStack -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Recall that since we set `TEST_RUN=True`, we are not testing the part of the code that writes to a Kinesis stream. And because we changed the code, it might not be working at this point. In this section, we will look at how we can test AWS services, such as S3 and Kinesis, even without using an AWS account. This thing will work completely locally and should be useful for testing and developing cloud services without having to wait on cloud resources. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- For this we will use [LocalStack](https://github.com/localstack/localstack). From the project page it is claimed that LocalStack provides a fully functional local AWS cloud stack for developing and testing your cloud & Serverless apps offline. This should be really useful for us. To start LocalStack with Docker: -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ```bash\n",
    "docker run --rm -it -p 4566:4566 -p 4510-4559:4510-4559 localstack/localstack\n",
    "``` -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Kinesis with LocalStack can be added to our `docker-compose.yml` file as follows: -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ```\n",
    "# docker-compose.yml -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code quality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will talk about code quality. Specifically, we talk about **linting** and **code formatting**. Previously, we already covered code quality, but in the point of view of reliability. That code is doing what it is supposed to do. Now we want to talk about the readability as well as code quality. This is also related to maintainability of the code base. \n",
    "\n",
    "For static code analysis, i.e. detecting code smells, we will use [pylint](https://pylint.pycqa.org/en/latest/). And for code formatting, or styling, we will be using [Black](https://black.readthedocs.io/en/stable/). Both of these tools adhere to PEP 8, the Python style guide. Finally, we will use [isort](https://pycqa.github.io/isort/) for ordering our imports."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's run `pylint` for all files in the `code/` directory to see what it outputs:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "$ pylint --recursive=y .\n",
    "************* Module model\n",
    "model.py:12:53: C0303: Trailing whitespace (trailing-whitespace)\n",
    "model.py:50:0: C0303: Trailing whitespace (trailing-whitespace)\n",
    "model.py:53:0: C0303: Trailing whitespace (trailing-whitespace)\n",
    "...\n",
    "model.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
    "model.py:16:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
    "model.py:22:0: C0115: Missing class docstring (missing-class-docstring)\n",
    "model.py:29:4: C0116: Missing function or method docstring (missing-function-docstring)\n",
    "model.py:31:28: C0209: Formatting a regular string which could be a f-string (consider-using-f-string)\n",
    "...\n",
    "model.py:74:0: C0115: Missing class docstring (missing-class-docstring)\n",
    "model.py:80:4: C0116: Missing function or method docstring (missing-function-docstring)\n",
    "model.py:74:0: R0903: Too few public methods (1/2) (too-few-public-methods)\n",
    "model.py:4:0: C0411: standard import \"import base64\" should be placed before \"import boto3\" (wrong-import-order)\n",
    "model.py:1:0: W0611: Unused import os (unused-import)\n",
    "model.py:6:0: W0611: Unused import joblib (unused-import)\n",
    "************* Module lambda_function\n",
    "lambda_function.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
    "lambda_function.py:18:4: C0103: Constant name \"model_version\" doesn't conform to UPPER_CASE naming style (invalid-name)\n",
    "lambda_function.py:29:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
    "lambda_function.py:29:26: W0613: Unused argument 'context' (unused-argument)\n",
    "lambda_function.py:2:0: C0411: standard import \"import os\" should be placed before \"import model\" (wrong-import-order)\n",
    "************* Module tests.model_test\n",
    "tests/model_test.py:6:26: C0303: Trailing whitespace (trailing-whitespace)\n",
    "tests/model_test.py:24:0: C0303: Trailing whitespace (trailing-whitespace)\n",
    "tests/model_test.py:35:0: C0301: Line too long (245/100) (line-too-long)\n",
    "tests/model_test.py:36:0: C0303: Trailing whitespace (trailing-whitespace)\n",
    "...\n",
    "tests/model_test.py:8:22: C0103: Argument name \"X\" doesn't conform to snake_case naming style (invalid-name)\n",
    "tests/model_test.py:9:8: C0103: Variable name \"n\" doesn't conform to snake_case naming style (invalid-name)\n",
    "tests/model_test.py:4:0: R0903: Too few public methods (1/2) (too-few-public-methods)\n",
    "tests/model_test.py:33:0: C0116: Missing function or method docstring (missing-function-docstring)\n",
    "...\n",
    "************* Module test_docker\n",
    "integration-test/test_docker.py:14:0: C0301: Line too long (251/100) (line-too-long)\n",
    "integration-test/test_docker.py:19:0: C0301: Line too long (103/100) (line-too-long)\n",
    "integration-test/test_docker.py:38:54: C0303: Trailing whitespace (trailing-whitespace)\n",
    "integration-test/test_docker.py:1:0: C0114: Missing module docstring (missing-module-docstring)\n",
    "integration-test/test_docker.py:29:0: C0103: Constant name \"url\" doesn't conform to UPPER_CASE naming style (invalid-name)\n",
    "\n",
    "-----------------------------------\n",
    "Your code has been rated at 5.56/10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that it has a bunch of rules, for example, no trailing whitespaces. These are whitespaces at the end of each line. Missing docstrings are also flagged. Another recommendation is to use f-strings instead of `.format` for string formatting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/trailing-whitespace.png\n",
    "---\n",
    "width: 38em\n",
    "---\n",
    "Pylint flags trailing whitespace at line 12, after column 53, of `model.py`. \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something more convenient in VS Code is to `CMD+SHIFT+P` and `Python: Select Linter` to get warnings on the UI level. This is easier than reading through the above output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/pylint-warnings.png\n",
    "---\n",
    "width: 38em\n",
    "---\n",
    "Highlighted warnings in VS Code along with an explanation from pylint.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these errors we don't really care about. So we can actually configure pylint using `pyproject.toml`. See here for all [pylint messages](https://pylint.pycqa.org/en/latest/user_guide/messages/messages_overview.html). Messages that we don't care about can also be copied from the above output (e.g. `too-few-public-methods` or `invalid-name` for variables `X` and `n` which are fine for machine learning applications)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```toml\n",
    "# pyproject.toml\n",
    "\n",
    "[tool.pylint.messages_control]\n",
    "max-line-length = 88\n",
    "disable = [\n",
    "  \"missing-docstring\",\n",
    "  \"unused-argument\",\n",
    "  \"missing-class-docstring\",\n",
    "  \"missing-function-docstring\",\n",
    "  \"invalid-name\",\n",
    "]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running pylint again. Note that score improves:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "â¯ pylint --recursive=y .\n",
    "************* Module /Users/particle1331/code/ok-transformer/docs/nb/mlops/06-best-practices/code/pyproject.toml\n",
    "pyproject.toml:1:0: W0012: Unknown option value for '--disable', expected a valid pylint message and got 'final-newline' (unknown-option-value)\n",
    "************* Module model\n",
    "model.py:12:53: C0303: Trailing whitespace (trailing-whitespace)\n",
    "...\n",
    "model.py:31:28: C0209: Formatting a regular string which could be a f-string (consider-using-f-string)\n",
    "model.py:4:0: C0411: standard import \"import base64\" should be placed before \"import boto3\" (wrong-import-order)\n",
    "model.py:1:0: W0611: Unused import os (unused-import)\n",
    "model.py:6:0: W0611: Unused import joblib (unused-import)\n",
    "************* Module lambda_function\n",
    "lambda_function.py:18:4: C0103: Constant name \"model_version\" doesn't conform to UPPER_CASE naming style (invalid-name)\n",
    "lambda_function.py:2:0: C0411: standard import \"import os\" should be placed before \"import model\" (wrong-import-order)\n",
    "************* Module tests.model_test\n",
    "tests/model_test.py:6:26: C0303: Trailing whitespace (trailing-whitespace)\n",
    "tests/model_test.py:24:0: C0303: Trailing whitespace (trailing-whitespace)\n",
    "tests/model_test.py:35:0: C0301: Line too long (245/88) (line-too-long)\n",
    "...\n",
    "tests/model_test.py:8:22: C0103: Argument name \"X\" doesn't conform to snake_case naming style (invalid-name)\n",
    "tests/model_test.py:9:8: C0103: Variable name \"n\" doesn't conform to snake_case naming style (invalid-name)\n",
    "************* Module test_docker\n",
    "integration-test/test_docker.py:13:0: C0301: Line too long (93/88) (line-too-long)\n",
    "...\n",
    "integration-test/test_docker.py:38:54: C0303: Trailing whitespace (trailing-whitespace)\n",
    "integration-test/test_docker.py:29:0: C0103: Constant name \"url\" doesn't conform to UPPER_CASE naming style (invalid-name)\n",
    "\n",
    "------------------------------------------------------------------\n",
    "Your code has been rated at 7.01/10 (previous run: 5.64/10, +1.37)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to suppress messages for specific parts of the code, we can use the following:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "class KinesisCallback:\n",
    "    # pylint: disable=too-few-public-methods\n",
    "\n",
    "    def __init__(self, kinesis_client, predictions_stream_name):\n",
    "        self.kinesis_client = kinesis_client\n",
    "        self.predictions_stream_name = predictions_stream_name\n",
    "\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `line-too-long` for base 64 inputs, we define the following function which is used to read `data.b64` which stores the encoded string. Note that pylint catches error of failing to specify the encoding. This is actually useful since not specifying the encoding can fail in Linux systems.\n",
    "\n",
    "```python\n",
    "# model.py\n",
    "...\n",
    "\n",
    "def read_text(file):\n",
    "    test_directory = pathlib.Path(__file__).parent\n",
    "    with open(test_directory / file, 'rt', encoding='utf-8') as f_in:\n",
    "        return f_in.read().strip()\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for `integration-test/test_docker.py`, we save and load the `event` from an `event.json` file. After all of these changes, and removing unused imports, running `pylint --recursive=y .` gives a score of `8.10/10`. The messages that are left are all regarding whitespaces and import ordering. For these, we will use an tools for automatic code formatting and import sorter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view changes that are not yet applied we can use the following command:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "â¯ black --diff model.py\n",
    "--- model.py\t2022-07-29 20:16:30.129099 +0000\n",
    "+++ model.py\t2022-07-29 20:26:13.503436 +0000\n",
    "@@ -5,106 +5,101 @@\n",
    " import mlflow\n",
    "\n",
    "\n",
    " def load_model(model_location):\n",
    "     \"\"\"Load MLflow model from path.\"\"\"\n",
    "-    model =  mlflow.pyfunc.load_model(model_location)\n",
    "+    model = mlflow.pyfunc.load_model(model_location)\n",
    "     return model\n",
    "\n",
    "\n",
    " def base64_decode(encoded_data):\n",
    "-    decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "+    decoded_data = base64.b64decode(encoded_data).decode(\"utf-8\")\n",
    "     ride_event = json.loads(decoded_data)\n",
    "     return ride_event\n",
    "\n",
    "\n",
    " class ModelService:\n",
    "-\n",
    "     def __init__(self, model, model_version, callbacks=None):\n",
    "         self.model = model\n",
    "         self.model_version = model_version\n",
    "         self.callbacks = callbacks or []\n",
    "\n",
    "     def prepare_features(self, ride):\n",
    "         features = {}\n",
    "-        features['PU_DO'] = f\"{ride['PULocationID']}_{ride['DOLocationID']}\"\n",
    "-        features['trip_distance'] = ride['trip_distance']\n",
    "+        features[\"PU_DO\"] = f\"{ride['PULocationID']}_{ride['DOLocationID']}\"\n",
    "+        features[\"trip_distance\"] = ride[\"trip_distance\"]\n",
    "         return features\n",
    "\n",
    "     def predict(self, features):\n",
    "         pred = self.model.predict(features)\n",
    "         return float(pred[0])\n",
    "\n",
    "-\n",
    "     def lambda_handler(self, event):\n",
    "\n",
    "         predictions_events = []\n",
    "\n",
    "-        for record in event['Records']:\n",
    "-            encoded_data = record['kinesis']['data']\n",
    "+        for record in event[\"Records\"]:\n",
    "+            encoded_data = record[\"kinesis\"][\"data\"]\n",
    "             ride_event = base64_decode(encoded_data)\n",
    "\n",
    "-            ride = ride_event['ride']\n",
    "-            ride_id = ride_event['ride_id']\n",
    "-\n",
    "+            ride = ride_event[\"ride\"]\n",
    "+            ride_id = ride_event[\"ride_id\"]\n",
    "+\n",
    "             features = self.prepare_features(ride)\n",
    "             prediction = self.predict(features)\n",
    "-\n",
    "+\n",
    "             prediction_event = {\n",
    "-                'model': 'ride_duration_prediction_model',\n",
    "-                'version': self.model_version,\n",
    "-                'prediction': {\n",
    "-                    'ride_duration': prediction,\n",
    "-                    'ride_id': ride_id,\n",
    "-                }\n",
    "+                \"model\": \"ride_duration_prediction_model\",\n",
    "+                \"version\": self.model_version,\n",
    "+                \"prediction\": {\n",
    "+                    \"ride_duration\": prediction,\n",
    "+                    \"ride_id\": ride_id,\n",
    "+                },\n",
    "             }\n",
    "\n",
    "             for callback in self.callbacks:\n",
    "                 callback(prediction_event)\n",
    "-\n",
    "+\n",
    "             predictions_events.append(prediction_event)\n",
    "\n",
    "-\n",
    "-        return {\n",
    "-            'predictions': predictions_events\n",
    "-        }\n",
    "+        return {\"predictions\": predictions_events}\n",
    "\n",
    "\n",
    " class KinesisCallback:\n",
    "     # pylint: disable=too-few-public-methods\n",
    "\n",
    "     def __init__(self, kinesis_client, predictions_stream_name):\n",
    "         self.kinesis_client = kinesis_client\n",
    "         self.predictions_stream_name = predictions_stream_name\n",
    "\n",
    "     def put_record(self, prediction_event):\n",
    "-        ride_id = prediction_event['prediction']['ride_id']\n",
    "+        ride_id = prediction_event[\"prediction\"][\"ride_id\"]\n",
    "         self.kinesis_client.put_record(\n",
    "             StreamName=self.predictions_stream_name,\n",
    "             Data=json.dumps(prediction_event),\n",
    "-            PartitionKey=str(ride_id)\n",
    "+            PartitionKey=str(ride_id),\n",
    "         )\n",
    "\n",
    "\n",
    " def init(\n",
    "-        predictions_stream_name: str,\n",
    "-        model_location: str,\n",
    "-        model_version: str,\n",
    "-        test_run: bool\n",
    "-    ):\n",
    "+    predictions_stream_name: str,\n",
    "+    model_location: str,\n",
    "+    model_version: str,\n",
    "+    test_run: bool,\n",
    "+):\n",
    "     \"\"\"Initialize model_service for lambda_function module.\"\"\"\n",
    "\n",
    "     model = load_model(model_location)\n",
    "-\n",
    "+\n",
    "     callbacks = []\n",
    "     if not test_run:\n",
    "-        kinesis_client = boto3.client('kinesis')\n",
    "+        kinesis_client = boto3.client(\"kinesis\")\n",
    "         kinesis_callback = KinesisCallback(kinesis_client, predictions_stream_name)\n",
    "         callbacks.append(kinesis_callback.put_record)\n",
    "\n",
    "     model_service = ModelService(\n",
    "-        model=model,\n",
    "-        model_version=model_version,\n",
    "+        model=model,\n",
    "+        model_version=model_version,\n",
    "         callbacks=callbacks,\n",
    "     )\n",
    "-\n",
    "+\n",
    "     return model_service\n",
    "would reformat model.py\n",
    "\n",
    "All done! âœ¨ ðŸ° âœ¨\n",
    "1 file would be reformatted.\n",
    "````\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this mostly involve replacing single quotes with double quotes, adding trailing commas to last items, and removing whitespaces. This looks fine so let's apply it:\n",
    "\n",
    "```bash\n",
    "$ black model.py\n",
    "reformatted model.py\n",
    "\n",
    "All done! âœ¨ ðŸ° âœ¨\n",
    "1 file reformatted.\n",
    "$ git status\n",
    "On branch mlops\n",
    "Your branch is up to date with 'origin/mlops'.\n",
    "\n",
    "Changes not staged for commit:\n",
    "  (use \"git add <file>...\" to update what will be committed)\n",
    "  (use \"git restore <file>...\" to discard changes in working directory)\n",
    "\tmodified:   model.py\n",
    "\n",
    "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/black-changes.png\n",
    "---\n",
    "width: 45em\n",
    "---\n",
    "Changes in `model.py` after using `black`. \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For black to not single quotes we can use the flag `-S` or `--skip-string-normalization`. Note that if we want black to not convert manually multi-line formatted dictionaries to one-liners we can add a trailing comma on the last item. Or we can add this in the `pyproject.toml` for black:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```toml\n",
    "# pyproject.toml\n",
    "...\n",
    "\n",
    "[tool.black]\n",
    "line-length = 88\n",
    "target-version = ['py39']\n",
    "skip-string-normalization = true\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running pylint again shows that we only have import ordering left:\n",
    "\n",
    "```bash\n",
    "$ pylint --recursive=y .\n",
    "************* Module model\n",
    "model.py:3:0: C0411: standard import \"import base64\" should be placed before \"import boto3\" (wrong-import-order)\n",
    "************* Module lambda_function\n",
    "lambda_function.py:2:0: C0411: standard import \"import os\" should be placed before \"import model\" (wrong-import-order)\n",
    "************* Module tests.model_test\n",
    "tests/model_test.py:2:0: C0411: standard import \"import pathlib\" should be placed before \"import model\" (wrong-import-order)\n",
    "\n",
    "------------------------------------------------------------------\n",
    "Your code has been rated at 9.75/10 (previous run: 9.75/10, +0.00)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will use isort. The following configuration sorts imports in increasing length, for readability. Here `multi_line_output = 3` is the familiar convention where break imports into multiple lines by means of parentheses (see [here](https://pycqa.github.io/isort/docs/configuration/multi_line_output_modes.html#3-vertical-hanging-indent)).\n",
    "\n",
    "```toml\n",
    "# pyproject.toml\n",
    "...\n",
    "\n",
    "[tool.isort]\n",
    "multi_line_output = 3\n",
    "length_sort = true\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running isort and pylint now:\n",
    "\n",
    "```bash\n",
    "$ isort .\n",
    "Fixing code/model.py\n",
    "Fixing code/lambda_function.py\n",
    "Fixing code/tests/model_test.py\n",
    "Fixing code/integration-test/test_docker.py\n",
    "$ pylint --recursive=y .\n",
    "\n",
    "-------------------------------------------------------------------\n",
    "Your code has been rated at 10.00/10 (previous run: 9.75/10, +0.25)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git pre-commit hooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about the tools discussed in the previous section is that these can all be run automatically. For example, in the following order. In this section, we will see how to do this using **pre-commit hooks**.\n",
    "\n",
    "```bash\n",
    "isort .\n",
    "black .\n",
    "pylint --recursive=y .\n",
    "pytest tests/\n",
    "sh integration-test/run.sh\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makefiles and make"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('06-best-practices-x7NRfZPQ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1b699a8819a62dafef9731c86e973af25e5f38384875608f63366144800428d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
