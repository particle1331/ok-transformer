
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Activation Functions &#8212; ùó¶ùòÅùó≤ùó≤ùóΩùó≤ùòÄùòÅ ùóîùòÄùó∞ùó≤ùóªùòÅ ‚õ∞Ô∏è</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/loss_surface.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Developing a RESTful API" href="fastapi/ch3.html" />
    <link rel="prev" title="Introduction to PyTorch" href="pytorch-intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/loss_surface.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ùó¶ùòÅùó≤ùó≤ùóΩùó≤ùòÄùòÅ ùóîùòÄùó∞ùó≤ùóªùòÅ ‚õ∞Ô∏è</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  FUNDAMENTALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="house-prices.html">
   Pipelines in Scikit-Learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="blending-stacking.html">
   Blending and Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optuna.html">
   Hyperparameter Tuning with Optuna
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="backpropagation.html">
   Backpropagation on DAGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="seb3/tensorflow-nn.html">
   Neural Networks with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="seb3/tensorflow-mechanics.html">
   Mechanics of TensorFlow
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  PYTORCH TUTORIALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pytorch-intro.html">
   Introduction to PyTorch
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Activation Functions
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  REST APIs with FASTAPI
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fastapi/ch3.html">
   Developing a RESTful API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fastapi/ch4.html">
   Managing Pydantic Data Models
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/pytorch-activation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/particle1331/steepest-ascent/issues/new?title=Issue%20on%20page%20%2Fnotebooks/pytorch-activation.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/particle1331/steepest-ascent/master?urlpath=tree/docs/notebooks/pytorch-activation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#common-activation-functions">
   Common activation functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-functions-graphs">
     Activation functions graphs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysing-the-effect-of-activation-functions">
   Analysing the effect of activation functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup">
     Setup
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradient-flow-after-initialization">
     Gradient flow after initialization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#saving-and-loading-a-model">
     Saving and loading a model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-a-model">
     Training a model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-distribution">
     Activation distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#measuring-dead-neurons-in-relu-networks">
     Measuring dead neurons in ReLU networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix-downloading-pretrained-models">
   Appendix: Downloading pretrained models
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="activation-functions">
<h1>Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¬∂</a></h1>
<div class="admonition-attribution admonition">
<p class="admonition-title">Attribution</p>
<p>This notebook is based on <a class="reference external" href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial3/Activation_Functions.html">Tutorial 3</a> of the <a class="reference external" href="https://uvadlc.github.io/lectures-nov2020.html">Deep Learning Course</a> at the University of Amsterdam. The full list of tutorials can be found <a class="reference external" href="https://uvadlc-notebooks.rtfd.io">here</a>.</p>
</div>
<p>In this tutorial, we will take a closer look at popular activation functions and investigate their effect on optimization properties in neural networks.
Activation functions are a crucial part of deep learning models as they add the non-linearity to neural networks.
There is a great variety of activation functions in the literature, and some are more beneficial than others.
The goal of this tutorial is to show the importance of choosing a good activation function (and how to do so), and what problems might occur if we don‚Äôt.</p>
<p>Before we start, we import our standard libraries and set up basic functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cuda:0
</pre></div>
</div>
</div>
</div>
<p>We will define a function to set a seed on all libraries we might interact with in this tutorial (here <code class="docutils literal notranslate"><span class="pre">numpy</span></code> and <code class="docutils literal notranslate"><span class="pre">torch</span></code>). This allows us to make our training reproducible. However, note that in contrast to the CPU, the same seed on different GPU architectures can give different results. All models here have been trained on a NVIDIA Tesla P100, which is provided free in a Kaggle kernel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Function for setting the seed.&quot;&quot;&quot;</span>
    
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="c1"># Separate seed for GPU</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        
        
<span class="c1"># Set random seed</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">determinstic</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># https://stackoverflow.com/a/58965640</span>
</pre></div>
</div>
</div>
</div>
<p>Additionally, the following cell defines two paths: <code class="docutils literal notranslate"><span class="pre">DATASET_PATH</span></code> and <code class="docutils literal notranslate"><span class="pre">CHECKPOINT_PATH</span></code>. The dataset path is the directory where we will download datasets used in the notebooks. It is recommended to store all datasets from PyTorch in one joined directory to prevent duplicate downloads. The checkpoint path is the directory where we will store trained model weights and additional files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Path to datasets, e.g. MNIST, and path to pretrained models</span>
<span class="n">DATASET_PATH</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/kaggle/working/data&quot;</span><span class="p">)</span> 
<span class="n">CHECKPOINT_PATH</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/kaggle/working/saved_models/tutorial3&quot;</span><span class="p">)</span>

<span class="c1"># Create directories; exists =&gt; skip, no parent =&gt; create</span>
<span class="n">DATASET_PATH</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">CHECKPOINT_PATH</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also define two utility functions for constructing the appropriate file paths.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_get_config_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">model_path</span> <span class="o">/</span> <span class="p">(</span><span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;.config&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_get_model_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">:</span> 
    <span class="k">return</span> <span class="n">model_path</span> <span class="o">/</span> <span class="p">(</span><span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;.tar&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="common-activation-functions">
<h2>Common activation functions<a class="headerlink" href="#common-activation-functions" title="Permalink to this headline">¬∂</a></h2>
<p>As a first step, we will implement some common activation functions by ourselves. Of course, most of them can also be found in the <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> package. However, we‚Äôll write our own functions here for a better understanding and insights.</p>
<p>For an easier time of comparing various activation functions, we start with defining a base class from which all our future modules will inherit. Every activation function will be an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> so that we can integrate them nicely in a network. We will use the <code class="docutils literal notranslate"><span class="pre">config</span></code> dictionary to store adjustable parameters for some activation functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ActivationFunction</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we implement two of the ‚Äúoldest‚Äù activation functions that are still commonly used for various tasks: sigmoid and tanh.
Both the sigmoid and tanh activation can be also found as PyTorch functions (<code class="docutils literal notranslate"><span class="pre">torch.sigmoid</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.tanh</span></code>) or as modules (<code class="docutils literal notranslate"><span class="pre">nn.Sigmoid</span></code>, <code class="docutils literal notranslate"><span class="pre">nn.Tanh</span></code>).
Here, we implement them by hand:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

    
<span class="k">class</span> <span class="nc">Tanh</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">exp_x</span><span class="p">,</span> <span class="n">exp_neg_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">exp_x</span> <span class="o">-</span> <span class="n">exp_neg_x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">exp_x</span> <span class="o">+</span> <span class="n">exp_neg_x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Another popular activation function that has allowed the training of deeper networks, is the <strong>Rectified Linear Unit</strong> or <strong>ReLU</strong>.
Despite its simplicity of being a piecewise linear function, ReLU has one major benefit compared to sigmoid and tanh: a strong, stable gradient for a large range of values.
Based on this idea, a lot of variations of ReLU have been proposed, of which we will implement the following three: <strong>LeakyReLU</strong>, <strong>ELU</strong>, and <strong>Swish</strong>. Modifications on the ReLU improves on zero-centering of outputs, vanishing gradients on negative numbers, and smoothness of gradients around zero.</p>
<p>LeakyReLU replaces the zero settings in the negative part with a smaller slope to allow gradients to flow also in this part of the input.
Similarly, ELU replaces the negative part with an exponential decay.
The third, most recently proposed activation function is Swish, which is actually the result of a large experiment with the purpose of finding the ‚Äúoptimal‚Äù activation function.
Compared to the other activation functions, Swish is both smooth and non-monotonic (i.e. contains a change of sign in the gradient). Moreover, Swish is the only activation in our list which has maximum gradient greater than one.
This has been shown to prevent dead neurons as in standard ReLU activation, especially for deep networks. Let‚Äôs implement the four activation functions below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    
<span class="k">class</span> <span class="nc">LeakyReLU</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

    
<span class="k">class</span> <span class="nc">ELU</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    
<span class="k">class</span> <span class="nc">Swish</span><span class="p">(</span><span class="n">ActivationFunction</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For later usage, we summarize all our activation functions in a dictionary mapping the name to the class object. In case you implement a new activation function by yourself, add it here to include it in future comparisons as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">act_fn_by_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span> <span class="n">Sigmoid</span><span class="p">,</span>
    <span class="s2">&quot;tanh&quot;</span><span class="p">:</span> <span class="n">Tanh</span><span class="p">,</span>
    <span class="s2">&quot;relu&quot;</span><span class="p">:</span> <span class="n">ReLU</span><span class="p">,</span>
    <span class="s2">&quot;leakyrelu&quot;</span><span class="p">:</span> <span class="n">LeakyReLU</span><span class="p">,</span>
    <span class="s2">&quot;elu&quot;</span><span class="p">:</span> <span class="n">ELU</span><span class="p">,</span>
    <span class="s2">&quot;swish&quot;</span><span class="p">:</span> <span class="n">Swish</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="activation-functions-graphs">
<h3>Activation functions graphs<a class="headerlink" href="#activation-functions-graphs" title="Permalink to this headline">¬∂</a></h3>
<p>To get an idea of what each activation function actually does, we will visualize them in the following.
Next to the actual activation value, the gradient of the function is an important aspect as it is crucial for optimizing the neural network.
PyTorch allows us to compute the gradients simply by calling the <code class="docutils literal notranslate"><span class="pre">backward</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_grads</span><span class="p">(</span><span class="n">act_fn</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the gradients of an activation function at specified positions.</span>
<span class="sd">    </span>
<span class="sd">    Inputs:</span>
<span class="sd">        act_fn: An instance of `ActivationFunction` with an implemented forward pass.</span>
<span class="sd">        x: 1D input tensor. </span>
<span class="sd">    Output:</span>
<span class="sd">        A tensor with the same size of x containing the gradients of act_fn at x.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">act_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Trick: ùúï(y1 + y2) / ùúïx1 = ùúïy1 / ùúïx1 =&gt; stored in x1. </span>
    
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can visualize all our activation functions including their gradients:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_act_fn</span><span class="p">(</span><span class="n">act_fn</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    
    <span class="c1"># Run activation function</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">act_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y_grads</span> <span class="o">=</span> <span class="n">get_grads</span><span class="p">(</span><span class="n">act_fn</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Push x, y and gradients back to cpu for plotting</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_grads</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_grads</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="c1"># Plotting</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ActFn&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_grads</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gradient&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">act_fn</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>

<span class="c1"># Initialize activations in a list</span>
<span class="n">act_fns</span> <span class="o">=</span> <span class="p">[</span><span class="n">act_fn</span><span class="p">()</span> <span class="k">for</span> <span class="n">act_fn</span> <span class="ow">in</span> <span class="n">act_fn_by_name</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

<span class="c1"># Plotting</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">act_fns</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">rows</span><span class="o">*</span><span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">act_fn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">act_fns</span><span class="p">):</span>
    <span class="n">visualize_act_fn</span><span class="p">(</span><span class="n">act_fn</span><span class="p">,</span> <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="n">x</span><span class="p">)</span> <span class="c1"># divmod(m, n) = m // n, m % n</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch-activation_22_0.png" src="../_images/pytorch-activation_22_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="analysing-the-effect-of-activation-functions">
<h2>Analysing the effect of activation functions<a class="headerlink" href="#analysing-the-effect-of-activation-functions" title="Permalink to this headline">¬∂</a></h2>
<p>After implementing and visualizing the activation functions, we are aiming to gain insights into their effect.
We do this by using a simple neural network trained on <a class="reference external" href="https://github.com/zalandoresearch/fashion-mnist">FashionMNIST</a> and examine various aspects of the model, including the performance and gradient flow.</p>
<div class="section" id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¬∂</a></h3>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Defining the base network</strong></p>
</div>
<p>Firstly, let‚Äôs set up a neural network. The chosen network views the images as 1D tensors and pushes them through a sequence of linear layers and a specified activation function. Feel free to experiment with other network architectures.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BaseNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">act_fn</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Inputs:</span>
<span class="sd">            act_fn - Object of the activation function that should be used as non-linearity in the network.</span>
<span class="sd">            input_size - Size of the input images in pixels</span>
<span class="sd">            num_classes - Number of classes we want to predict</span>
<span class="sd">            hidden_sizes - A list of integers specifying the hidden layer sizes in the NN</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Create the network based on the specified hidden sizes</span>
        <span class="c1"># Iteratively add linear layer, followed by activation modules</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">hidden_sizes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">)):</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">act_fn</span><span class="p">]</span>
            
        <span class="c1"># Add output layer. Combine modules via nn.Sequential</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Store all hyperparameters in a dictionary for saving and loading of the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;act_fn&quot;</span><span class="p">:</span> <span class="n">act_fn</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> 
            <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="n">input_size</span><span class="p">,</span> 
            <span class="s2">&quot;num_classes&quot;</span><span class="p">:</span> <span class="n">num_classes</span><span class="p">,</span> 
            <span class="s2">&quot;hidden_sizes&quot;</span><span class="p">:</span> <span class="n">hidden_sizes</span>
        <span class="p">}</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Reshape images to a flat vector, i.e. B = x.size(0)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>    
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Understanding the sequential module</strong></p>
</div>
<p>Let us pause for a bit to look at how the <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> works. Observe that <code class="docutils literal notranslate"><span class="pre">nn.Sequential(*layers)</span></code> is the main component of the forward function of <code class="docutils literal notranslate"><span class="pre">BaseNetwork</span></code>. Since the layers consist of linear transformations followed by a non-linearity, <code class="docutils literal notranslate"><span class="pre">BaseNetwork</span></code> basically implements an MLP. Indeed, this works by applying the modules in the list recursively on an input tensor and its subsequent transformations starting with <code class="docutils literal notranslate"><span class="pre">layers[0]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">Sigmoid</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Linear(in_features=784, out_features=512, bias=True)
  (1): Sigmoid()
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): Sigmoid()
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): Sigmoid()
  (6): Linear(in_features=128, out_features=64, bias=True)
  (7): Sigmoid()
  (8): Linear(in_features=64, out_features=64, bias=True)
  (9): Sigmoid()
  (10): Linear(in_features=64, out_features=32, bias=True)
  (11): Sigmoid()
  (12): Linear(in_features=32, out_features=10, bias=True)
)
</pre></div>
</div>
</div>
</div>
<p>From the shape of the linear layers of the network below, we see that <code class="docutils literal notranslate"><span class="pre">net.layers[0]</span></code> is the input layer while <code class="docutils literal notranslate"><span class="pre">net.layers[-1]</span></code> is the output layer. We can check that the forward function works as expected with the following computation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">)):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">j</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>

<span class="nb">print</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">out</span> <span class="o">-</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(True)
</pre></div>
</div>
</div>
</div>
<p>The parameters of the network can be obtained using its <code class="docutils literal notranslate"><span class="pre">named_parameters()</span></code> method. Note that this is properly ordered with the same indexing as <code class="docutils literal notranslate"><span class="pre">net.layers</span></code>. However, this skips the sigmoids which have no trainable parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">shape</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> 
    <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">dict</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
<span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">18</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="si">:</span><span class="s2">10</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  layers.0.weight    [512, 784]
  layers.0.bias      [512]     
  layers.2.weight    [256, 512]
  layers.2.bias      [256]     
  layers.4.weight    [128, 256]
  layers.4.bias      [128]     
  layers.6.weight    [64, 128] 
  layers.6.bias      [64]      
  layers.8.weight    [64, 64]  
  layers.8.bias      [64]      
  layers.10.weight   [32, 64]  
  layers.10.bias     [32]      
  layers.12.weight   [10, 32]  
  layers.12.bias     [10]      
</pre></div>
</div>
</div>
</div>
<p>We also set up the dataset we want to train it on, namely <a class="reference external" href="https://github.com/zalandoresearch/fashion-mnist">FashionMNIST</a>. FashionMNIST is a more complex version of MNIST and contains black-and-white images of clothes instead of digits. The 10 classes include trousers, coats, shoes, bags and more. To load this dataset, we will make use of yet another PyTorch package, namely <code class="docutils literal notranslate"><span class="pre">torchvision</span></code>. The <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> package consists of popular datasets, model architectures, and common image transformations for computer vision. We will use the package for many of the notebooks in this course to simplify our dataset handling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">FashionMNIST</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>


<span class="c1"># Transformations applied on each image. </span>
<span class="c1"># First make them a tensor, then normalize them in the range -1 to 1.</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))])</span>

<span class="c1"># Loading the training dataset. We need to split it into a training and validation part.</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">val_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">])</span>

<span class="c1"># Loading the test set.</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /kaggle/working/data/FashionMNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "b24de63de5bc4bd9839d034848cba899", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting /kaggle/working/data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /kaggle/working/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "0876987d28084bcbb569fe502f707442", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting /kaggle/working/data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /kaggle/working/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "8ba77761d30d40cb923b3d45a1192d7b", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting /kaggle/working/data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /kaggle/working/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "9ac0967a6df24929ba53a89aa9314d08", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting /kaggle/working/data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/data/FashionMNIST/raw
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_numpy.cpp:174.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs visualize a few images to get an impression of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exmp_imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_set</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">)]</span>
<span class="n">class_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;T-shirt/top&quot;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;Trouser&quot;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;Pullover&quot;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;Dress&quot;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">&quot;Coat&quot;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">&quot;Sandal&quot;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">&quot;Shirt&quot;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s2">&quot;Sneaker&quot;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">&quot;Bag&quot;</span><span class="p">,</span>
    <span class="mi">9</span><span class="p">:</span> <span class="s2">&quot;Ankle boot&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">exmp_imgs</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([]);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">class_map</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch-activation_37_0.png" src="../_images/pytorch-activation_37_0.png" />
</div>
</div>
</div>
<div class="section" id="gradient-flow-after-initialization">
<h3>Gradient flow after initialization<a class="headerlink" href="#gradient-flow-after-initialization" title="Permalink to this headline">¬∂</a></h3>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Vanishing and exploding gradients</strong></p>
</div>
<p>As mentioned previously, one important aspect of activation functions is how they propagate gradients through the network. Imagine we have a very deep neural network with more than 50 layers. The gradients for the input layer, i.e. the very first layer, have passed &gt;50 times the activation function, but we still want them to be of a reasonable size. If the gradient through the activation function is in expectation considerably smaller than 1, our gradients will vanish until they reach the input layer. If the gradient through the activation function is larger than 1, the gradients exponentially increase and might explode.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_gradients</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inputs</span>
<span class="sd">        net: Object of class BaseNetwork</span>
<span class="sd">        color: Color in which we want to visualize the histogram (for easier separation of activation functions)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="c1"># Get one batch (size=256) of images</span>
    <span class="n">small_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">small_loader</span><span class="p">))</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Pass the batch through the network, and calculate the gradients for the weights</span>
    <span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># Exclude the bias to reduce the number of plots</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">params</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> 
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;weight&quot;</span> <span class="ow">in</span> <span class="n">name</span>
    <span class="p">}</span>

    <span class="c1"># Remove side-effects</span>
    <span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="c1"># Plotting</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">columns</span><span class="o">*</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>
    <span class="n">fig_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grads</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">key_ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">fig_index</span> <span class="o">%</span> <span class="n">columns</span><span class="p">]</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">key_ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">key_ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Grad magnitude&quot;</span><span class="p">)</span>
        <span class="n">key_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">fig_index</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradient magnitude distribution (weights) for activation function </span><span class="si">{</span><span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;act_fn&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<p>To get a feeling of how every activation function influences the gradients, we can look at a freshly initialized network and measure the gradients for each parameter for a batch of 256 images. That is, we pass 256 images, backpropagate gradients based on the available labels for this images, then look at the histogram of gradient values. We keep our eyes peeled for vanishing or exploding gradients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Seaborn prints warnings if histogram has small values. We can ignore them for now</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># Create a plot for every activation function</span>
<span class="c1"># Setting the seed ensures that we have the same weight initialization</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">act_fn_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">act_fn_by_name</span><span class="p">):</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> 
    <span class="n">act_fn</span> <span class="o">=</span> <span class="n">act_fn_by_name</span><span class="p">[</span><span class="n">act_fn_name</span><span class="p">]()</span>
    <span class="n">net_actfn</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">visualize_gradients</span><span class="p">(</span><span class="n">net_actfn</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch-activation_41_0.png" src="../_images/pytorch-activation_41_0.png" />
<img alt="../_images/pytorch-activation_41_1.png" src="../_images/pytorch-activation_41_1.png" />
<img alt="../_images/pytorch-activation_41_2.png" src="../_images/pytorch-activation_41_2.png" />
<img alt="../_images/pytorch-activation_41_3.png" src="../_images/pytorch-activation_41_3.png" />
<img alt="../_images/pytorch-activation_41_4.png" src="../_images/pytorch-activation_41_4.png" />
<img alt="../_images/pytorch-activation_41_5.png" src="../_images/pytorch-activation_41_5.png" />
</div>
</div>
<p>The sigmoid activation function shows a clearly undesirable behavior. While the gradients for the output layer are very large with up to 0.1, the input layer has the lowest gradient norm across all activation functions with only 1e-5. This is due to its small maximum gradient of 1/4, and finding a suitable learning rate across all layers is not possible in this setup.
All the other activation functions show to have similar gradient norms across all layers. Interestingly, the ReLU activation has a spike around 0 which is caused by its zero-part on the left, and dead neurons (we will take a closer look at this later on).</p>
<p>Note that additionally to the activation, the <strong>initialization</strong> of the weight parameters can be crucial. By default, PyTorch uses the <a class="reference external" href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_">Kaiming</a> initialization for linear layers optimized for ReLU activations. In <a class="reference external" href="https://particle1331.github.io/machine-learning/notebooks/pytorch-optim-init.html">Optimization and Initialization</a>, we will take a closer look at initialization, but assume for now that the Kaiming initialization works for all activation functions reasonably well.</p>
</div>
<div class="section" id="saving-and-loading-a-model">
<h3>Saving and loading a model<a class="headerlink" href="#saving-and-loading-a-model" title="Permalink to this headline">¬∂</a></h3>
<p>Before proceeding to model training, we define and test utility functions for saving and loading PyTorch models. The hyperparameters are stored in a configuration file (simple JSON file), while values of parameters that the network has learned are stored in a tar file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
    <span class="n">model_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> 
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
    <span class="n">net</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads a saved model from disk.</span>
<span class="sd">    </span>
<span class="sd">    Inputs:</span>
<span class="sd">        model_path - Path of the checkpoint directory</span>
<span class="sd">        model_name - Name of the model (str)</span>
<span class="sd">        net - (Optional) If given, the state dict is loaded into this model. Otherwise, a new model is created.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Get pathlib paths of model and config files; check if existing</span>
    <span class="n">config_file</span> <span class="o">=</span> <span class="n">_get_config_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    
    <span class="n">error_msg</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">fn</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Could not find the file </span><span class="se">\&quot;</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2">.&quot;</span>
    <span class="k">assert</span> <span class="n">config_file</span><span class="o">.</span><span class="n">is_file</span><span class="p">(),</span> <span class="n">error_msg</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">model_file</span><span class="o">.</span><span class="n">is_file</span><span class="p">(),</span> <span class="n">error_msg</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
    
    <span class="c1"># If no network passed, init. network with architecture from config</span>
    <span class="k">if</span> <span class="n">net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        
        <span class="c1"># Recall structure of config file in BaseNetwork</span>
        <span class="n">act_fn_name</span> <span class="o">=</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;act_fn&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">act_fn</span> <span class="o">=</span> <span class="n">act_fn_by_name</span><span class="p">[</span><span class="n">act_fn_name</span><span class="p">](</span><span class="o">**</span><span class="n">config_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;act_fn&quot;</span><span class="p">))</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">,</span> <span class="o">**</span><span class="n">config_dict</span><span class="p">)</span>
    
    <span class="c1"># Load weights to network</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">net</span>
    
    
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> 
    <span class="n">model_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a model, we save the state_dict and hyperparameters.</span>
<span class="sd">    </span>
<span class="sd">    Inputs:</span>
<span class="sd">        model - Network object to save parameters from</span>
<span class="sd">        model_path - Path of the checkpoint directory</span>
<span class="sd">        model_name - Name of the model (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">config_dict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
    <span class="n">model_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">config_file</span> <span class="o">=</span> <span class="n">_get_config_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">model_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Testing <code class="docutils literal notranslate"><span class="pre">save_model</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_path</span><span class="o">=</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;test_save_model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Checking artifacts:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config_file</span> <span class="o">=</span> <span class="n">_get_config_file</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s1">&#39;test_save_model&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">config_dict</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;act_fn&#39;: {&#39;name&#39;: &#39;Sigmoid&#39;},
 &#39;input_size&#39;: 1,
 &#39;num_classes&#39;: 1,
 &#39;hidden_sizes&#39;: [1, 1, 1]}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s1">&#39;test_save_model&#39;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;layers.0.weight&#39;, tensor([[-0.8584]], device=&#39;cuda:0&#39;)),
             (&#39;layers.0.bias&#39;, tensor([-0.2528], device=&#39;cuda:0&#39;)),
             (&#39;layers.2.weight&#39;, tensor([[-0.0063]], device=&#39;cuda:0&#39;)),
             (&#39;layers.2.bias&#39;, tensor([-0.3326], device=&#39;cuda:0&#39;)),
             (&#39;layers.4.weight&#39;, tensor([[0.9424]], device=&#39;cuda:0&#39;)),
             (&#39;layers.4.bias&#39;, tensor([0.7875], device=&#39;cuda:0&#39;)),
             (&#39;layers.6.weight&#39;, tensor([[-0.5816]], device=&#39;cuda:0&#39;)),
             (&#39;layers.6.bias&#39;, tensor([0.5567], device=&#39;cuda:0&#39;))])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-a-model">
<h3>Training a model<a class="headerlink" href="#training-a-model" title="Permalink to this headline">¬∂</a></h3>
<p>Next, we want to train our model with different activation functions on FashionMNIST and compare the gained performance. All in all, our final goal is to achieve the best possible performance on a dataset of our choice.
Therefore, we write a training loop in the next cell including a validation after every epoch and a final test on the best model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train a model on the training set of FashionMNIST</span>
<span class="sd">    </span>
<span class="sd">    Inputs:</span>
<span class="sd">        net - Object of BaseNetwork</span>
<span class="sd">        model_name - (str) Name of the model, used for creating the checkpoint names</span>
<span class="sd">        max_epochs - Number of epochs we want to (maximally) train for</span>
<span class="sd">        patience - If the performance on the validation set has not improved for #patience epochs, we stop training early</span>
<span class="sd">        batch_size - Size of batches used in training</span>
<span class="sd">        overwrite - Determines how to handle the case when there already exists a checkpoint. If True, it will be overwritten. Otherwise, we skip training.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">file_exists</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">file_exists</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model file already exists. Skipping training...&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">file_exists</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model file exists, but will be overwritten...&quot;</span><span class="p">)</span>
            
        <span class="c1"># Defining optimizer, loss and data loader</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">loss_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> 
        
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">val_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">best_val_epoch</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>                        
            <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">true_preds</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
                <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                
                <span class="c1"># Backward pass</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_module</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                
                <span class="c1"># Record statistics during training</span>
                <span class="n">true_preds</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">true_preds</span> <span class="o">/</span> <span class="n">count</span>
            
            <span class="c1"># Validation</span>
            <span class="n">val_acc</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
            <span class="n">val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
            <span class="n">log</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">] Training accuracy: </span><span class="si">{</span><span class="n">train_acc</span><span class="o">*</span><span class="mf">100.0</span><span class="si">:</span><span class="s2">05.2f</span><span class="si">}</span><span class="s2">%, Validation accuracy: </span><span class="si">{</span><span class="n">val_acc</span><span class="o">*</span><span class="mf">100.0</span><span class="si">:</span><span class="s2">05.2f</span><span class="si">}</span><span class="s2">%&quot;</span>
            <span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>
            
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_scores</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">val_scores</span><span class="p">[</span><span class="n">best_val_epoch</span><span class="p">]:</span>
                <span class="n">log</span> <span class="o">+=</span> <span class="s2">&quot; (New best performance, saving model...)&quot;</span>
                <span class="n">save_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
                <span class="n">best_val_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
                
            <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&gt;=</span> <span class="n">best_val_epoch</span> <span class="o">+</span> <span class="n">patience</span><span class="p">:</span>
                <span class="n">log</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Early stopping due to no improvement over the last </span><span class="si">{</span><span class="n">patience</span><span class="si">}</span><span class="s2"> epochs&quot;</span>
                <span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
                
            <span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">early_stop</span><span class="p">:</span> <span class="k">break</span>

            
        <span class="c1"># Plot a curve of the validation accuracy</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">val_scores</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">val_scores</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Validation accuracy&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation performance of </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
    <span class="c1"># Load best weights and evaluate on test set</span>
    <span class="n">load_model</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">((</span><span class="sa">f</span><span class="s2">&quot; Test accuracy: </span><span class="si">{</span><span class="n">test_acc</span><span class="o">*</span><span class="mf">100.0</span><span class="si">:</span><span class="s2">4.2f</span><span class="si">}</span><span class="s2">% &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="mi">47</span><span class="p">,</span> <span class="s2">&quot;=&quot;</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">test_acc</span>
    

<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test a model on a specified dataset.</span>
<span class="sd">    </span>
<span class="sd">    Inputs:</span>
<span class="sd">        net - Trained model of type BaseNetwork</span>
<span class="sd">        data_loader - DataLoader object of the dataset to test on (validation or test)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">true_preds</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">true_preds</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">true_preds</span> <span class="o">/</span> <span class="n">count</span>
    <span class="k">return</span> <span class="n">test_acc</span> 
</pre></div>
</div>
</div>
</div>
<p>We train one model for each activation function. We recommend using the pretrained models to save time if you are running this notebook on CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">act_fn_name</span> <span class="ow">in</span> <span class="n">act_fn_by_name</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training BaseNetwork with </span><span class="si">{</span><span class="n">act_fn_name</span><span class="si">}</span><span class="s2"> activation...&quot;</span><span class="p">)</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">act_fn</span> <span class="o">=</span> <span class="n">act_fn_by_name</span><span class="p">[</span><span class="n">act_fn_name</span><span class="p">]()</span>
    <span class="n">net_actfn</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># May set overwrite=False if pretrained models are available. See appendix.</span>
    <span class="n">results</span><span class="p">[</span><span class="n">act_fn_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_model</span><span class="p">(</span><span class="n">net_actfn</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FashionMNIST_</span><span class="si">{</span><span class="n">act_fn_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training BaseNetwork with sigmoid activation...
[Epoch  1] Training accuracy: 10.15%, Validation accuracy: 10.46% (New best performance, saving model...)
[Epoch  2] Training accuracy: 10.09%, Validation accuracy: 10.03%
[Epoch  3] Training accuracy: 10.12%, Validation accuracy: 09.95%
[Epoch  4] Training accuracy: 10.20%, Validation accuracy: 09.67%
[Epoch  5] Training accuracy: 09.99%, Validation accuracy: 10.46%
[Epoch  6] Training accuracy: 10.18%, Validation accuracy: 09.84%
[Epoch  7] Training accuracy: 09.98%, Validation accuracy: 10.94% (New best performance, saving model...)
[Epoch  8] Training accuracy: 10.24%, Validation accuracy: 09.87%
[Epoch  9] Training accuracy: 10.17%, Validation accuracy: 09.67%
[Epoch 10] Training accuracy: 10.06%, Validation accuracy: 10.24%
[Epoch 11] Training accuracy: 10.09%, Validation accuracy: 10.03%
[Epoch 12] Training accuracy: 10.66%, Validation accuracy: 10.56%
[Epoch 13] Training accuracy: 10.16%, Validation accuracy: 09.87%
[Epoch 14] Training accuracy: 10.35%, Validation accuracy: 09.87%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_1.png" src="../_images/pytorch-activation_54_1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 10.37% ============

Training BaseNetwork with tanh activation...
[Epoch  1] Training accuracy: 66.67%, Validation accuracy: 77.90% (New best performance, saving model...)
[Epoch  2] Training accuracy: 81.51%, Validation accuracy: 82.23% (New best performance, saving model...)
[Epoch  3] Training accuracy: 84.02%, Validation accuracy: 83.62% (New best performance, saving model...)
[Epoch  4] Training accuracy: 85.27%, Validation accuracy: 84.45% (New best performance, saving model...)
[Epoch  5] Training accuracy: 85.99%, Validation accuracy: 85.33% (New best performance, saving model...)
[Epoch  6] Training accuracy: 86.29%, Validation accuracy: 85.82% (New best performance, saving model...)
[Epoch  7] Training accuracy: 86.81%, Validation accuracy: 86.25% (New best performance, saving model...)
[Epoch  8] Training accuracy: 87.34%, Validation accuracy: 85.64%
[Epoch  9] Training accuracy: 87.95%, Validation accuracy: 86.89% (New best performance, saving model...)
[Epoch 10] Training accuracy: 88.11%, Validation accuracy: 86.95% (New best performance, saving model...)
[Epoch 11] Training accuracy: 88.41%, Validation accuracy: 87.36% (New best performance, saving model...)
[Epoch 12] Training accuracy: 88.64%, Validation accuracy: 86.92%
[Epoch 13] Training accuracy: 88.95%, Validation accuracy: 86.23%
[Epoch 14] Training accuracy: 89.03%, Validation accuracy: 87.03%
[Epoch 15] Training accuracy: 89.29%, Validation accuracy: 87.08%
[Epoch 16] Training accuracy: 89.60%, Validation accuracy: 86.84%
[Epoch 17] Training accuracy: 89.77%, Validation accuracy: 88.01% (New best performance, saving model...)
[Epoch 18] Training accuracy: 89.97%, Validation accuracy: 87.73%
[Epoch 19] Training accuracy: 90.20%, Validation accuracy: 88.03% (New best performance, saving model...)
[Epoch 20] Training accuracy: 90.67%, Validation accuracy: 88.37% (New best performance, saving model...)
[Epoch 21] Training accuracy: 90.68%, Validation accuracy: 87.83%
[Epoch 22] Training accuracy: 90.58%, Validation accuracy: 87.76%
[Epoch 23] Training accuracy: 91.00%, Validation accuracy: 88.26%
[Epoch 24] Training accuracy: 90.94%, Validation accuracy: 87.58%
[Epoch 25] Training accuracy: 91.45%, Validation accuracy: 87.85%
[Epoch 26] Training accuracy: 91.45%, Validation accuracy: 87.99%
[Epoch 27] Training accuracy: 91.61%, Validation accuracy: 88.53% (New best performance, saving model...)
[Epoch 28] Training accuracy: 91.94%, Validation accuracy: 88.84% (New best performance, saving model...)
[Epoch 29] Training accuracy: 91.95%, Validation accuracy: 88.77%
[Epoch 30] Training accuracy: 92.04%, Validation accuracy: 88.29%
[Epoch 31] Training accuracy: 92.32%, Validation accuracy: 88.87% (New best performance, saving model...)
[Epoch 32] Training accuracy: 92.15%, Validation accuracy: 88.73%
[Epoch 33] Training accuracy: 92.47%, Validation accuracy: 89.22% (New best performance, saving model...)
[Epoch 34] Training accuracy: 92.85%, Validation accuracy: 88.40%
[Epoch 35] Training accuracy: 92.89%, Validation accuracy: 88.69%
[Epoch 36] Training accuracy: 93.03%, Validation accuracy: 88.88%
[Epoch 37] Training accuracy: 93.49%, Validation accuracy: 88.96%
[Epoch 38] Training accuracy: 93.45%, Validation accuracy: 88.79%
[Epoch 39] Training accuracy: 93.41%, Validation accuracy: 88.94%
[Epoch 40] Training accuracy: 93.72%, Validation accuracy: 87.70%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_3.png" src="../_images/pytorch-activation_54_3.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 88.37% ============

Training BaseNetwork with relu activation...
[Epoch  1] Training accuracy: 50.12%, Validation accuracy: 74.80% (New best performance, saving model...)
[Epoch  2] Training accuracy: 78.91%, Validation accuracy: 80.84% (New best performance, saving model...)
[Epoch  3] Training accuracy: 83.33%, Validation accuracy: 83.47% (New best performance, saving model...)
[Epoch  4] Training accuracy: 84.93%, Validation accuracy: 84.64% (New best performance, saving model...)
[Epoch  5] Training accuracy: 86.13%, Validation accuracy: 85.81% (New best performance, saving model...)
[Epoch  6] Training accuracy: 86.93%, Validation accuracy: 85.72%
[Epoch  7] Training accuracy: 87.61%, Validation accuracy: 86.83% (New best performance, saving model...)
[Epoch  8] Training accuracy: 88.32%, Validation accuracy: 86.21%
[Epoch  9] Training accuracy: 88.75%, Validation accuracy: 87.47% (New best performance, saving model...)
[Epoch 10] Training accuracy: 89.09%, Validation accuracy: 87.22%
[Epoch 11] Training accuracy: 89.59%, Validation accuracy: 88.25% (New best performance, saving model...)
[Epoch 12] Training accuracy: 89.88%, Validation accuracy: 88.16%
[Epoch 13] Training accuracy: 90.21%, Validation accuracy: 87.24%
[Epoch 14] Training accuracy: 90.69%, Validation accuracy: 87.51%
[Epoch 15] Training accuracy: 90.85%, Validation accuracy: 87.83%
[Epoch 16] Training accuracy: 91.24%, Validation accuracy: 87.68%
[Epoch 17] Training accuracy: 91.56%, Validation accuracy: 87.73%
[Epoch 18] Training accuracy: 91.67%, Validation accuracy: 89.05% (New best performance, saving model...)
[Epoch 19] Training accuracy: 92.27%, Validation accuracy: 88.49%
[Epoch 20] Training accuracy: 92.56%, Validation accuracy: 88.87%
[Epoch 21] Training accuracy: 92.45%, Validation accuracy: 88.57%
[Epoch 22] Training accuracy: 92.86%, Validation accuracy: 88.28%
[Epoch 23] Training accuracy: 92.96%, Validation accuracy: 89.04%
[Epoch 24] Training accuracy: 93.18%, Validation accuracy: 89.30% (New best performance, saving model...)
[Epoch 25] Training accuracy: 93.80%, Validation accuracy: 88.47%
[Epoch 26] Training accuracy: 93.76%, Validation accuracy: 87.72%
[Epoch 27] Training accuracy: 94.04%, Validation accuracy: 89.04%
[Epoch 28] Training accuracy: 94.36%, Validation accuracy: 88.32%
[Epoch 29] Training accuracy: 94.24%, Validation accuracy: 88.78%
[Epoch 30] Training accuracy: 94.44%, Validation accuracy: 88.43%
[Epoch 31] Training accuracy: 94.65%, Validation accuracy: 88.93%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_5.png" src="../_images/pytorch-activation_54_5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 88.93% ============

Training BaseNetwork with leakyrelu activation...
[Epoch  1] Training accuracy: 51.24%, Validation accuracy: 75.01% (New best performance, saving model...)
[Epoch  2] Training accuracy: 79.07%, Validation accuracy: 80.87% (New best performance, saving model...)
[Epoch  3] Training accuracy: 83.34%, Validation accuracy: 82.99% (New best performance, saving model...)
[Epoch  4] Training accuracy: 84.82%, Validation accuracy: 84.76% (New best performance, saving model...)
[Epoch  5] Training accuracy: 85.87%, Validation accuracy: 85.45% (New best performance, saving model...)
[Epoch  6] Training accuracy: 86.65%, Validation accuracy: 85.69% (New best performance, saving model...)
[Epoch  7] Training accuracy: 87.43%, Validation accuracy: 86.64% (New best performance, saving model...)
[Epoch  8] Training accuracy: 87.83%, Validation accuracy: 85.66%
[Epoch  9] Training accuracy: 88.57%, Validation accuracy: 87.45% (New best performance, saving model...)
[Epoch 10] Training accuracy: 88.70%, Validation accuracy: 87.24%
[Epoch 11] Training accuracy: 89.30%, Validation accuracy: 88.00% (New best performance, saving model...)
[Epoch 12] Training accuracy: 89.53%, Validation accuracy: 87.80%
[Epoch 13] Training accuracy: 89.65%, Validation accuracy: 87.00%
[Epoch 14] Training accuracy: 90.24%, Validation accuracy: 87.26%
[Epoch 15] Training accuracy: 90.35%, Validation accuracy: 87.71%
[Epoch 16] Training accuracy: 90.72%, Validation accuracy: 87.05%
[Epoch 17] Training accuracy: 91.08%, Validation accuracy: 87.76%
[Epoch 18] Training accuracy: 91.30%, Validation accuracy: 88.67% (New best performance, saving model...)
[Epoch 19] Training accuracy: 91.62%, Validation accuracy: 88.27%
[Epoch 20] Training accuracy: 92.04%, Validation accuracy: 89.03% (New best performance, saving model...)
[Epoch 21] Training accuracy: 91.78%, Validation accuracy: 88.75%
[Epoch 22] Training accuracy: 92.28%, Validation accuracy: 87.92%
[Epoch 23] Training accuracy: 92.31%, Validation accuracy: 88.71%
[Epoch 24] Training accuracy: 92.59%, Validation accuracy: 88.96%
[Epoch 25] Training accuracy: 93.02%, Validation accuracy: 88.79%
[Epoch 26] Training accuracy: 93.16%, Validation accuracy: 88.17%
[Epoch 27] Training accuracy: 93.39%, Validation accuracy: 88.71%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_7.png" src="../_images/pytorch-activation_54_7.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 88.43% ============

Training BaseNetwork with elu activation...
[Epoch  1] Training accuracy: 66.48%, Validation accuracy: 78.59% (New best performance, saving model...)
[Epoch  2] Training accuracy: 81.67%, Validation accuracy: 82.53% (New best performance, saving model...)
[Epoch  3] Training accuracy: 84.00%, Validation accuracy: 83.37% (New best performance, saving model...)
[Epoch  4] Training accuracy: 85.03%, Validation accuracy: 84.77% (New best performance, saving model...)
[Epoch  5] Training accuracy: 85.75%, Validation accuracy: 85.01% (New best performance, saving model...)
[Epoch  6] Training accuracy: 86.14%, Validation accuracy: 85.17% (New best performance, saving model...)
[Epoch  7] Training accuracy: 86.58%, Validation accuracy: 85.67% (New best performance, saving model...)
[Epoch  8] Training accuracy: 86.93%, Validation accuracy: 85.64%
[Epoch  9] Training accuracy: 87.51%, Validation accuracy: 86.35% (New best performance, saving model...)
[Epoch 10] Training accuracy: 87.64%, Validation accuracy: 86.44% (New best performance, saving model...)
[Epoch 11] Training accuracy: 87.75%, Validation accuracy: 86.38%
[Epoch 12] Training accuracy: 88.23%, Validation accuracy: 86.55% (New best performance, saving model...)
[Epoch 13] Training accuracy: 88.44%, Validation accuracy: 85.93%
[Epoch 14] Training accuracy: 88.67%, Validation accuracy: 86.78% (New best performance, saving model...)
[Epoch 15] Training accuracy: 88.85%, Validation accuracy: 86.95% (New best performance, saving model...)
[Epoch 16] Training accuracy: 89.22%, Validation accuracy: 87.05% (New best performance, saving model...)
[Epoch 17] Training accuracy: 89.31%, Validation accuracy: 87.86% (New best performance, saving model...)
[Epoch 18] Training accuracy: 89.54%, Validation accuracy: 87.84%
[Epoch 19] Training accuracy: 89.71%, Validation accuracy: 87.37%
[Epoch 20] Training accuracy: 89.94%, Validation accuracy: 87.96% (New best performance, saving model...)
[Epoch 21] Training accuracy: 90.06%, Validation accuracy: 87.64%
[Epoch 22] Training accuracy: 90.05%, Validation accuracy: 87.92%
[Epoch 23] Training accuracy: 90.48%, Validation accuracy: 87.73%
[Epoch 24] Training accuracy: 90.47%, Validation accuracy: 87.86%
[Epoch 25] Training accuracy: 90.74%, Validation accuracy: 88.28% (New best performance, saving model...)
[Epoch 26] Training accuracy: 90.74%, Validation accuracy: 88.14%
[Epoch 27] Training accuracy: 90.76%, Validation accuracy: 88.00%
[Epoch 28] Training accuracy: 90.95%, Validation accuracy: 87.73%
[Epoch 29] Training accuracy: 91.15%, Validation accuracy: 88.53% (New best performance, saving model...)
[Epoch 30] Training accuracy: 91.22%, Validation accuracy: 88.43%
[Epoch 31] Training accuracy: 91.34%, Validation accuracy: 88.53%
[Epoch 32] Training accuracy: 91.41%, Validation accuracy: 88.74% (New best performance, saving model...)
[Epoch 33] Training accuracy: 91.64%, Validation accuracy: 88.56%
[Epoch 34] Training accuracy: 92.02%, Validation accuracy: 87.97%
[Epoch 35] Training accuracy: 92.13%, Validation accuracy: 88.46%
[Epoch 36] Training accuracy: 92.14%, Validation accuracy: 88.35%
[Epoch 37] Training accuracy: 92.25%, Validation accuracy: 89.06% (New best performance, saving model...)
[Epoch 38] Training accuracy: 92.36%, Validation accuracy: 88.58%
[Epoch 39] Training accuracy: 92.15%, Validation accuracy: 88.94%
[Epoch 40] Training accuracy: 92.53%, Validation accuracy: 88.84%
[Epoch 41] Training accuracy: 92.53%, Validation accuracy: 88.70%
[Epoch 42] Training accuracy: 92.61%, Validation accuracy: 88.67%
[Epoch 43] Training accuracy: 92.96%, Validation accuracy: 88.92%
[Epoch 44] Training accuracy: 93.02%, Validation accuracy: 88.58%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_9.png" src="../_images/pytorch-activation_54_9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 88.42% ============

Training BaseNetwork with swish activation...
[Epoch  1] Training accuracy: 28.92%, Validation accuracy: 29.34% (New best performance, saving model...)
[Epoch  2] Training accuracy: 64.90%, Validation accuracy: 74.27% (New best performance, saving model...)
[Epoch  3] Training accuracy: 79.36%, Validation accuracy: 81.79% (New best performance, saving model...)
[Epoch  4] Training accuracy: 82.60%, Validation accuracy: 82.54% (New best performance, saving model...)
[Epoch  5] Training accuracy: 83.90%, Validation accuracy: 83.71% (New best performance, saving model...)
[Epoch  6] Training accuracy: 84.75%, Validation accuracy: 84.45% (New best performance, saving model...)
[Epoch  7] Training accuracy: 85.57%, Validation accuracy: 84.98% (New best performance, saving model...)
[Epoch  8] Training accuracy: 86.04%, Validation accuracy: 85.18% (New best performance, saving model...)
[Epoch  9] Training accuracy: 86.60%, Validation accuracy: 86.10% (New best performance, saving model...)
[Epoch 10] Training accuracy: 86.94%, Validation accuracy: 85.38%
[Epoch 11] Training accuracy: 87.25%, Validation accuracy: 86.56% (New best performance, saving model...)
[Epoch 12] Training accuracy: 87.50%, Validation accuracy: 85.60%
[Epoch 13] Training accuracy: 87.74%, Validation accuracy: 85.29%
[Epoch 14] Training accuracy: 88.20%, Validation accuracy: 86.35%
[Epoch 15] Training accuracy: 88.24%, Validation accuracy: 86.66% (New best performance, saving model...)
[Epoch 16] Training accuracy: 88.59%, Validation accuracy: 86.81% (New best performance, saving model...)
[Epoch 17] Training accuracy: 88.64%, Validation accuracy: 87.62% (New best performance, saving model...)
[Epoch 18] Training accuracy: 89.05%, Validation accuracy: 87.42%
[Epoch 19] Training accuracy: 89.15%, Validation accuracy: 87.05%
[Epoch 20] Training accuracy: 89.52%, Validation accuracy: 87.89% (New best performance, saving model...)
[Epoch 21] Training accuracy: 89.54%, Validation accuracy: 87.01%
[Epoch 22] Training accuracy: 89.68%, Validation accuracy: 87.70%
[Epoch 23] Training accuracy: 89.90%, Validation accuracy: 87.94% (New best performance, saving model...)
[Epoch 24] Training accuracy: 89.97%, Validation accuracy: 87.60%
[Epoch 25] Training accuracy: 90.24%, Validation accuracy: 88.20% (New best performance, saving model...)
[Epoch 26] Training accuracy: 90.37%, Validation accuracy: 88.06%
[Epoch 27] Training accuracy: 90.35%, Validation accuracy: 88.02%
[Epoch 28] Training accuracy: 90.53%, Validation accuracy: 87.45%
[Epoch 29] Training accuracy: 90.81%, Validation accuracy: 88.51% (New best performance, saving model...)
[Epoch 30] Training accuracy: 90.79%, Validation accuracy: 88.78% (New best performance, saving model...)
[Epoch 31] Training accuracy: 91.10%, Validation accuracy: 88.53%
[Epoch 32] Training accuracy: 91.18%, Validation accuracy: 88.44%
[Epoch 33] Training accuracy: 91.37%, Validation accuracy: 88.54%
[Epoch 34] Training accuracy: 91.51%, Validation accuracy: 87.43%
[Epoch 35] Training accuracy: 91.78%, Validation accuracy: 88.40%
[Epoch 36] Training accuracy: 91.85%, Validation accuracy: 88.95% (New best performance, saving model...)
[Epoch 37] Training accuracy: 92.07%, Validation accuracy: 89.36% (New best performance, saving model...)
[Epoch 38] Training accuracy: 92.07%, Validation accuracy: 88.39%
[Epoch 39] Training accuracy: 92.13%, Validation accuracy: 89.14%
[Epoch 40] Training accuracy: 92.43%, Validation accuracy: 88.51%
[Epoch 41] Training accuracy: 92.50%, Validation accuracy: 88.60%
[Epoch 42] Training accuracy: 92.67%, Validation accuracy: 88.74%
[Epoch 43] Training accuracy: 92.71%, Validation accuracy: 88.51%
[Epoch 44] Training accuracy: 92.93%, Validation accuracy: 88.76%
Early stopping due to no improvement over the last 7 epochs
</pre></div>
</div>
<img alt="../_images/pytorch-activation_54_11.png" src="../_images/pytorch-activation_54_11.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============ Test accuracy: 88.50% ============
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sigmoid</th>
      <th>tanh</th>
      <th>relu</th>
      <th>leakyrelu</th>
      <th>elu</th>
      <th>swish</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.1037</td>
      <td>0.8837</td>
      <td>0.8893</td>
      <td>0.8843</td>
      <td>0.8842</td>
      <td>0.885</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Not surprisingly, the model using the sigmoid activation function shows to fail and does not improve upon random performance (10 classes =&gt; 1/10 for random chance).</p>
<p>All the other activation functions gain similar performance.
To have a more accurate conclusion, we would have to train the models for multiple seeds and look at the averages.
However, the ‚Äúoptimal‚Äù activation function also depends on many other factors (hidden sizes, number of layers, type of layers, task, dataset, optimizer, learning rate, etc.) so that a thorough grid search would not be useful in our case.
In the literature, activation functions that have shown to work well with deep networks are all types of ReLU functions we experiment with here, with small gains for specific activation functions in specific networks.</p>
</div>
<div class="section" id="activation-distribution">
<h3>Activation distribution<a class="headerlink" href="#activation-distribution" title="Permalink to this headline">¬∂</a></h3>
<p>After we have trained the models, we can look at the actual activation values that find inside the model. For instance, how many neurons are set to zero in ReLU? Where do we find most values in Tanh?
To answer these questions, we can write a simple function which takes a trained model, applies it to a batch of images, and plots the histogram of the activations inside the network over the input batch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_activations</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">):</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">small_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">small_loader</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">layer_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># We need to manually loop through the layers to save all activations</span>
        <span class="k">for</span> <span class="n">layer_index</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
            <span class="n">activations</span><span class="p">[</span><span class="n">layer_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="c1"># Plotting</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span><span class="o">/</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">columns</span><span class="o">*</span><span class="mf">2.7</span><span class="p">,</span> <span class="n">rows</span><span class="o">*</span><span class="mf">2.5</span><span class="p">))</span>
    <span class="n">fig_index</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">:</span> <span class="c1"># key := layer_index</span>
        <span class="n">key_ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">fig_index</span><span class="p">,</span> <span class="n">columns</span><span class="p">)]</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">key_ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">)</span>
        <span class="n">key_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">fig_index</span> <span class="o">+=</span> <span class="mi">1</span>
        
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Activation distribution for activation function </span><span class="si">{</span><span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;act_fn&#39;</span><span class="p">][</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\phantom{3}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">act_fn_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">act_fn_by_name</span><span class="p">):</span>
    <span class="n">net_actfn</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;FashionMNIST_</span><span class="si">{</span><span class="n">act_fn_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">visualize_activations</span><span class="p">(</span><span class="n">net_actfn</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch-activation_61_0.png" src="../_images/pytorch-activation_61_0.png" />
<img alt="../_images/pytorch-activation_61_1.png" src="../_images/pytorch-activation_61_1.png" />
<img alt="../_images/pytorch-activation_61_2.png" src="../_images/pytorch-activation_61_2.png" />
<img alt="../_images/pytorch-activation_61_3.png" src="../_images/pytorch-activation_61_3.png" />
<img alt="../_images/pytorch-activation_61_4.png" src="../_images/pytorch-activation_61_4.png" />
<img alt="../_images/pytorch-activation_61_5.png" src="../_images/pytorch-activation_61_5.png" />
</div>
</div>
<p>As the model with sigmoid activation was not able to train properly, the activations are also less informative and all gathered around 0.5 (the activation at input 0).</p>
<p>The tanh shows a more diverse behavior. While for the input layer we experience a larger amount of neurons to be close to -1 and 1, where the gradients are close to zero, the activations in the two consecutive layers are closer to zero. This is probably because the input layers look for <strong>specific features</strong> in the input image, and the consecutive layers combine those together. The activations for the last layer are again more biased to the extreme points because the classification layer can be seen as a weighted average of those values (the gradients push the activations to those extremes).</p>
<p>The ReLU has a strong peak at 0, as we initially expected. The effect of having no gradients for negative values is that the network does not have a Gaussian-like distribution after the linear layers, but a longer tail towards the positive values.
The LeakyReLU shows a very similar behavior while ELU follows again a more Gaussian-like distribution.
The Swish activation seems to lie in between, although it is worth noting that Swish uses significantly higher values than other activation functions (up to 20).</p>
<p>As all activation functions show slightly different behavior although obtaining similar performance for our simple network, it becomes apparent that the selection of the ‚Äúoptimal‚Äù activation function really depends on many factors, and is not the same for all possible networks.</p>
</div>
<div class="section" id="measuring-dead-neurons-in-relu-networks">
<h3>Measuring dead neurons in ReLU networks<a class="headerlink" href="#measuring-dead-neurons-in-relu-networks" title="Permalink to this headline">¬∂</a></h3>
<p>One known drawback of the ReLU activation is the occurrence of ‚Äúdead neurons‚Äù, i.e. neurons with no gradient for any training input.
The issue of dead neurons is that as no gradient is provided for the layer, we cannot train the parameters of this neuron in the previous layer to obtain output values besides zero.
For dead neurons to happen, the output value of a specific neuron of the linear layer before the ReLU has to be negative for all input images.
Note that all gradients are also zero so that the weights will also not update if we introduce no new data.
Considering the large number of neurons we have in a neural network, it is not unlikely for this to happen.</p>
<p>To get a better understanding of how much of a problem this is, and when we need to be careful, we will measure how many dead neurons different networks have. For this, we implement a function which runs the network on the whole training set and records whether a neuron is ‚Äúzero‚Äù for majority of the data points (99% by default):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.99</span><span class="p">):</span>

    <span class="c1"># Count of zero activations over the train set for each neuron in a layer.</span>
    <span class="n">zero_count</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span> 
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Note if layer is not an activation, then input is simply passed.</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">images</span>
            <span class="k">for</span> <span class="n">layer_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_index</span><span class="p">]</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">ActivationFunction</span><span class="p">):</span>
                    <span class="n">zero_count</span><span class="p">[</span><span class="n">layer_index</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
    <span class="c1"># Count all dead neurons for each layer. A dead neuron has zero activation ratio </span>
    <span class="c1"># that exceeds the threshold, e.g. zero for 99% of the training examples (default).</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of dead neurons:&quot;</span><span class="p">)</span>
    <span class="n">message</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">zero_count</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">num_dead</span> <span class="o">=</span> <span class="p">((</span><span class="n">zero_count</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">=</span> <span class="n">zero_count</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">)&#39;</span><span class="si">:</span><span class="s2">&gt;4</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">num_dead</span><span class="si">:</span><span class="s2">3</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total</span><span class="si">:</span><span class="s2">3</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;(</span><span class="si">{</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">num_dead</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">message</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Testing with network with all neurons having zero output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">weights_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    
<span class="c1"># Initialize with zero weights</span>
<span class="n">net_zero</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">ReLU</span><span class="p">())</span>
<span class="n">net_zero</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">weights_init</span><span class="p">)</span>

<span class="c1"># Should sum to zero</span>
<span class="nb">sum</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">net_zero</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0., grad_fn=&lt;AddBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net_zero</span><span class="p">)</span> <span class="c1"># Should be all dead</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of dead neurons:
   (1) ReLU: 512/512 (100.00%)
   (3) ReLU: 256/256 (100.00%)
   (5) ReLU: 256/256 (100.00%)
   (7) ReLU: 128/128 (100.00%)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Going back to the discussion, we can now measure the number of dead neurons for an <strong>untrained network</strong>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">net_relu</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net_relu</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
<span class="n">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net_relu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Linear(in_features=784, out_features=512, bias=True)
  (1): ReLU()
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ReLU()
  (4): Linear(in_features=256, out_features=256, bias=True)
  (5): ReLU()
  (6): Linear(in_features=256, out_features=128, bias=True)
  (7): ReLU()
  (8): Linear(in_features=128, out_features=10, bias=True)
)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of dead neurons:
   (1) ReLU:   4/512  (0.78%)
   (3) ReLU:  10/256  (3.91%)
   (5) ReLU:  28/256 (10.94%)
   (7) ReLU:  30/128 (23.44%)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>We see that only a minor amount of neurons are dead, but that they increase with the depth of the layer.
In the long term, this is not a problem for the small number of dead neurons we have as the input to later layers is changed due to updates to the weights of previous layers. Therefore, dead neurons in later layers can potentially become ‚Äúalive‚Äù or active again.</p>
<p>How does this look like for a <strong>trained network</strong> (with the same initialization)?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">net_relu</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;FashionMNIST_relu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net_relu</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of dead neurons:
   (1) ReLU: 508/512 (99.22%)
   (3) ReLU: 215/256 (83.98%)
   (5) ReLU: 174/256 (67.97%)
   (7) ReLU:  97/128 (75.78%)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>Observe that the number of dead neurons increased after training. Probably, this is arrived at by learning a large negative bias term for its weights. For deeper layers, this can mean that these neurons learn to take no role in discriminating the network‚Äôs inputs. However, it should be noted that dead neurons are especially problematic in the input layer where only 4 neurons in the input layer are alive (i.e. has fired ‚Äúnonzero‚Äù vales for at least 1% of the data)!</p>
<p>Finally, we check how the number of dead neurons behaves with increasing layer depth. For instance, let‚Äôs take the following untrained 10-layer neural network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">net_relu</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net_relu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of dead neurons:
   (1) ReLU:   2/256  (0.78%)
   (3) ReLU:  10/256  (3.91%)
   (5) ReLU:  25/256  (9.77%)
   (7) ReLU:  66/256 (25.78%)
   (9) ReLU: 117/256 (45.70%)
  (11) ReLU:  61/128 (47.66%)
  (13) ReLU:  58/128 (45.31%)
  (15) ReLU:  61/128 (47.66%)
  (17) ReLU:  72/128 (56.25%)
  (19) ReLU:  56/128 (43.75%)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p>The number of dead neurons is significantly higher than before which harms the gradient flow especially in the first iterations. For instance, more than 56% of the neurons in the pre-last layer are dead which creates a considerable bottleneck.
Hence, it is advisible to use other nonlinearities like Swish for very deep networks:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">net_swish</span> <span class="o">=</span> <span class="n">BaseNetwork</span><span class="p">(</span><span class="n">act_fn</span><span class="o">=</span><span class="n">Swish</span><span class="p">(),</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">measure_number_dead_neurons</span><span class="p">(</span><span class="n">net_swish</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                               
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of dead neurons:
   (1) Swish:   0/256  (0.00%)
   (3) Swish:   0/256  (0.00%)
   (5) Swish:   0/256  (0.00%)
   (7) Swish:   0/256  (0.00%)
   (9) Swish:   0/256  (0.00%)
  (11) Swish:   0/128  (0.00%)
  (13) Swish:   0/128  (0.00%)
  (15) Swish:   0/128  (0.00%)
  (17) Swish:   0/128  (0.00%)
  (19) Swish:   0/128  (0.00%)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¬∂</a></h2>
<p>In this notebook, we have reviewed a set of six activation functions (sigmoid, tanh, ReLU, LeakyReLU, ELU, and Swish) in neural networks, and discussed how they influence the gradient distribution across layers. Sigmoid tends to fail deep neural networks as the highest gradient it provides is 0.25 leading to vanishing gradients in early layers. All ReLU-based activation functions have shown to perform well, and besides the original ReLU, do not have the issue of dead neurons. When implementing your own neural network, it is recommended to start with a ReLU-based network and select the specific activation function based on the properties of the network.</p>
</div>
<div class="section" id="appendix-downloading-pretrained-models">
<h2>Appendix: Downloading pretrained models<a class="headerlink" href="#appendix-downloading-pretrained-models" title="Permalink to this headline">¬∂</a></h2>
<p>In this section, we will show how to download pretrained models. These can be used to speed-up analysis and experiment cycles. First upload all model files in a GitHub repository. First, let‚Äôs delete these files since the script below skips existing files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>

<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span> <span class="o">/</span> <span class="s1">&#39;FashionMNIST_*&#39;</span><span class="p">)):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next we download all files from the repository.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">from</span> <span class="nn">urllib.error</span> <span class="kn">import</span> <span class="n">HTTPError</span>

<span class="c1"># Github URL where saved models are stored for this tutorial</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/&quot;</span>

<span class="c1"># Files to download</span>
<span class="n">pretrained_files</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;FashionMNIST_elu.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_elu.tar&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_leakyrelu.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_leakyrelu.tar&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;FashionMNIST_relu.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_relu.tar&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;FashionMNIST_sigmoid.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_sigmoid.tar&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;FashionMNIST_swish.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_swish.tar&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;FashionMNIST_tanh.config&quot;</span><span class="p">,</span> 
                    <span class="s2">&quot;FashionMNIST_tanh.tar&quot;</span><span class="p">]</span>

<span class="c1"># For each file, check whether it already exists. If not, try downloading it.</span>
<span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">pretrained_files</span><span class="p">:</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">CHECKPOINT_PATH</span> <span class="o">/</span> <span class="n">file_name</span>
    
    <span class="k">if</span> <span class="n">file_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_name</span><span class="si">:</span><span class="s2"> &lt;30</span><span class="si">}</span><span class="s2"> already exists. Skipping download.&quot;</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="ow">not</span> <span class="n">file_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
        <span class="n">file_url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="n">file_name</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Downloading </span><span class="si">{</span><span class="n">file_url</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">file_url</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_elu.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_elu.tar...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_leakyrelu.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_leakyrelu.tar...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_relu.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_relu.tar...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_sigmoid.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_sigmoid.tar...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_swish.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_swish.tar...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_tanh.config...
Downloading https://raw.githubusercontent.com/particle1331/saved_models/main/tutorial3/FashionMNIST_tanh.tar...
</pre></div>
</div>
</div>
</div>
<p>Finally, load the pretrained models and evaluate performance on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">act_fn_by_name</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s1">&#39;FashionMNIST_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">test_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: sigmoid    10.00 %
Test accuracy: tanh       87.59 %
Test accuracy: relu       88.62 %
Test accuracy: leakyrelu  88.92 %
Test accuracy: elu        87.27 %
Test accuracy: swish      88.73 %
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="pytorch-intro.html" title="previous page">Introduction to PyTorch</a>
    <a class='right-next' id="next-link" href="fastapi/ch3.html" title="next page">Developing a RESTful API</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ùó•ùóºùóª ùó†ùó≤ùó±ùó∂ùóªùóÆ. Powered by <a href="https://jupyterbook.org">Jupyter Book</a>.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>