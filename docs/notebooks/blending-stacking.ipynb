{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbebca8",
   "metadata": {
    "id": "053f56f1",
    "papermill": {
     "duration": 0.049766,
     "end_time": "2022-01-03T15:53:34.905082",
     "exception": false,
     "start_time": "2022-01-03T15:53:34.855316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Blending and Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfc5ee",
   "metadata": {
    "id": "28113721",
    "papermill": {
     "duration": 0.047543,
     "end_time": "2022-01-03T15:53:35.193026",
     "exception": false,
     "start_time": "2022-01-03T15:53:35.145483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook, we implement an ensembling technique called **stacking**. Ensemble machine learning methods combine multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms. That is, instead of getting predictions from a single best model, we combine predictions of multiple models.\n",
    "\n",
    "Many of the popular modern machine learning algorithms are actually ensemble methods. Bagging and random forests average predictions from many decision trees to reduce prediction variance and become robust to outliers and noise; ultimately leading to greater predictive accuracy. Boosted decision trees are another ensemble approach that slowly learns unique patterns in the data by sequentially combining individual, shallow trees. Observe that these two approaches combines similar models that are trained differently. Stacking, on the other hand, ensembles a diverse group of **strong learners**. That is, we combine any set of machine learning models, regardless of the architecture and training algorithm, as long as they are trained on the same task. \n",
    "\n",
    "Implementing stacking successfully mainly requires good cross-validation strategy between levels of prediction. In particular, we will demonstrate that maintaining the same cross-validation folds between levels, minimizes the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed560a",
   "metadata": {
    "editable": false,
    "id": "53f855cd",
    "papermill": {
     "duration": 0.057863,
     "end_time": "2022-01-03T15:53:35.304336",
     "exception": false,
     "start_time": "2022-01-03T15:53:35.246473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```{figure} ../img/stacking.png\n",
    "---\n",
    "width: 45em\n",
    "name: stacking\n",
    "---\n",
    "Stacking with $k$-fold cross-validation. Each new data point ${\\mathbf{x}^\\prime}^{[i]}$ has $T$ features corresponding to predictions of each base model for $\\mathbf{x}^{[i]}$. Note line 10 should be: \"**for** $i \\leftarrow 1$ to $n = |\\mathcal{D}_k|$ **do**\" where predictions are made on $\\mathbf{x}^{[i]} \\in \\mathcal{D}_k.$ {cite}`stat451`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844efea4",
   "metadata": {
    "editable": false,
    "id": "b18cedf4",
    "papermill": {
     "duration": 0.04709,
     "end_time": "2022-01-03T15:53:35.406155",
     "exception": false,
     "start_time": "2022-01-03T15:53:35.359065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```{figure} ../img/hypothesis_space.png\n",
    "---\n",
    "width: 45em\n",
    "name: hypothesis\n",
    "---\n",
    "An ensemble can have a larger hypothesis space than each single model. {cite}`stat451`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0ef8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:35.505149Z",
     "iopub.status.busy": "2022-01-03T15:53:35.503957Z",
     "iopub.status.idle": "2022-01-03T15:53:36.842647Z",
     "shell.execute_reply": "2022-01-03T15:53:36.843147Z",
     "shell.execute_reply.started": "2022-01-03T09:38:16.957485Z"
    },
    "papermill": {
     "duration": 1.389836,
     "end_time": "2022-01-03T15:53:36.843436",
     "exception": false,
     "start_time": "2022-01-03T15:53:35.453600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "import pathlib\n",
    "from enum import Enum\n",
    "from typing import Union, Any, List, Dict\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import minimize\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import model_selection, linear_model, metrics, decomposition, ensemble\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
    "\n",
    "from tqdm import tqdm\n",
    "from functools import partial, reduce\n",
    "from typing import List\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# config\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62631baf",
   "metadata": {
    "editable": false,
    "id": "4b2ae18d",
    "papermill": {
     "duration": 0.047063,
     "end_time": "2022-01-03T15:53:36.939032",
     "exception": false,
     "start_time": "2022-01-03T15:53:36.891969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959fd80",
   "metadata": {
    "editable": false,
    "id": "d5512e9b",
    "papermill": {
     "duration": 0.047663,
     "end_time": "2022-01-03T15:53:37.034846",
     "exception": false,
     "start_time": "2022-01-03T15:53:36.987183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dataset consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, with rating < 5 results in a sentiment score of 0, and rating ≥ 7 resulting in a sentiment score of 1. No individual movie has more than 30 reviews. [^dataref]\n",
    "\n",
    "[^dataref]: One should perform group $k$-fold so that two reviews of the same movie are all either in the train and test set. We will not do that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458ea946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:37.135810Z",
     "iopub.status.busy": "2022-01-03T15:53:37.135143Z",
     "iopub.status.idle": "2022-01-03T15:53:38.033517Z",
     "shell.execute_reply": "2022-01-03T15:53:38.034421Z",
     "shell.execute_reply.started": "2022-01-03T09:38:16.968126Z"
    },
    "papermill": {
     "duration": 0.952187,
     "end_time": "2022-01-03T15:53:38.034612",
     "exception": false,
     "start_time": "2022-01-03T15:53:37.082425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path('../../input/kumarmanoj-bag-of-words-meets-bags-of-popcorn')\n",
    "data = pd.read_csv(DATA_DIR / 'labeledTrainData.tsv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa75ba",
   "metadata": {
    "editable": false,
    "id": "684e067f",
    "papermill": {
     "duration": 0.04822,
     "end_time": "2022-01-03T15:53:38.131598",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.083378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca36e859",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:38.236652Z",
     "iopub.status.busy": "2022-01-03T15:53:38.235948Z",
     "iopub.status.idle": "2022-01-03T15:53:38.252222Z",
     "shell.execute_reply": "2022-01-03T15:53:38.251718Z",
     "shell.execute_reply.started": "2022-01-03T09:38:17.357297Z"
    },
    "id": "b8ddc93b",
    "outputId": "4f1165e0-b3a9-4f90-9000-22e518519660",
    "papermill": {
     "duration": 0.072538,
     "end_time": "2022-01-03T15:53:38.252351",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.179813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1) (20000,)\n",
      "(5000, 1) (5000,)\n"
     ]
    }
   ],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.20, shuffle=True, random_state=42)\n",
    "\n",
    "y_train = train.sentiment.values\n",
    "X_train = train[['review']]\n",
    "\n",
    "y_test = test.sentiment.values\n",
    "X_test = test[['review']]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877297f",
   "metadata": {
    "editable": false,
    "id": "f81cf982",
    "papermill": {
     "duration": 0.048156,
     "end_time": "2022-01-03T15:53:38.349288",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.301132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The `StackingClassifier` Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497f9dd",
   "metadata": {
    "id": "f9214ab8",
    "papermill": {
     "duration": 0.048207,
     "end_time": "2022-01-03T15:53:38.445966",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.397759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We define a class that automates training and prediction of stacked models. Several models can be trained on the training set whose predict probabilities can be used as **metafeatures** to train a **metamodel**. This process can be iterated to several more levels. To avoid creating meta-features that are overfitted to the train set, the metafeatures are generated by out-of-fold (OOF) training and prediction of the models on the features of the previous level. This requires defining cross-validation folds. The same cross-validation folds will be used to generate meta-features at deeper levels.\n",
    "\n",
    "After generating metafeatures, the models will be retrained on the whole training set on that. This increases accuracy of prediction during inference. Note that prediction on the test set simulates conditions when the model was trained with the test set essentially acting like an extra validation fold.\n",
    "\n",
    "\n",
    ":::{note}\n",
    "Alternatively, we could make predictions on the test dataset using each base model immediately after it gets fitted on each fold. In our case, this would generate five sets of predictions for each base model. Then, we would average the predictions per model to generate our metafeatures.\n",
    "\n",
    "One benefit to this is that it is less time consuming than the current approach since we won't have to retrain each model on the full training dataset. However, the test metafeatures are likely more accurate in the first approach since each base model was trained on the full training dataset (as opposed to 80% of the training dataset five times).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7b6a4",
   "metadata": {
    "editable": false,
    "id": "d8f858af",
    "papermill": {
     "duration": 0.048478,
     "end_time": "2022-01-03T15:53:38.543679",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.495201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that we **clone** models in the `model_dict_list` inside the `StackingCLassifier` object to avoid leaking state changes outside instances of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a2352e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:38.644461Z",
     "iopub.status.busy": "2022-01-03T15:53:38.643791Z",
     "iopub.status.idle": "2022-01-03T15:53:38.669939Z",
     "shell.execute_reply": "2022-01-03T15:53:38.670411Z",
     "shell.execute_reply.started": "2022-01-03T09:38:17.370626Z"
    },
    "papermill": {
     "duration": 0.078342,
     "end_time": "2022-01-03T15:53:38.670601",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.592259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackingClassifier:\n",
    "    \"\"\"Implements model stacking for classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "        models: List[Dict[str, Any]], \n",
    "        num_folds: int = NUM_FOLDS,\n",
    "        verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        models (dict) - List of dictionaries of name model pairs for each level. \n",
    "        verbose (bool) - Verbosity level.\n",
    "        num_folds (int) - No. of CV folds.\n",
    "\n",
    "        Example:\n",
    "        >>> models = [\n",
    "            {'level1_model1': level1_model1, 'level2_model2': level2_model2},\n",
    "            {'level2_model1': level2_model1},\n",
    "        ]\n",
    "        >>> stacked_model = StackingClassifier(models)\n",
    "        \"\"\"\n",
    "        self.models = [{name: clone(level[name]) for name in level} for level in models]\n",
    "        self.cv_scores_ = {}\n",
    "        self.metafeatures_ = None\n",
    "        self.verbose = verbose\n",
    "        self.num_folds = num_folds\n",
    "\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: np.array):\n",
    "        \"\"\"\n",
    "        Fit classifier. CV strategy: stratified 5-fold.\n",
    "        Inputs:\n",
    "            X (DataFrame) - features\n",
    "            y (numpy array) - targets\n",
    "        \"\"\"\n",
    "\n",
    "        # Create folds (add \"kfold\" column)\n",
    "        train = self._stratified_kfold_cv(X, y)\n",
    "\n",
    "        # Iterating over all stacking levels and over all models:\n",
    "        for level in range(len(self.models)):\n",
    "\n",
    "            # (1) Get features from predictions of models in the previous level.\n",
    "            feature_cols = self._get_feature_columns(train, level)\n",
    "            features = train[['target', 'kfold'] + feature_cols]            \n",
    "            \n",
    "            # (2) Create features for next level models using current predictions.  \n",
    "            for model_name in self.models[level].keys():\n",
    "                if self.verbose:\n",
    "                    print(f'\\nLevel {level} preds: {model_name}')\n",
    "                \n",
    "                model = self.models[level][model_name]\n",
    "                preds, aucs = self._generate_val_preds(features, model, self.verbose) \n",
    "                train[f'{model_name}_{level}'] = preds\n",
    "                self.cv_scores_[f'{model_name}_{level}'] = aucs\n",
    "        \n",
    "                # Train models on entire feature columns for inference.\n",
    "                model.fit(train[feature_cols], train.target.values)\n",
    "        \n",
    "        # Save learned metafeatures\n",
    "        levels = len(self.models)\n",
    "        metafeatures = [f'{n}_{m}' for m in range(levels) for n in self.models[m].keys()]\n",
    "        self.metafeatures_ = train[metafeatures]\n",
    "\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return classification probabilities.\"\"\"\n",
    "        \n",
    "        # Iterate over layers to make predictions.\n",
    "        X = X.copy()\n",
    "        for level in range(len(self.models)):\n",
    "\n",
    "            self.models[level] = self.models[level]\n",
    "            feature_cols = self._get_feature_columns(X, level)\n",
    "\n",
    "            # Append predictions to test DataFrame.\n",
    "            for model_name in self.models[level].keys():\n",
    "                model = self.models[level][model_name]\n",
    "                pred = model.predict_proba(X[feature_cols])[:, 1] \n",
    "                X.loc[:, f\"{model_name}_{level}\"] = pred\n",
    "\n",
    "        # Return last prediction, i.e. top-most model.\n",
    "        return np.c_[1 - pred, pred]\n",
    "\n",
    "    \n",
    "    def _stratified_kfold_cv(self, X, y):\n",
    "        data = X.copy().reset_index(drop=True)\n",
    "        data['target'] = y\n",
    "        data['kfold'] = -1\n",
    "        skf = model_selection.StratifiedKFold(n_splits=self.num_folds)\n",
    "        for fold, (_, val_) in enumerate(skf.split(data, data.target)):\n",
    "            data.loc[val_, \"kfold\"] = fold\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _get_feature_columns(self, data, level):\n",
    "        if level == 0:\n",
    "            features = data.drop(['target', 'kfold'], axis=1, errors=\"ignore\")\n",
    "            feature_cols = features.columns.tolist()\n",
    "        else:\n",
    "            prev_level = self.models[level-1].keys()\n",
    "            feature_cols = [f'{name}_{level-1}' for name in prev_level]\n",
    "        return feature_cols\n",
    "\n",
    "    \n",
    "    def _generate_val_preds(self, data, model, verbose):\n",
    "        val_preds = []\n",
    "        val_aucs = []\n",
    "        for j in range(data.kfold.nunique()):\n",
    "            val_pred, val_auc = self._val_pred(data, model, j, verbose)\n",
    "            val_preds.append(val_pred)\n",
    "            val_aucs.append(val_auc)\n",
    "        return np.concatenate(val_preds), val_aucs\n",
    "\n",
    "    \n",
    "    def _val_pred(self, data, model, fold, verbose):\n",
    "        \"Return out-of-fold predictions: train on K-1 folds, predict on fold K.\"\n",
    "\n",
    "        # Get folds; include target and feature cols.\n",
    "        data_trn = data[data.kfold != fold]\n",
    "        data_val = data[data.kfold == fold]\n",
    "        \n",
    "        # Fit model.\n",
    "        model.fit(data_trn, data_trn.target.values)\n",
    "        val_pred = model.predict_proba(data_val)[:, 1] \n",
    "        auc = metrics.roc_auc_score(data_val.target.values, val_pred)\n",
    "        if verbose:\n",
    "            print(f\"fold={fold}, auc={auc}\")\n",
    "\n",
    "        # Return out-of-fold predictions.\n",
    "        return val_pred, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd8de1",
   "metadata": {
    "editable": false,
    "id": "42494105",
    "papermill": {
     "duration": 0.048737,
     "end_time": "2022-01-03T15:53:38.768099",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.719362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Blending prediction probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820c84b",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2021-08-23T17:34:52.241474Z",
     "iopub.status.busy": "2021-08-23T17:34:52.240952Z",
     "iopub.status.idle": "2021-08-23T17:34:52.256728Z",
     "shell.execute_reply": "2021-08-23T17:34:52.255385Z",
     "shell.execute_reply.started": "2021-08-23T17:34:52.241439Z"
    },
    "id": "eef6d053",
    "papermill": {
     "duration": 0.048313,
     "end_time": "2022-01-03T15:53:38.865324",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.817011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's start with a simple stacked model where we simply perform a weighted average of the prediction probabilities. This method is called **blending**. We will use three base models to generate probabilities. Hopefully these are uncorrelated:\n",
    "1. Logistic Regression + TF-IDF\n",
    "2. Logistic Regression + Count Vectorizer\n",
    "3. Random Forest + TF-IDF + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738a338a",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:38.968823Z",
     "iopub.status.busy": "2022-01-03T15:53:38.966202Z",
     "iopub.status.idle": "2022-01-03T15:53:38.970768Z",
     "shell.execute_reply": "2022-01-03T15:53:38.971416Z",
     "shell.execute_reply.started": "2022-01-03T09:38:17.395547Z"
    },
    "id": "3bbc61cf",
    "papermill": {
     "duration": 0.05759,
     "end_time": "2022-01-03T15:53:38.971595",
     "exception": false,
     "start_time": "2022-01-03T15:53:38.914005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReviewColumnExtractor(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Extract text column, e.g. letting X = df_train[['review']]\n",
    "    as train dataset for TfidfVectorizer and CountVectorizer does\n",
    "    not work as expected.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc618b",
   "metadata": {
    "editable": false,
    "id": "767710ae",
    "papermill": {
     "duration": 0.04857,
     "end_time": "2022-01-03T15:53:39.068376",
     "exception": false,
     "start_time": "2022-01-03T15:53:39.019806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize base models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff7fccf",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:39.168342Z",
     "iopub.status.busy": "2022-01-03T15:53:39.167728Z",
     "iopub.status.idle": "2022-01-03T15:53:39.174447Z",
     "shell.execute_reply": "2022-01-03T15:53:39.173900Z",
     "shell.execute_reply.started": "2022-01-03T09:38:17.411612Z"
    },
    "id": "efe7c6e5",
    "papermill": {
     "duration": 0.057505,
     "end_time": "2022-01-03T15:53:39.174596",
     "exception": false,
     "start_time": "2022-01-03T15:53:39.117091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    TfidfVectorizer(max_features=1000),\n",
    "    linear_model.LogisticRegression(random_state=42)\n",
    ")\n",
    "\n",
    "lr_cnt = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    CountVectorizer(),\n",
    "    linear_model.LogisticRegression(solver='liblinear', random_state=42)\n",
    ")\n",
    "\n",
    "rf_svd = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    TfidfVectorizer(max_features=None),\n",
    "    decomposition.TruncatedSVD(n_components=120, random_state=42),\n",
    "    ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3097f64",
   "metadata": {
    "editable": false,
    "id": "f8b3740a",
    "papermill": {
     "duration": 0.047813,
     "end_time": "2022-01-03T15:53:39.270852",
     "exception": false,
     "start_time": "2022-01-03T15:53:39.223039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5355b097",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:53:39.376092Z",
     "iopub.status.busy": "2022-01-03T15:53:39.375446Z",
     "iopub.status.idle": "2022-01-03T15:57:47.284449Z",
     "shell.execute_reply": "2022-01-03T15:57:47.283762Z",
     "shell.execute_reply.started": "2022-01-03T09:38:17.424098Z"
    },
    "id": "166d801f",
    "outputId": "5694267b-47e7-4117-fdf6-0a8b877a1afa",
    "papermill": {
     "duration": 247.965144,
     "end_time": "2022-01-03T15:57:47.284610",
     "exception": false,
     "start_time": "2022-01-03T15:53:39.319466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0 preds: lr\n",
      "fold=0, auc=0.9381197524790099\n",
      "fold=1, auc=0.9324757299029196\n",
      "fold=2, auc=0.9339827359309438\n",
      "fold=3, auc=0.9294992179968721\n",
      "fold=4, auc=0.9271420860696936\n",
      "\n",
      "Level 0 preds: lr_cnt\n",
      "fold=0, auc=0.9485602942411769\n",
      "fold=1, auc=0.9419147676590707\n",
      "fold=2, auc=0.9474275397101588\n",
      "fold=3, auc=0.943625774503098\n",
      "fold=4, auc=0.9382201109952497\n",
      "\n",
      "Level 0 preds: rf_svd\n",
      "fold=0, auc=0.8831412825651302\n",
      "fold=1, auc=0.8762381299525198\n",
      "fold=2, auc=0.8792050168200674\n",
      "fold=3, auc=0.8731112424449698\n",
      "fold=4, auc=0.8795378539601714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.StackingClassifier at 0x280060820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basemodels = {'lr': lr, 'lr_cnt': lr_cnt, 'rf_svd': rf_svd}\n",
    "stack = StackingClassifier([basemodels])\n",
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017b6411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:47.403614Z",
     "iopub.status.busy": "2022-01-03T15:57:47.402946Z",
     "iopub.status.idle": "2022-01-03T15:57:47.409337Z",
     "shell.execute_reply": "2022-01-03T15:57:47.409958Z",
     "shell.execute_reply.started": "2022-01-03T09:38:24.969448Z"
    },
    "papermill": {
     "duration": 0.070856,
     "end_time": "2022-01-03T15:57:47.410119",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.339263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>rf_svd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052181</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917899</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982799</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.531607</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.713444</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.882874</td>\n",
       "      <td>0.992238</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.639375</td>\n",
       "      <td>0.907093</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.134785</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lr_0  lr_cnt_0  rf_svd_0\n",
       "0      0.052181  0.001930      0.27\n",
       "1      0.029885  0.000006      0.30\n",
       "2      0.052702  0.000440      0.32\n",
       "3      0.917899  0.996462      0.65\n",
       "4      0.982799  0.999165      0.86\n",
       "...         ...       ...       ...\n",
       "19995  0.531607  0.047658      0.55\n",
       "19996  0.713444  0.999911      0.58\n",
       "19997  0.882874  0.992238      0.75\n",
       "19998  0.639375  0.907093      0.70\n",
       "19999  0.134785  0.000208      0.49\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.metafeatures_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cf295",
   "metadata": {
    "editable": false,
    "id": "fb619a21",
    "papermill": {
     "duration": 0.054452,
     "end_time": "2022-01-03T15:57:47.519475",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.465023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check if basemodels are uncorrelated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bde526f",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:47.631443Z",
     "iopub.status.busy": "2022-01-03T15:57:47.630537Z",
     "iopub.status.idle": "2022-01-03T15:57:47.644574Z",
     "shell.execute_reply": "2022-01-03T15:57:47.644042Z",
     "shell.execute_reply.started": "2022-01-03T09:38:24.985354Z"
    },
    "id": "334b3b59",
    "outputId": "43ebf3fa-8b42-44f8-a978-e9a0f236be33",
    "papermill": {
     "duration": 0.071072,
     "end_time": "2022-01-03T15:57:47.644707",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.573635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>rf_svd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884571</td>\n",
       "      <td>0.832398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <td>0.884571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_svd_0</th>\n",
       "      <td>0.832398</td>\n",
       "      <td>0.727050</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lr_0  lr_cnt_0  rf_svd_0\n",
       "lr_0      1.000000  0.884571  0.832398\n",
       "lr_cnt_0  0.884571  1.000000  0.727050\n",
       "rf_svd_0  0.832398  0.727050  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.metafeatures_.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b190b9",
   "metadata": {
    "editable": false,
    "id": "88635821",
    "papermill": {
     "duration": 0.054681,
     "end_time": "2022-01-03T15:57:47.754535",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.699854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model saves learned probabilistic features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7df112",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:47.869858Z",
     "iopub.status.busy": "2022-01-03T15:57:47.868237Z",
     "iopub.status.idle": "2022-01-03T15:57:47.881042Z",
     "shell.execute_reply": "2022-01-03T15:57:47.880306Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.005861Z"
    },
    "id": "3278c3b0",
    "outputId": "7dcb431b-d2d2-4fbd-cf20-07f319d12874",
    "papermill": {
     "duration": 0.071755,
     "end_time": "2022-01-03T15:57:47.881222",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.809467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>rf_svd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052181</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917899</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982799</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr_0  lr_cnt_0  rf_svd_0\n",
       "0  0.052181  0.001930      0.27\n",
       "1  0.029885  0.000006      0.30\n",
       "2  0.052702  0.000440      0.32\n",
       "3  0.917899  0.996462      0.65\n",
       "4  0.982799  0.999165      0.86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(stack.metafeatures_.shape)\n",
    "stack.metafeatures_.head() # predict probas for each example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e049956",
   "metadata": {
    "editable": false,
    "id": "57e2ff2c",
    "papermill": {
     "duration": 0.055671,
     "end_time": "2022-01-03T15:57:47.993431",
     "exception": false,
     "start_time": "2022-01-03T15:57:47.937760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also check scores of the base models on each validation fold. This informs us of the stability of the folds and the cross-validation performance of the base models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494df881",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:48.115042Z",
     "iopub.status.busy": "2022-01-03T15:57:48.114403Z",
     "iopub.status.idle": "2022-01-03T15:57:48.128752Z",
     "shell.execute_reply": "2022-01-03T15:57:48.129272Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.023344Z"
    },
    "id": "a2750309",
    "outputId": "99bbbea9-8efc-4650-9efd-806fe7a1f3cb",
    "papermill": {
     "duration": 0.080194,
     "end_time": "2022-01-03T15:57:48.129444",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.049250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>rf_svd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.932244</td>\n",
       "      <td>0.943950</td>\n",
       "      <td>0.878247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr_0  lr_cnt_0  rf_svd_0\n",
       "mean  0.932244  0.943950  0.878247\n",
       "std   0.004218  0.004196  0.003773"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566a426",
   "metadata": {
    "editable": false,
    "id": "d491cec1",
    "papermill": {
     "duration": 0.062375,
     "end_time": "2022-01-03T15:57:48.248081",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.185706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try to blend the probabilities using some hand-designed coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e0ca74",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:48.380626Z",
     "iopub.status.busy": "2022-01-03T15:57:48.379693Z",
     "iopub.status.idle": "2022-01-03T15:57:48.436151Z",
     "shell.execute_reply": "2022-01-03T15:57:48.436869Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.047993Z"
    },
    "id": "2429bd72",
    "outputId": "6a078541-bb31-4dd2-8ac9-445060683b1b",
    "papermill": {
     "duration": 0.116698,
     "end_time": "2022-01-03T15:57:48.437093",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.320395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC (averaged):      0.9320632947484941\n",
      "Train AUC (wtd. avg):      0.9333874895288372\n",
      "Train AUC (rank avg):      0.9279256398115597\n",
      "Train AUC (wtd. rank avg): 0.9338361261484154\n"
     ]
    }
   ],
   "source": [
    "# roc is scale invariant, so we dont bother dividing by total weights\n",
    "avg_preds = (stack.metafeatures_ * [1, 1, 1]).sum(axis=1)\n",
    "wtd_preds = (stack.metafeatures_ * [1, 3, 1]).sum(axis=1)\n",
    "rank_avg_preds = (stack.metafeatures_.rank() * [1, 1, 1]).sum(axis=1)\n",
    "rank_wtd_preds = (stack.metafeatures_.rank() * [1, 3, 1]).sum(axis=1)\n",
    "\n",
    "# Calculate AUC over combined OOF preds\n",
    "print(f\"Train AUC (averaged):     \", metrics.roc_auc_score(y_train, avg_preds))\n",
    "print(f\"Train AUC (wtd. avg):     \", metrics.roc_auc_score(y_train, wtd_preds))\n",
    "print(f\"Train AUC (rank avg):     \", metrics.roc_auc_score(y_train, rank_avg_preds)) \n",
    "print(f\"Train AUC (wtd. rank avg):\", metrics.roc_auc_score(y_train, rank_wtd_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e40e3",
   "metadata": {},
   "source": [
    "### Finding blending coefficients that optimize AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae6fcb",
   "metadata": {
    "editable": false,
    "id": "289771ae",
    "papermill": {
     "duration": 0.055919,
     "end_time": "2022-01-03T15:57:48.549668",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.493749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since these coefficients are hand-designed, we may want to devise a strategy for automatically finding the optimal coefficients for blending. This is accomplished by the folowing class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2197dca3",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:48.674273Z",
     "iopub.status.busy": "2022-01-03T15:57:48.673619Z",
     "iopub.status.idle": "2022-01-03T15:57:48.676058Z",
     "shell.execute_reply": "2022-01-03T15:57:48.675561Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.072447Z"
    },
    "id": "29872038",
    "papermill": {
     "duration": 0.070601,
     "end_time": "2022-01-03T15:57:48.676190",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.605589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Blender(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Implement blending that maximizes AUC score.\"\"\"\n",
    "    \n",
    "    def __init__(self, rank=False, random_state=42):\n",
    "        self.coef_ = None\n",
    "        self.rank = rank\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find optimal blending coefficients.\"\"\"\n",
    "        \n",
    "        if self.rank:\n",
    "            X = X.rank()\n",
    "\n",
    "        self.coef_ = self._optimize_auc(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return blended probabilities for class 0 and class 1.\"\"\"\n",
    "        \n",
    "        if self.rank:\n",
    "            X = X.rank()\n",
    "            \n",
    "        pred = np.sum(X * self.coef_, axis=1)\n",
    "        return np.c_[1 - pred, pred]\n",
    "\n",
    "    def _auc(self, coef, X, y):\n",
    "        \"\"\"Calculate AUC of blended predict probas.\"\"\"\n",
    "\n",
    "        auc = metrics.roc_auc_score(y, np.sum(X * coef, axis=1))\n",
    "        return -1.0 * auc # min -auc = max auc\n",
    "    \n",
    "    def _optimize_auc(self, X, y):\n",
    "        \"\"\"Maximize AUC as a bound-constrained optimization problem using Nelder-Mead \n",
    "        method with Dirichlet init. \n",
    "        \n",
    "        Reference: \n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
    "        \"\"\"\n",
    "        partial_loss = partial(self._auc, X=X, y=y) \n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        init_coef = rng.dirichlet(np.ones(X.shape[1]))\n",
    "        return minimize(partial_loss, init_coef, \n",
    "                        method='Nelder-Mead', \n",
    "                        bounds=[(0, 1)]*X.shape[1])['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a803da",
   "metadata": {
    "editable": false,
    "id": "5b09fb0a",
    "papermill": {
     "duration": 0.056499,
     "end_time": "2022-01-03T15:57:48.789764",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.733265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This implementation uses `partial` from `functools` and `minimize` from `scipy.optimize` to minimize the coefficients constained in $(0, 1).$ The initial values of the coefficient are drawn from a Dirichlet distribution $\\operatorname{Dir}(\\boldsymbol{\\alpha})$ with $\\boldsymbol{\\alpha} = [1, 1, 1].$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26caa7b2",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:48.911396Z",
     "iopub.status.busy": "2022-01-03T15:57:48.906945Z",
     "iopub.status.idle": "2022-01-03T15:57:50.600327Z",
     "shell.execute_reply": "2022-01-03T15:57:50.599815Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.085816Z"
    },
    "id": "52fbbcfd",
    "outputId": "a589904b-db25-4200-fa04-bd80dceaf659",
    "papermill": {
     "duration": 1.754157,
     "end_time": "2022-01-03T15:57:50.600479",
     "exception": false,
     "start_time": "2022-01-03T15:57:48.846322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC (Blended):     0.9335436800926852\n",
      "Train AUC (Blended rk.): 0.9343620830471198\n"
     ]
    }
   ],
   "source": [
    "# Blended predictions\n",
    "blender = Blender()\n",
    "blender.fit(stack.metafeatures_, y_train)\n",
    "combined_oof_preds = blender.predict_proba(stack.metafeatures_)[:, 1]\n",
    "\n",
    "# Blended ranked predictions\n",
    "blender_rk = Blender(rank=True)\n",
    "blender_rk.fit(stack.metafeatures_, y_train)\n",
    "combined_oof_rk_preds = blender_rk.predict_proba(stack.metafeatures_)[:, 1]\n",
    "\n",
    "print(f\"Train AUC (Blended):    \", metrics.roc_auc_score(y_train, combined_oof_preds))\n",
    "print(f\"Train AUC (Blended rk.):\", metrics.roc_auc_score(y_train, combined_oof_rk_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e46f4",
   "metadata": {
    "editable": false,
    "id": "468c1747",
    "papermill": {
     "duration": 0.056855,
     "end_time": "2022-01-03T15:57:50.714191",
     "exception": false,
     "start_time": "2022-01-03T15:57:50.657336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These scores beat the scores for hand-designed ones. Note that the model is not overfitted. This motivates why we take out-of-fold predictions to create meta-features. In fact, the train AUC should be a good approximation of the test AUC. Calculating the train AUC on the entire out-of-fold predictions involves tracking the rows of the confusion matrix that is the sum of the confusion matrices for each fold, over all thresholds. On the other hand, the average AUC scores on CV folds involves tracking each confusion matrix separately to compute the AUC, then averaging the resulting individual AUCs. Thus, train and test AUCs should be similar to cross-validation scores, if error is well-distributed between folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2475ed2",
   "metadata": {
    "papermill": {
     "duration": 0.056367,
     "end_time": "2022-01-03T15:57:50.827150",
     "exception": false,
     "start_time": "2022-01-03T15:57:50.770783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We don't want to retrain the stacked models with the blender at the top. So we just hack into the trained models to make inference on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cc38fe",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:51.015631Z",
     "iopub.status.busy": "2022-01-03T15:57:50.978888Z",
     "iopub.status.idle": "2022-01-03T15:57:55.492582Z",
     "shell.execute_reply": "2022-01-03T15:57:55.493105Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.421637Z"
    },
    "id": "97c43440",
    "outputId": "d7b36210-acb6-4607-d125-844240a299f8",
    "papermill": {
     "duration": 4.609598,
     "end_time": "2022-01-03T15:57:55.493275",
     "exception": false,
     "start_time": "2022-01-03T15:57:50.883677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC (Blended):     0.9537213269438443\n",
      "Test AUC (Blended rk.): 0.9535875592174204\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "test_features = []\n",
    "for model_name in stack.models[0].keys():\n",
    "    test_features.append(stack.models[0][model_name].predict_proba(X_test)[:, 1])\n",
    "\n",
    "test_features = pd.DataFrame(test_features).T\n",
    "test_pred = blender.predict_proba(test_features)[:, 1]\n",
    "test_rk_pred = blender_rk.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Test AUC (Blended):    ', metrics.roc_auc_score(y_test, test_pred))\n",
    "print('Test AUC (Blended rk.):', metrics.roc_auc_score(y_test, test_rk_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696a63f",
   "metadata": {},
   "source": [
    "### Blender as final stacker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b85474",
   "metadata": {
    "papermill": {
     "duration": 0.058368,
     "end_time": "2022-01-03T15:57:55.609528",
     "exception": false,
     "start_time": "2022-01-03T15:57:55.551160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Actually, let's do that. Seems all stochasticity has been taken care of!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9992d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T15:57:55.732754Z",
     "iopub.status.busy": "2022-01-03T15:57:55.732139Z",
     "iopub.status.idle": "2022-01-03T16:06:30.177407Z",
     "shell.execute_reply": "2022-01-03T16:06:30.178387Z",
     "shell.execute_reply.started": "2022-01-03T09:38:25.608176Z"
    },
    "papermill": {
     "duration": 514.511919,
     "end_time": "2022-01-03T16:06:30.178722",
     "exception": false,
     "start_time": "2022-01-03T15:57:55.666803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC (Blended):     0.9537213269438443\n",
      "Test AUC (Blended rk.): 0.9535875592174204\n"
     ]
    }
   ],
   "source": [
    "stack = StackingClassifier([basemodels, {'blender': Blender()}], verbose=False)\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "stack_rk = StackingClassifier([basemodels, {'blender_rk': Blender(rank=True)}], verbose=False)\n",
    "stack_rk.fit(X_train, y_train)\n",
    "\n",
    "print('Test AUC (Blended):    ', metrics.roc_auc_score(y_test, stack.predict_proba(X_test)[:, 1]))\n",
    "print('Test AUC (Blended rk.):', metrics.roc_auc_score(y_test, stack_rk.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e3829",
   "metadata": {
    "editable": false,
    "id": "a20d8200",
    "papermill": {
     "duration": 0.057882,
     "end_time": "2022-01-03T16:06:30.295557",
     "exception": false,
     "start_time": "2022-01-03T16:06:30.237675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ":::{tip}\n",
    "Using blended **rank probabilities** is a good trick when optimizing AUC score. Here individual probabilities are replaced by their rank index. Recall that AUC only cares about the predict probability of a randomly chosen negative examples to be assigned lower predict proba than a randomly chosen positive example. Note that this only works for ensembles; for single models using rank probabilities does not affect AUC score.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68437ac",
   "metadata": {
    "editable": false,
    "id": "033f7e39",
    "papermill": {
     "duration": 0.057958,
     "end_time": "2022-01-03T16:06:30.411852",
     "exception": false,
     "start_time": "2022-01-03T16:06:30.353894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGBoost classifier as final stacker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c263b09",
   "metadata": {
    "editable": false,
    "id": "98f895d7",
    "papermill": {
     "duration": 0.057368,
     "end_time": "2022-01-03T16:06:30.527033",
     "exception": false,
     "start_time": "2022-01-03T16:06:30.469665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Blending can be easily generalized to any machine learning model that learns and predicts with the meta-features. For example, we can train an `XGBoostClassifier` on the meta-features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d4e18c",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T16:06:30.651911Z",
     "iopub.status.busy": "2022-01-03T16:06:30.651010Z",
     "iopub.status.idle": "2022-01-03T16:10:41.540015Z",
     "shell.execute_reply": "2022-01-03T16:10:41.540524Z",
     "shell.execute_reply.started": "2022-01-03T09:38:43.558886Z"
    },
    "id": "9d4a3eee",
    "outputId": "1e5102cf-7e96-4214-a610-fe99b05c5d54",
    "papermill": {
     "duration": 250.955922,
     "end_time": "2022-01-03T16:10:41.540731",
     "exception": false,
     "start_time": "2022-01-03T16:06:30.584809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0 preds: lr\n",
      "fold=0, auc=0.9381197524790099\n",
      "fold=1, auc=0.9324757299029196\n",
      "fold=2, auc=0.9339827359309438\n",
      "fold=3, auc=0.9294992179968721\n",
      "fold=4, auc=0.9271420860696936\n",
      "\n",
      "Level 0 preds: lr_cnt\n",
      "fold=0, auc=0.9485602942411769\n",
      "fold=1, auc=0.9419147676590707\n",
      "fold=2, auc=0.9474275397101588\n",
      "fold=3, auc=0.943625774503098\n",
      "fold=4, auc=0.9382201109952497\n",
      "\n",
      "Level 0 preds: rf_svd\n",
      "fold=0, auc=0.8831412825651302\n",
      "fold=1, auc=0.8762381299525198\n",
      "fold=2, auc=0.8792050168200674\n",
      "fold=3, auc=0.8731112424449698\n",
      "fold=4, auc=0.8795378539601714\n",
      "\n",
      "Level 1 preds: xgb\n",
      "fold=0, auc=1.0\n",
      "fold=1, auc=1.0\n",
      "fold=2, auc=1.0\n",
      "fold=3, auc=1.0\n",
      "fold=4, auc=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.StackingClassifier at 0x2822163d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basemodels = {'lr': lr, 'lr_cnt': lr_cnt, 'rf_svd': rf_svd}\n",
    "metamodel = {'xgb': XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)}\n",
    "stack = StackingClassifier([basemodels, metamodel])\n",
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4068e0ad",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T16:10:41.674731Z",
     "iopub.status.busy": "2022-01-03T16:10:41.674041Z",
     "iopub.status.idle": "2022-01-03T16:11:03.561545Z",
     "shell.execute_reply": "2022-01-03T16:11:03.562656Z",
     "shell.execute_reply.started": "2022-01-03T09:38:52.567083Z"
    },
    "id": "96b0b35f",
    "outputId": "1f8cf851-5e91-49fb-b304-39581f6c4e01",
    "papermill": {
     "duration": 21.956799,
     "end_time": "2022-01-03T16:11:03.562941",
     "exception": false,
     "start_time": "2022-01-03T16:10:41.606142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC (XGB stack): 0.9998198793497644\n",
      "Test  AUC (XGB stack): 0.9490586576280645\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train AUC (XGB stack):\", metrics.roc_auc_score(y_train, stack.predict_proba(X_train)[:, 1]))\n",
    "print(f\"Test  AUC (XGB stack):\", metrics.roc_auc_score(y_test, stack.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c6f0e4",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:03.720409Z",
     "iopub.status.busy": "2022-01-03T16:11:03.713246Z",
     "iopub.status.idle": "2022-01-03T16:11:03.734697Z",
     "shell.execute_reply": "2022-01-03T16:11:03.734048Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.093515Z"
    },
    "id": "ff8fcd4b",
    "outputId": "ff07b3aa-1859-488d-8d43-f0352c4686cb",
    "papermill": {
     "duration": 0.099638,
     "end_time": "2022-01-03T16:11:03.734878",
     "exception": false,
     "start_time": "2022-01-03T16:11:03.635240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>rf_svd_0</th>\n",
       "      <th>xgb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.932244</td>\n",
       "      <td>0.943950</td>\n",
       "      <td>0.878247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lr_0  lr_cnt_0  rf_svd_0  xgb_1\n",
       "mean  0.932244  0.943950  0.878247    1.0\n",
       "std   0.004218  0.004196  0.003773    0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stack.cv_scores_).describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a026a",
   "metadata": {
    "editable": false,
    "id": "7245ea4a",
    "papermill": {
     "duration": 0.06989,
     "end_time": "2022-01-03T16:11:03.878613",
     "exception": false,
     "start_time": "2022-01-03T16:11:03.808723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observe that cross-validated AUC scores is indicative of test performance. Meanwhile, train AUC is useless. A better estimate is the mean cross-validation AUC score. If we assume that each fold has the same error distribution, then this should approximate the test AUC which can be thought of as predicting on another fold. Indeed, the above results supports this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73bbbc",
   "metadata": {
    "editable": false,
    "id": "c8131d00",
    "papermill": {
     "duration": 0.073816,
     "end_time": "2022-01-03T16:11:04.023521",
     "exception": false,
     "start_time": "2022-01-03T16:11:03.949705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parallelizing Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd2b46",
   "metadata": {
    "editable": false,
    "id": "b301de4e",
    "papermill": {
     "duration": 0.071563,
     "end_time": "2022-01-03T16:11:04.168931",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.097368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generating features require training each model on each fold. This is very slow. Note that each training process are independent of each other (they only use static features from the previous level), so in principle can be easily parallelized. For this task, we parallelize only the training on cross-validation folds. During inference, parallelizing results in worse times, likely due to overhead. \n",
    "\n",
    "We implement parallelizing training on CV folds using `joblib.Parallel`. Some remarks:\n",
    "\n",
    "* Setting `backend='loky'` is important. On a Macbook 2015 with Mojave 10.14.6, setting `backend='multiprocessing'` with an XGBoost classifier causes training to hang. In a Kaggle kernel, `multiprocessing` doesn't seem to work at all, even without using an XGBoost model. Using the `loky` backend seems to work consistently across platforms. \n",
    "\n",
    "+++\n",
    "\n",
    "* Setting `nthread=1` for XGBClassifier decreases train trime from ~250s to ~100s with backend `loky` and `n_jobs=-1`. Note that the former time is way worse than sequential evaluation. \n",
    "\n",
    "+++\n",
    "\n",
    "* Joblib pickles every object used inside `Parallel`. Best to use stateless objects. Careful about shared memory. Using `n_jobs=1` turns off parallel computing for debugging.\n",
    "\n",
    "Results below show that there is significant speed up with parallelization using the `loky` backend. Consider this implementation the current stable version of our implementation of stacking in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485658f",
   "metadata": {
    "editable": false,
    "id": "7c42b261",
    "papermill": {
     "duration": 0.072991,
     "end_time": "2022-01-03T16:11:04.315821",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.242830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adding workers to `StackingClassifier` using `joblib.Parallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "928dc8c0",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:04.470148Z",
     "iopub.status.busy": "2022-01-03T16:11:04.469195Z",
     "iopub.status.idle": "2022-01-03T16:11:04.471874Z",
     "shell.execute_reply": "2022-01-03T16:11:04.471306Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.121891Z"
    },
    "id": "faba716c",
    "papermill": {
     "duration": 0.08158,
     "end_time": "2022-01-03T16:11:04.472018",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.390438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearRegressionClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Linear regression for model-based AUC optimization.\n",
    "    Note that we transform probabilities to rank probabilities!\"\"\"\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.lr = linear_model.LinearRegression()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.lr.fit(pd.DataFrame(X).rank(), y)\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        return np.c_[[0]*len(X), self.lr.predict(pd.DataFrame(X).rank())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fea235",
   "metadata": {
    "papermill": {
     "duration": 0.070337,
     "end_time": "2022-01-03T16:11:04.616146",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.545809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This defines a linear regression ranking model. Next, we finally implement stacking with parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c24cb643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:04.765222Z",
     "iopub.status.busy": "2022-01-03T16:11:04.759345Z",
     "iopub.status.idle": "2022-01-03T16:11:04.788820Z",
     "shell.execute_reply": "2022-01-03T16:11:04.788209Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.129901Z"
    },
    "papermill": {
     "duration": 0.102648,
     "end_time": "2022-01-03T16:11:04.788976",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.686328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackingClassifierParallel:\n",
    "    \"\"\"Implements model stacking for classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "        models: List[Dict[str, Any]], \n",
    "        num_folds: int = NUM_FOLDS,\n",
    "        n_jobs: int = 1, \n",
    "        backend: str = 'loky',\n",
    "        verbose: int=1):\n",
    "        \"\"\"\n",
    "        Initialize by passing list of model dictionaries for each level.\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        models: List of dictionaries of name model pairs for each level. \n",
    "        verbose: Verbosity level.\n",
    "        num_folds: No. of CV folds.\n",
    "        n_jobs:  passed to an internal joblib.Parallel object\n",
    "        backend: passed to an internal joblib.Parallel object\n",
    "        verbose: passed to an internal joblib.Parallel object\n",
    "        See: https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html\n",
    "        \n",
    "        Example:\n",
    "        >>> models = [\n",
    "            {'level1_model1': level1_model1, 'level2_model2': level2_model2},\n",
    "            {'level2_model1': level2_model1},\n",
    "        ]\n",
    "        >>> stacked_model = StackingClassifier(models)\n",
    "        \"\"\"\n",
    "        self.models = [{name: clone(level[name]) for name in level} for level in models]\n",
    "        self.cv_scores_ = {}\n",
    "        self.metafeatures_ = None\n",
    "        self.verbose = verbose\n",
    "        self.num_folds = num_folds\n",
    "        self.n_jobs = n_jobs\n",
    "        self.backend = backend\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: np.array):\n",
    "        \"\"\"\n",
    "        Fit classifier. CV strategy: stratified 5-fold.\n",
    "        Inputs:\n",
    "            X (DataFrame) - features\n",
    "            y (numpy array) - targets\n",
    "        \"\"\"\n",
    "        # Create folds (add \"kfold\" column)\n",
    "        train = self._stratified_kfold_cv(X, y)\n",
    "\n",
    "        # Iterating over all stacking levels and over all models:\n",
    "        for level in range(len(self.models)):\n",
    "\n",
    "            # (1) Get features from predictions of models in the previous level.\n",
    "            feature_cols = self._get_feature_columns(train, level)\n",
    "            features = train[['target', 'kfold'] + feature_cols] \n",
    "                \n",
    "            # Parallel context manager: prevents discarding workers for each model.\n",
    "            with Parallel(n_jobs=self.n_jobs, backend=self.backend, verbose=self.verbose) as parallel:\n",
    "                \n",
    "                # (2) Create features for next level models using current predictions. \n",
    "                for model_name in tqdm(self.models[level].keys(), leave=False):\n",
    "                    if self.verbose:\n",
    "                        print(f'\\nLevel {level} preds: {model_name}')\n",
    "                                    \n",
    "                    model = self.models[level][model_name]\n",
    "                    preds, aucs = self._generate_fold_preds(\n",
    "                        parallel, features, model, self.verbose)\n",
    "                                        \n",
    "                    train[f'{model_name}_{level}'] = np.concatenate(preds)\n",
    "                    self.cv_scores_[f'{model_name}_{level}'] = aucs\n",
    "                    \n",
    "                    # Train models on entire feature columns for inference.\n",
    "                    model.fit(train[feature_cols], train.target.values) \n",
    "        \n",
    "        # Save learned metafeatures\n",
    "        levels = len(self.models)\n",
    "        metafeatures = [f'{n}_{m}' for m in range(levels) for n in self.models[m].keys()]\n",
    "        self.metafeatures_ = train[metafeatures]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return classification probabilities.\"\"\"\n",
    "        \n",
    "        # Iterate over layers to make predictions.\n",
    "        X = X.copy()\n",
    "        for level in range(len(self.models)):\n",
    "\n",
    "            self.models[level] = self.models[level]\n",
    "            feature_cols = self._get_feature_columns(X, level)\n",
    "\n",
    "            # Append predictions to test DataFrame.\n",
    "            for model_name in self.models[level].keys():\n",
    "                model = self.models[level][model_name]\n",
    "                pred = model.predict_proba(X[feature_cols])[:, 1] \n",
    "                X.loc[:, f\"{model_name}_{level}\"] = pred\n",
    "\n",
    "        # Return last prediction, i.e. top-most model.\n",
    "        return np.c_[1 - pred, pred]\n",
    "\n",
    "    \n",
    "    def _stratified_kfold_cv(self, X, y):\n",
    "        data = X.copy().reset_index(drop=True)\n",
    "        data['target'] = y\n",
    "        data['kfold'] = -1\n",
    "        skf = model_selection.StratifiedKFold(n_splits=self.num_folds)\n",
    "        for fold, (_, val_) in enumerate(skf.split(data, data.target)):\n",
    "            data.loc[val_, \"kfold\"] = fold\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def _get_feature_columns(self, data, level):\n",
    "        if level == 0:\n",
    "            features = data.drop(['target', 'kfold'], axis=1, errors=\"ignore\")\n",
    "            feature_cols = features.columns.tolist()\n",
    "        else:\n",
    "            prev_level = self.models[level-1].keys()\n",
    "            feature_cols = [f'{name}_{level-1}' for name in prev_level]\n",
    "        return feature_cols\n",
    "\n",
    "    \n",
    "    def _generate_fold_preds(self, parallel, data, model, verbose):\n",
    "        # We clone the model inside to not mess with the random seed.\n",
    "        out = parallel(\n",
    "            delayed(self._predict_fold)(data, clone(model), fold, verbose) \n",
    "            for fold in data.kfold.unique()\n",
    "        )\n",
    "        return list(zip(*out))\n",
    "\n",
    "    \n",
    "    def _predict_fold(self, data, model, fold, verbose):\n",
    "        \"Return out-of-fold predictions: train on K-1 folds, predict on fold K.\"\n",
    "\n",
    "        # Get folds; include target and feature cols.\n",
    "        data_trn = data[data.kfold != fold]\n",
    "        data_val = data[data.kfold == fold]\n",
    "        \n",
    "        # Fit model.\n",
    "        model.fit(data_trn, data_trn.target.values)\n",
    "        val_pred = model.predict_proba(data_val)[:, 1] \n",
    "        auc = metrics.roc_auc_score(data_val.target.values, val_pred)\n",
    "        if verbose:\n",
    "            print(f\"fold={fold}, auc={auc}\")\n",
    "\n",
    "        # Return out-of-fold predictions.\n",
    "        return val_pred, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268295d4",
   "metadata": {
    "papermill": {
     "duration": 0.068513,
     "end_time": "2022-01-03T16:11:04.926813",
     "exception": false,
     "start_time": "2022-01-03T16:11:04.858300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that `StackingClassifierParallel` is not a scikit-learn estimator, so it cannot be used inside pipelines. That should be fine since we tend to tune the base models individually anyway as the complexity of hyperparameter search increasing exponentially in the number of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cda9d",
   "metadata": {},
   "source": [
    "### Defining models to stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75dcc0c",
   "metadata": {
    "editable": false,
    "id": "d8fee63a",
    "papermill": {
     "duration": 0.067619,
     "end_time": "2022-01-03T16:11:05.206955",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.139336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the models for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c90a0a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:05.364186Z",
     "iopub.status.busy": "2022-01-03T16:11:05.363485Z",
     "iopub.status.idle": "2022-01-03T16:11:05.368440Z",
     "shell.execute_reply": "2022-01-03T16:11:05.367824Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.156075Z"
    },
    "papermill": {
     "duration": 0.088674,
     "end_time": "2022-01-03T16:11:05.368615",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.279941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    TfidfVectorizer(max_features=1000),\n",
    "    linear_model.LogisticRegression(random_state=42)\n",
    ")\n",
    "\n",
    "lr_cnt = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    CountVectorizer(),\n",
    "    linear_model.LogisticRegression(solver='liblinear', random_state=42)\n",
    ")\n",
    "\n",
    "rf_svd = make_pipeline(\n",
    "    ReviewColumnExtractor(),\n",
    "    TfidfVectorizer(max_features=None),\n",
    "    decomposition.TruncatedSVD(n_components=120, random_state=42),\n",
    "    ensemble.RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfe7f5",
   "metadata": {
    "papermill": {
     "duration": 0.078481,
     "end_time": "2022-01-03T16:11:05.527581",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.449100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define models dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c16ca5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:05.681353Z",
     "iopub.status.busy": "2022-01-03T16:11:05.680628Z",
     "iopub.status.idle": "2022-01-03T16:11:05.691558Z",
     "shell.execute_reply": "2022-01-03T16:11:05.692071Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.172579Z"
    },
    "papermill": {
     "duration": 0.088164,
     "end_time": "2022-01-03T16:11:05.692274",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.604110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base models\n",
    "level1 = {\n",
    "    'lr': make_pipeline(\n",
    "        ReviewColumnExtractor(),\n",
    "        TfidfVectorizer(max_features=1000),\n",
    "        linear_model.LogisticRegression(random_state=42)\n",
    "    ), \n",
    "    \n",
    "    'lr_cnt': make_pipeline(\n",
    "        ReviewColumnExtractor(),\n",
    "        CountVectorizer(), \n",
    "        linear_model.LogisticRegression(solver='liblinear', random_state=42)\n",
    "    ), \n",
    "}\n",
    "\n",
    "# Meta models\n",
    "level2 = {\n",
    "    'lr': linear_model.LogisticRegression(random_state=42),\n",
    "    'linreg': make_pipeline(StandardScaler(), LinearRegressionClassifier()),\n",
    "    'xgb': XGBClassifier(eval_metric=\"logloss\", \n",
    "                         use_label_encoder=False, \n",
    "                         nthread=1, \n",
    "                         random_state=42)\n",
    "}\n",
    "\n",
    "# Meta models\n",
    "level3 = {\n",
    "    'linreg': make_pipeline(StandardScaler(), LinearRegressionClassifier()),\n",
    "    'xgb': XGBClassifier(eval_metric=\"logloss\", \n",
    "                         use_label_encoder=False, \n",
    "                         nthread=1,\n",
    "                         random_state=42)\n",
    "}\n",
    "\n",
    "# Blender head: rank true for linear reg.\n",
    "level4 = {'blender': Blender(rank=True, random_state=42)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad436b96",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2021-08-31T14:00:57.221484Z",
     "iopub.status.busy": "2021-08-31T14:00:57.221148Z",
     "iopub.status.idle": "2021-08-31T14:00:57.22775Z",
     "shell.execute_reply": "2021-08-31T14:00:57.226607Z",
     "shell.execute_reply.started": "2021-08-31T14:00:57.221454Z"
    },
    "id": "4557cc3b",
    "papermill": {
     "duration": 0.068356,
     "end_time": "2022-01-03T16:11:05.831427",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.763071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ":::{caution}\n",
    "Setting `nthread=1` for `XGBClassifier` decreases train time for the parallel stacker from ~250s to ~100s. This goes from worse to better than sequential processing. See [this issue](https://github.com/dmlc/xgboost/issues/2163) from the XGBoost repository.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa909ca1",
   "metadata": {
    "editable": false,
    "id": "0e075e51",
    "papermill": {
     "duration": 0.072145,
     "end_time": "2022-01-03T16:11:05.975807",
     "exception": false,
     "start_time": "2022-01-03T16:11:05.903662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Comparing training times between serial and parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c13451e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:06.126988Z",
     "iopub.status.busy": "2022-01-03T16:11:06.126239Z",
     "iopub.status.idle": "2022-01-03T16:11:06.129803Z",
     "shell.execute_reply": "2022-01-03T16:11:06.130369Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.191194Z"
    },
    "papermill": {
     "duration": 0.081851,
     "end_time": "2022-01-03T16:11:06.130591",
     "exception": false,
     "start_time": "2022-01-03T16:11:06.048740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [level1, level2, level3, level4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebaf7a",
   "metadata": {
    "editable": false,
    "id": "c2a0135f",
    "papermill": {
     "duration": 0.073538,
     "end_time": "2022-01-03T16:11:06.275756",
     "exception": false,
     "start_time": "2022-01-03T16:11:06.202218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start timing runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a44d897a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:11:06.426997Z",
     "iopub.status.busy": "2022-01-03T16:11:06.426262Z",
     "iopub.status.idle": "2022-01-03T16:16:46.940912Z",
     "shell.execute_reply": "2022-01-03T16:16:46.938394Z",
     "shell.execute_reply.started": "2022-01-03T09:38:53.201421Z"
    },
    "papermill": {
     "duration": 340.590938,
     "end_time": "2022-01-03T16:16:46.941080",
     "exception": false,
     "start_time": "2022-01-03T16:11:06.350142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26.701034625371296, 2.027048202300999)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = []\n",
    "for i in range(3):\n",
    "    start_time = time.time()\n",
    "    parallel = StackingClassifierParallel(models, n_jobs=-1, verbose=0)\n",
    "    parallel.fit(X_train, y_train)\n",
    "    times.append(time.time() - start_time)\n",
    "    \n",
    "times = np.array(times)\n",
    "times.mean(), times.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168f2eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:16:47.129832Z",
     "iopub.status.busy": "2022-01-03T16:16:47.129136Z",
     "iopub.status.idle": "2022-01-03T16:25:01.868988Z",
     "shell.execute_reply": "2022-01-03T16:25:01.869497Z",
     "shell.execute_reply.started": "2022-01-03T09:39:14.324795Z"
    },
    "papermill": {
     "duration": 494.835929,
     "end_time": "2022-01-03T16:25:01.869700",
     "exception": false,
     "start_time": "2022-01-03T16:16:47.033771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.20562450091044, 2.389116944961817)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = []\n",
    "for i in range(3):\n",
    "    start_time = time.time()\n",
    "    serial = StackingClassifier(models, verbose=0)\n",
    "    serial.fit(X_train, y_train)\n",
    "    times.append(time.time() - start_time)\n",
    "    \n",
    "times = np.array(times)\n",
    "times.mean(), times.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c1260",
   "metadata": {
    "editable": false,
    "id": "a8de71ba",
    "papermill": {
     "duration": 0.085092,
     "end_time": "2022-01-03T16:25:02.044823",
     "exception": false,
     "start_time": "2022-01-03T16:25:01.959731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Observe that parallel training has approximately 40% speed up over sequential training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9911d",
   "metadata": {
    "editable": false,
    "id": "449c95c6",
    "papermill": {
     "duration": 0.0886,
     "end_time": "2022-01-03T16:25:02.220148",
     "exception": false,
     "start_time": "2022-01-03T16:25:02.131548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing consistency of parallel and serial predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa89e99",
   "metadata": {
    "papermill": {
     "duration": 0.085483,
     "end_time": "2022-01-03T16:25:02.394864",
     "exception": false,
     "start_time": "2022-01-03T16:25:02.309381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Testing if predictions agree between serial and parallel training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4e852d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:25:02.615631Z",
     "iopub.status.busy": "2022-01-03T16:25:02.594125Z",
     "iopub.status.idle": "2022-01-03T16:25:08.616437Z",
     "shell.execute_reply": "2022-01-03T16:25:08.618038Z",
     "shell.execute_reply.started": "2022-01-03T09:45:46.787821Z"
    },
    "papermill": {
     "duration": 6.136018,
     "end_time": "2022-01-03T16:25:08.618348",
     "exception": false,
     "start_time": "2022-01-03T16:25:02.482330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yp_test = parallel.predict_proba(X_test)[:, 1]\n",
    "ys_test = serial.predict_proba(X_test)[:, 1]\n",
    "assert (yp_test - ys_test).mean() < 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bd4cd07",
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-01-03T16:30:45.655783Z",
     "iopub.status.busy": "2022-01-03T16:30:45.654997Z",
     "iopub.status.idle": "2022-01-03T16:30:45.668419Z",
     "shell.execute_reply": "2022-01-03T16:30:45.667613Z",
     "shell.execute_reply.started": "2022-01-03T09:48:34.759544Z"
    },
    "id": "7a2ac238",
    "outputId": "76c06369-c9ae-46c2-c925-10c0d163f653",
    "papermill": {
     "duration": 0.131131,
     "end_time": "2022-01-03T16:30:45.668613",
     "exception": false,
     "start_time": "2022-01-03T16:30:45.537482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>lr_1</th>\n",
       "      <th>linreg_1</th>\n",
       "      <th>xgb_1</th>\n",
       "      <th>linreg_2</th>\n",
       "      <th>xgb_2</th>\n",
       "      <th>blender_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052181</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>955.843253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1038.124480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>955.843253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917899</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1841.468940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982799</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1704.229475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr_0  lr_cnt_0      lr_1  linreg_1     xgb_1  linreg_2     xgb_2  \\\n",
       "0  0.052181  0.001930  0.000659 -0.375688  0.000111 -0.375688  0.000111   \n",
       "1  0.029885  0.000006  0.000640 -0.375688  0.000111 -0.375688  0.000111   \n",
       "2  0.052702  0.000440  0.000658 -0.375688  0.000111 -0.375688  0.000111   \n",
       "3  0.917899  0.996462  0.999197 -0.125688  0.999888 -0.125688  0.999888   \n",
       "4  0.982799  0.999165  0.999260 -0.125688  0.999888 -0.125688  0.999888   \n",
       "\n",
       "     blender_3  \n",
       "0   955.843253  \n",
       "1  1038.124480  \n",
       "2   955.843253  \n",
       "3  1841.468940  \n",
       "4  1704.229475  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel.metafeatures_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b423a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T16:30:45.900130Z",
     "iopub.status.busy": "2022-01-03T16:30:45.899437Z",
     "iopub.status.idle": "2022-01-03T16:30:45.913030Z",
     "shell.execute_reply": "2022-01-03T16:30:45.912452Z",
     "shell.execute_reply.started": "2022-01-03T09:48:35.819945Z"
    },
    "papermill": {
     "duration": 0.131089,
     "end_time": "2022-01-03T16:30:45.913191",
     "exception": false,
     "start_time": "2022-01-03T16:30:45.782102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_0</th>\n",
       "      <th>lr_cnt_0</th>\n",
       "      <th>lr_1</th>\n",
       "      <th>linreg_1</th>\n",
       "      <th>xgb_1</th>\n",
       "      <th>linreg_2</th>\n",
       "      <th>xgb_2</th>\n",
       "      <th>blender_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052181</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>955.843253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029885</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1038.124480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.375688</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>955.843253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917899</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1841.468940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982799</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>-0.125688</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1704.229475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr_0  lr_cnt_0      lr_1  linreg_1     xgb_1  linreg_2     xgb_2  \\\n",
       "0  0.052181  0.001930  0.000659 -0.375688  0.000111 -0.375688  0.000111   \n",
       "1  0.029885  0.000006  0.000640 -0.375688  0.000111 -0.375688  0.000111   \n",
       "2  0.052702  0.000440  0.000658 -0.375688  0.000111 -0.375688  0.000111   \n",
       "3  0.917899  0.996462  0.999197 -0.125688  0.999888 -0.125688  0.999888   \n",
       "4  0.982799  0.999165  0.999260 -0.125688  0.999888 -0.125688  0.999888   \n",
       "\n",
       "     blender_3  \n",
       "0   955.843253  \n",
       "1  1038.124480  \n",
       "2   955.843253  \n",
       "3  1841.468940  \n",
       "4  1704.229475  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial.metafeatures_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47958d9d",
   "metadata": {
    "papermill": {
     "duration": 0.101639,
     "end_time": "2022-01-03T16:30:46.123396",
     "exception": false,
     "start_time": "2022-01-03T16:30:46.021757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63b5b8",
   "metadata": {
    "papermill": {
     "duration": 0.104545,
     "end_time": "2022-01-03T16:30:46.334113",
     "exception": false,
     "start_time": "2022-01-03T16:30:46.229568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we have implemented a class for model stacking and blending on a text classification task. We saw that stacking uncorrelated models result in some improvement in performance by creating metafeatures which are prediction probabilities of lower level models. \n",
    "\n",
    "The main tools constructed in this notebook are the **`StackingClassifierParallel`** and the **`Blender`** classes. These classes expose a `.fit()` and `.predict_proba()` method similar to scikit-learn models, as well as learned attributes `.metafeatures_` and `.coef_` which can be useful for hacking into the models. The parallel implementation resulted in significant reduction in training time, without any undesirable side-effects. The implementation of blending uses the Nelder-Mead method from `scipy.optimize` to find the best blending coefficents for the columns.\n",
    "\n",
    "Parallelism can perhaps be implemented during inference, but this would depend on the exact use case. \n",
    "We got into some trouble with getting reproducible results using `joblib.Parallel`. This is solved by cloning the models in the right places. Also, we had issues making parallel work with XGBoost. But the current configuration seems to work in a Kaggle Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59800a1",
   "metadata": {
    "papermill": {
     "duration": 0.105033,
     "end_time": "2022-01-03T16:30:46.547401",
     "exception": false,
     "start_time": "2022-01-03T16:30:46.442368",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2242.595825,
   "end_time": "2022-01-03T16:30:47.778699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-03T15:53:25.182874",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
