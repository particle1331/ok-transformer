{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Engineering Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/mlops/04-deployment)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social)](https://github.com/particle1331/inefficient-networks)\n",
    "\n",
    "```text\n",
    "ð—”ð˜ð˜ð—¿ð—¶ð—¯ð˜‚ð˜ð—¶ð—¼ð—»: Notes for Module 6 of the MLOps Zoomcamp (2022) by DataTalks.Club.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will cover best practices for developing and deploying our code. We will take our example [streaming code](https://particle1331.github.io/inefficient-networks/notebooks/mlops/04-deployment/notes.html#streaming-deploying-models-with-kinesis-and-lambda) from a previous module, break it down into testable units, and improve it with software engineering best practices. More precisely, we create and automate unit and integration testing, code quality checks, and add pre-commit hooks for these. We will also look at how to use `make` which is a nice tools for abstracting and automating repetitive but involved tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Python code with pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at [the script](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/04-deployment/streaming/lambda_function.py) that we will work on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Load environmental variables\n",
    "PREDICTIONS_STREAM_NAME = os.getenv('PREDICTIONS_STREAM_NAME', 'ride_predictions')\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "TEST_RUN = os.getenv('TEST_RUN', 'False') == 'True'\n",
    "\n",
    "# Load model from S3\n",
    "logged_model = f's3://mlflow-models-ron/1/{RUN_ID}/artifacts/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(features):\n",
    "    pred = model.predict(features)\n",
    "    return float(pred[0])\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    predictions_events = []\n",
    "    \n",
    "    for record in event['Records']:\n",
    "        encoded_data = record['kinesis']['data']\n",
    "        decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "        ride_event = json.loads(decoded_data)\n",
    "\n",
    "        ride = ride_event['ride']\n",
    "        ride_id = ride_event['ride_id']\n",
    "    \n",
    "        features = prepare_features(ride)\n",
    "        prediction = predict(features)\n",
    "    \n",
    "        prediction_event = {\n",
    "            'model': 'ride_duration_prediction_model',\n",
    "            'version': '123',\n",
    "            'prediction': {\n",
    "                'ride_duration': prediction,\n",
    "                'ride_id': ride_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if not TEST_RUN:\n",
    "            kinesis_client = boto3.client('kinesis')\n",
    "            kinesis_client.put_record(\n",
    "                StreamName=PREDICTIONS_STREAM_NAME,\n",
    "                Data=json.dumps(prediction_event),\n",
    "                PartitionKey=str(ride_id)\n",
    "            )\n",
    "        \n",
    "        predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions_events\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, first this script loads the environmental variables and the model from S3. Then, it defines two helper functions for preprocessing and making prediction with the model. The most important function in this script is `lambda_handler` which takes in an `event` which contains a batch of events from the input stream. This explains the outer loop over `event['Records']`. \n",
    "\n",
    "Inside this block, the data is decoded and a prediction is made which is packaged as an event for the output stream. If this function is in production, i.e. outside of a test run, then the prediction event is written on the output stream. In this case, a Kinesis client is instantiated, and an output event is written to the specific predictions stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addding unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a `tests/` folder where we will put all our tests. We will be using `pipenv` to manage our environment. See the [previous module](https://particle1331.github.io/inefficient-networks/notebooks/mlops/04-deployment/notes.html#setting-up-the-environment-with-pipenv) for details. We will start with the following Pipfile:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ini\n",
    "[[source]]\n",
    "url = \"https://pypi.org/simple\"\n",
    "verify_ssl = true\n",
    "name = \"pypi\"\n",
    "\n",
    "[packages]\n",
    "boto3 = \"*\"\n",
    "mlflow = \"*\"\n",
    "scikit-learn = \"==1.0.2\"\n",
    "\n",
    "[dev-packages]\n",
    "pytest = \"*\"\n",
    "\n",
    "[requires]\n",
    "python_version = \"3.9\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this installs [pytest](https://docs.pytest.org/en/7.1.x/) as a dev dependency. Let us create one test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# tests/model_test.py\n",
    "import lambda_function\n",
    "\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 140,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 2.05\n",
    "    }\n",
    "\n",
    "    actual_features = lambda_function.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '140_205',\n",
    "        'trip_distance': 2.05,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this, since this test is not related to the model, we can comment out the block that loads the model from S3 to make this test run faster. Tests can be run either by doing `$ pytest` on the terminal:\n",
    "\n",
    "```bash\n",
    "$ pytest\n",
    "======================== test session starts ========================\n",
    "platform darwin -- Python 3.9.12, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: /Users/particle1331/code/inefficient-networks/docs/notebooks/mlops/06-best-practices\n",
    "plugins: anyio-3.6.1\n",
    "collected 1 item\n",
    "\n",
    "tests/model_test.py .                                         [100%]\n",
    "\n",
    "========================= 1 passed in 1.03s =========================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using the UI in VS Code after selecting pytest in the configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../../img/vscode-testing.png\n",
    "---\n",
    "width: 40em\n",
    "---\n",
    "Testing interface in VS Code. Really convenient for running and visualizing tests.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to manually comment out things in our tests. This is not really great. Also, it would fail if our dev environment cannot connect to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial version. Focus on prediction. No writing on stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import model\n",
    "\n",
    "RUN_ID = os.getenv('RUN_ID')\n",
    "\n",
    "model_service = model.init(run_id=RUN_ID)\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # pylint: disable=unused-argument\n",
    "    return model_service.lambda_handler(event)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import mlflow\n",
    "import base64\n",
    "\n",
    "\n",
    "def load_model(run_id):\n",
    "    model_path = f's3://mlflow-models-ron/1/{run_id}/artifacts/model'\n",
    "    model = mlflow.pyfunc.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def base64_decode(encoded_data):\n",
    "    decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "    ride_event = json.loads(decoded_data)\n",
    "    return ride_event\n",
    "\n",
    "\n",
    "class ModelService:\n",
    "\n",
    "    def __init__(self, model, model_version=None):\n",
    "        self.model = model\n",
    "        self.model_version = model_version\n",
    "\n",
    "    def prepare_features(self, ride):\n",
    "        features = {}\n",
    "        features['PU_DO'] = f\"{ride['PULocationID']}_{ride['DOLocationID']}\"\n",
    "        features['trip_distance'] = ride['trip_distance']\n",
    "        return features\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred = self.model.predict(features)\n",
    "        return float(pred[0])\n",
    "\n",
    "    def lambda_handler(self, event):\n",
    "        \"\"\"Predict on batch of input events.\"\"\"\n",
    "\n",
    "        predictions_events = []\n",
    "\n",
    "        for record in event['Records']:\n",
    "\n",
    "            # Decode data from input kinesis stream\n",
    "            encoded_data = record['kinesis']['data']\n",
    "            ride_event = base64_decode(encoded_data)\n",
    "\n",
    "            # Pickout id to match input to output\n",
    "            ride = ride_event['ride']\n",
    "            ride_id = ride_event['ride_id']\n",
    "\n",
    "            # Make predictions using model\n",
    "            features = self.prepare_features(ride)\n",
    "            prediction = self.predict(features)\n",
    "\n",
    "            # Package prediction event for output stream\n",
    "            prediction_event = {\n",
    "                'model': 'ride_duration_prediction_model',\n",
    "                'version': self.model_version,\n",
    "                'prediction': {'ride_duration': prediction, 'ride_id': ride_id},\n",
    "            }\n",
    "\n",
    "            predictions_events.append(prediction_event)\n",
    "\n",
    "        return {'predictions': predictions_events}\n",
    "\n",
    "\n",
    "def init(run_id: str):\n",
    "    \"\"\"Initialize model service.\"\"\"\n",
    "\n",
    "    model = load_model(run_id)\n",
    "    model_service = ModelService(model=model, model_version=run_id)\n",
    "\n",
    "    return model_service\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker build -t stream-model-duration:v2 .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker run -it --rm -p 8080:8080 --env-file .env stream-model-duration:v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python test_docker.py to check if still working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test base64 decode\n",
    "test prepare_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from model import ModelService\n",
    "from model import base64_decode\n",
    "\n",
    "\n",
    "def test_base64_decode():\n",
    "    base64_input = \"eyAgICAgICAgICAicmlkZSI6IHsgICAgICAgICAgICAgICJQVUxvY2F0aW9uSUQiOiAxMzAsICAgICAgICAgICAgICAiRE9Mb2NhdGlvbklEIjogMjA1LCAgICAgICAgICAgICAgInRyaXBfZGlzdGFuY2UiOiAzLjY2ICAgICAgICAgIH0sICAgICAgICAgICJyaWRlX2lkIjogMTIzICAgICAgfQ==\"\n",
    "\n",
    "    actual_result = base64_decode(base64_input)\n",
    "    expected_result = {\n",
    "        \"ride\": {\n",
    "            \"PULocationID\": 130,\n",
    "            \"DOLocationID\": 205,\n",
    "            \"trip_distance\": 3.66,\n",
    "        },\n",
    "        \"ride_id\": 123,\n",
    "    }\n",
    "\n",
    "    assert actual_result == expected_result\n",
    "\n",
    "\n",
    "def test_prepare_features():\n",
    "    \"\"\"Test preprocessing.\"\"\"\n",
    "\n",
    "    ride = {\n",
    "        \"PULocationID\": 140,\n",
    "        \"DOLocationID\": 205,\n",
    "        \"trip_distance\": 2.05\n",
    "    }\n",
    "\n",
    "    model_service = ModelService(model=None)\n",
    "\n",
    "    actual_features = model_service.prepare_features(ride)\n",
    "    \n",
    "    expected_features = {\n",
    "        'PU_DO': '140_205',\n",
    "        'trip_distance': 2.05,\n",
    "    }\n",
    "\n",
    "    assert actual_features == expected_features\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refactor to make easier to testm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model mock = test model same methods and attributes / stupid model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tdd, every change -> code still works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are unit tests -> test individual functionalities\n",
    "\n",
    "integration test -> make sure runs correctly as a whole\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unit tests quite limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not really care about accuracy of model, just want to make sure flow of prediction works. so we want to remove dependency on s3. remove all hard coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "aws s3 ls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
